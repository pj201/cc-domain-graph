{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN model of URIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First check that Tensorflow is correctly installed and can see the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15165060074906648118\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11332668621\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 7476987862329217921\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the pre-amble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM, Recurrent\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import gzip\n",
    "import math\n",
    "\n",
    "def entropy(pred): \n",
    "    return sum([-p*math.log(p) for p in pred])\n",
    "\n",
    "def sample(a, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Samples an index from a probability array;\n",
    "    higher temperature raises the entropy and vice versa    \n",
    "    \"\"\"\n",
    "    a = np.log(a) / temperature\n",
    "    dist = np.exp(a) / np.sum(np.exp(a))\n",
    "    choices = range(len(a)) \n",
    "    return np.random.choice(choices, p=dist)\n",
    "\n",
    "def hx(i):\n",
    "    \"\"\"\n",
    "    Normalised 2-char hex representation of 0-255\n",
    "    \"\"\"\n",
    "    a = hex(i)[2:]\n",
    "    if len(a)<2: a = ''.join(['0',a])\n",
    "    return a\n",
    "\n",
    "hexabet = [hx(x) for x in range(256)]\n",
    "byte_idx = dict((c, i) for i, c in enumerate(hexabet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the domain string file for training. At present from cloned git repo. \n",
    "\n",
    "TO DO: read from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# bytes: 10000000\n",
      "\n",
      "\n",
      "/www868686.wyw.cn/ncontact_346701.html\n",
      "/wlrq.wyw.cn/tradelist_347993.html\n",
      "/BANTAI801.wyw.cn/ntrade_541599.html\n",
      "/bantai806.wyw.cn/ncontact_541502.html\n",
      "/www.snc.edu/assets2/images/socialmedia/insta.png\n",
      "/page-4403.html\n",
      "/goodlife.wyw.cn/tradelist_540770.html\n",
      "/www.snc.edu/assets2//images/socialmedia/face.png\n",
      "/C:/Users/Skipper/Google%20%E9%9B%B2%E7%AB%AF%E7%A1%AC%E7%A2%9F/%E8%BB%8D%E4%BA%8B%E5%BE%AE%E9%9D%A9%E5%91%BD/%E8%87%AA%E8%A3%BD%E6%BD%9B%E8%89%A6%E6%98%AF%E4%B8%80%E9%A0%85%E5%BF%85%E9%A0%88%E5%84%98%E6%97%A9%E8%90%BD%E5%AF%A6%E7%9A%84%E5%9C%8B%E5%AE%B6%E9%87%8D%E5%A4%A7%E6%94%BF%E7%AD%96.docx\n",
      "/www.snc.edu/assets3/images/saint.png\n",
      "/www.xe.com/es/currencycharts/\n",
      "/page-843.html\n",
      "/page-1568.html\n",
      "/page-2924.html\n",
      "/piwik.php\n",
      "/wlkcjj.wyw.cn/contact_352711.html\n",
      "/DIMA.wyw.cn/tradelist_350616.html\n",
      "/www.abc7.com/apps\n",
      "/page-59.html\n",
      "/page-5792.html\n",
      "/BANTAI801.wyw.cn/ncontact_541599.html\n",
      "/joyson.ru/\n",
      "/newpearl.wyw.cn/contact_353014.html\n",
      "/page-6947.html\n",
      "/summit.wyw.cn/contact_347098.html\n",
      "/C:/Users/dm\n"
     ]
    }
   ],
   "source": [
    "train_file = \"big_domain_string_1.gz\"\n",
    "path = \"../sdata/\"\n",
    "\n",
    "with gzip.open(path + train_file, 'rb') as f:\n",
    "    content = f.read()\n",
    "\n",
    "bytes = [b.encode('hex') for b in content][int(3e07):int(4e07)] #Â sample bytes for local testing\n",
    "#bytes = [b.encode('hex') for b in content]\n",
    "print('# bytes:', len(bytes))\n",
    "print(content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training and test strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training length: 7500000\n",
      "test length: 2500000\n"
     ]
    }
   ],
   "source": [
    "# divide into training and test sets:\n",
    "n_train = int(3*len(bytes)/4)\n",
    "text_train = bytes[0:n_train]\n",
    "text_test = bytes[n_train:len(bytes)]\n",
    "\n",
    "print('training length:', len(text_train))\n",
    "print('test length:', len(text_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut the text in semi-redundant 'sentences' of bytes, each of length <tt>unroll</tt>, and stepping forward a number <tt>step</tt> of bytes each time. \n",
    "\n",
    "These sentences are then converted into numpy arrays for RNN input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sequences: 2499994\n"
     ]
    }
   ],
   "source": [
    "unroll = 20\n",
    "step = 3\n",
    "sentences = []\n",
    "next_byte = []\n",
    "for i in range(0, n_train - unroll, step):\n",
    "    sentences.append(text_train[i: i + unroll])\n",
    "    next_byte.append(text_train[i + unroll])\n",
    "print('# sequences:', len(sentences))\n",
    "\n",
    "# convert to feature vector + next character:\n",
    "X = np.zeros((len(sentences), unroll, 256), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), 256), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t,b in enumerate(sentence):\n",
    "        X[i, t, byte_idx[b]] = 1\n",
    "    y[i, byte_idx[next_byte[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the RNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 16)                17472     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4352      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "=================================================================\n",
      "Total params: 21,824\n",
      "Trainable params: 21,824\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the model: 2 stacked LSTM\n",
    "\n",
    "nhidden = [16] # e.g. [512, 512]\n",
    "dropout = 0.1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(nhidden[0], return_sequences=False, input_shape=(unroll, 256)))\n",
    "#model.add(LSTM(nhidden[0], return_sequences=True, input_shape=(unroll, 256)))\n",
    "#model.add(Dropout(dropout))\n",
    "#model.add(LSTM(nhidden[1], return_sequences=False))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load existing weights into the model, or fit from random initialisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# either load weights:\n",
    "wt_path = \"../sdata/\"\n",
    "model.set_weights(np.load(wt_path+\"model_from_big_domain_string_1.gz_arch_16_unroll_20_step_3_dropout_0.1.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4999994/4999994 [==============================] - 1304s - loss: 2.6086  - ETA: 0s -\n",
      "Epoch 2/20\n",
      "4999994/4999994 [==============================] - 1301s - loss: 2.5842  - ETA: 0s - loss: 2.584\n",
      "Epoch 3/20\n",
      "4999994/4999994 [==============================] - 1301s - loss: 2.5756  \n",
      "Epoch 4/20\n",
      "4999994/4999994 [==============================] - 1331s - loss: 2.5701  \n",
      "Epoch 5/20\n",
      "4999994/4999994 [==============================] - 1295s - loss: 2.5671  \n",
      "Epoch 6/20\n",
      "4999994/4999994 [==============================] - 1293s - loss: 2.5645  \n",
      "Epoch 7/20\n",
      "4999994/4999994 [==============================] - 1292s - loss: 2.5615  \n",
      "Epoch 8/20\n",
      "1983104/4999994 [==========>...................] - ETA: 780s - loss: 2.5604"
     ]
    }
   ],
   "source": [
    "# or fit and save weights:\n",
    "wt_path = \"../sdata/\"\n",
    "wt_file = \"model_from_%s_arch\" % train_file\n",
    "for i in nhidden: \n",
    "    wt_file += \"_%d\" % i\n",
    "wt_file += \"_unroll_%d_step_%d_dropout_%g.npy\" % (unroll, step, dropout)\n",
    "\n",
    "model.fit(X, y, batch_size=128, epochs=20, verbose=1)\n",
    "np.save(wt_path + wt_file, model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eyeball the model by using it to generate a stretch of synthetic domain strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --------------------------------------------------\n",
      "Seed:\n",
      "/50-to-100/sale/yes/\n",
      " --------------------------------------------------\n",
      "/50-to-100/sale/yes/xliahmo-tabetsposs-ach-alig_c_3/tai/images.jp-ger-siamo-testwy-tir.html\n",
      "/imeded-du-imi2-7\n",
      "/statial-corney/fouuntie_uolounhd/w-firc-5\n",
      "/mocjo-rhobii/0-im\n",
      "/\n",
      "/noiphon-dechS\n",
      "/granrgri/wenga-\n",
      "/thicts\n",
      "/capegof2/ipterber/poymantess/saloaoi-th-diren-evr/\n",
      "/logdenc-xory50961146336071\n",
      "\n",
      "\n",
      "\n",
      "wwwaxacobmad.tihipmobtsx/hsp-trebod-bre-tanamoa-den.asplw/rincYxp70_nile\n",
      "/oonuma-hirlali/c-128/\n",
      "/siation/warylead/caslach/5bs_contute-meus.html\n",
      "/10/hef-ec5626530.raezonbcr\n",
      "/vendlak.html\n",
      "\n",
      "\n",
      "\n",
      "vot.naeatulfebloamye.antesligense.ps\n",
      "/iwi\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wwwcododdbenmi.com\n",
      "\n",
      "\n",
      "/46naob/massa-en+tiod-ge/niri/\n",
      "/tutss-faye/pamedyinery-Fula-Ber/hefextr/peruntsebam-evfrc7dcb/tarc-capiya-ucarut-ets_\n",
      "/uates/centanlers-it-bolbshiana/categorex-dat-tbo-turt\n",
      "/snoi-dunsdounki-012984714100811/w8529i//Deverh-Sp-Neacher/77135213168.jpg\n",
      "/h-uaten/\n",
      "/Ssovggowieeri_sCttding/3767.1379491.103000b4926022x30\n",
      "/homauspilurcen-chinndc9_norissoagegef\n",
      "/catiatey-oont/img/reinla_Cult-ue-cit/detakobots/biart-3alf/fenche-prodyitalnts/pra-rodki-pony-klrinihads-2776/sowcatonise-ipicam/ploize-kineirgy/inder-6n7/iandions/\n",
      "/quat-mdergolGousVuiga-l-ew/lCem/MATr-84720rA205as5_75s_cortlyeertald/emagig-lowe/1747.html\n",
      "/calchilen/\n",
      "/wwrlut-15.html\n",
      "\n",
      "\n",
      "\n",
      "w\n",
      "www.ssiomodcikxve.jg\n",
      "/dinigitotensin/wenorii/casno-gagerobv-isban/ib/intkM.phg\n",
      "/adioan/sigunbiag.com\n",
      "/397a9.html\n",
      "/t-tag/ver-matarinii-2mst/hws/le-hochy06--abana-chits-sirs-leyniec-ouduly-catial-shovbanaikk-lanchine/msd96.html\n",
      "/blbotunsss/ler/owji3eal.jpg\n",
      "/imocit-cjthbtin-ashrkkifo/lemaini2_citihys/\n",
      "/tag/ac/19/neunw0_ut/seving/_Vutici/wmfT.html\n",
      "/ploaump/%ecuating/son-lufibi-colmits.pt9\n",
      "/riright-catibi-/0nes-1300.png\n",
      "/fosphan-pecfa/cort_tas_AArRaacom-2u-2f7701743714f/04/\n",
      "/matissowobore-60_846.ne4.j"
     ]
    }
   ],
   "source": [
    "temp = 1.0\n",
    "quote_length = 2000\n",
    "\n",
    "# pick random:\n",
    "start = random.randint(0, len(text_test) - unroll - 1)\n",
    "init_quote = text_test[start : start + unroll]\n",
    "\n",
    "generated = init_quote\n",
    "print('\\n', '-' * 50)\n",
    "print(\"Seed:\")\n",
    "sys.stdout.write(''.join([unichr(int(h, 16)) for h in init_quote]))\n",
    "print('\\n', '-' * 50)\n",
    "sys.stdout.write(''.join([unichr(int(h, 16)) for h in generated]))\n",
    "for i in range(quote_length):\n",
    "    x = np.zeros((1, unroll, 256))\n",
    "    for t,b in enumerate(generated):\n",
    "        x[0, t, byte_idx[b]] = 1.\n",
    "\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_index = sample(preds, temperature=temp)\n",
    "    next_byte = hexabet[next_index]\n",
    "    generated = generated[1:] + [next_byte]\n",
    "\n",
    "    sys.stdout.write(unichr(int(next_byte, 16)))\n",
    "    sys.stdout.flush()\n",
    "print('\\n', '-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
