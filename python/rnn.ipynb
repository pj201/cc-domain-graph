{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN model of URIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First check that Tensorflow is correctly installed and can see the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6475351416221427226\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11332668621\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 9648770111006450505\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the pre-amble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM, Recurrent\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import gzip\n",
    "import math\n",
    "\n",
    "def entropy(pred): \n",
    "    return sum([-p*math.log(p) for p in pred])\n",
    "\n",
    "def sample(a, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Samples an index from a probability array;\n",
    "    higher temperature raises the entropy and vice versa    \n",
    "    \"\"\"\n",
    "    a = np.log(a) / temperature\n",
    "    dist = np.exp(a) / np.sum(np.exp(a))\n",
    "    choices = range(len(a)) \n",
    "    return np.random.choice(choices, p=dist)\n",
    "\n",
    "def hx(i):\n",
    "    \"\"\"\n",
    "    Normalised 2-char hex representation of 0-255\n",
    "    \"\"\"\n",
    "    a = hex(i)[2:]\n",
    "    if len(a)<2: a = ''.join(['0',a])\n",
    "    return a\n",
    "\n",
    "hexabet = [hx(x) for x in range(256)]\n",
    "byte_idx = dict((c, i) for i, c in enumerate(hexabet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the domain string file for training. At present from cloned git repo. \n",
    "\n",
    "TO DO: read from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# bytes: 10000000\n",
      "\n",
      "\n",
      "/www868686.wyw.cn/ncontact_346701.html\n",
      "/wlrq.wyw.cn/tradelist_347993.html\n",
      "/BANTAI801.wyw.cn/ntrade_541599.html\n",
      "/bantai806.wyw.cn/ncontact_541502.html\n",
      "/www.snc.edu/assets2/images/socialmedia/insta.png\n",
      "/page-4403.html\n",
      "/goodlife.wyw.cn/tradelist_540770.html\n",
      "/www.snc.edu/assets2//images/socialmedia/face.png\n",
      "/C:/Users/Skipper/Google%20%E9%9B%B2%E7%AB%AF%E7%A1%AC%E7%A2%9F/%E8%BB%8D%E4%BA%8B%E5%BE%AE%E9%9D%A9%E5%91%BD/%E8%87%AA%E8%A3%BD%E6%BD%9B%E8%89%A6%E6%98%AF%E4%B8%80%E9%A0%85%E5%BF%85%E9%A0%88%E5%84%98%E6%97%A9%E8%90%BD%E5%AF%A6%E7%9A%84%E5%9C%8B%E5%AE%B6%E9%87%8D%E5%A4%A7%E6%94%BF%E7%AD%96.docx\n",
      "/www.snc.edu/assets3/images/saint.png\n",
      "/www.xe.com/es/currencycharts/\n",
      "/page-843.html\n",
      "/page-1568.html\n",
      "/page-2924.html\n",
      "/piwik.php\n",
      "/wlkcjj.wyw.cn/contact_352711.html\n",
      "/DIMA.wyw.cn/tradelist_350616.html\n",
      "/www.abc7.com/apps\n",
      "/page-59.html\n",
      "/page-5792.html\n",
      "/BANTAI801.wyw.cn/ncontact_541599.html\n",
      "/joyson.ru/\n",
      "/newpearl.wyw.cn/contact_353014.html\n",
      "/page-6947.html\n",
      "/summit.wyw.cn/contact_347098.html\n",
      "/C:/Users/dm\n"
     ]
    }
   ],
   "source": [
    "train_file = \"big_domain_string_1.gz\"\n",
    "path = \"../sdata/\"\n",
    "\n",
    "with gzip.open(path + train_file, 'rb') as f:\n",
    "    content = f.read()\n",
    "\n",
    "bytes = [b.encode('hex') for b in content][:10000000] #Â sample bytes for local testing\n",
    "#bytes = [b.encode('hex') for b in content]\n",
    "print('# bytes:', len(bytes))\n",
    "print(content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training and test strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training length: 7500000\n",
      "test length: 2500000\n"
     ]
    }
   ],
   "source": [
    "# divide into training and test sets:\n",
    "n_train = int(3*len(bytes)/4)\n",
    "text_train = bytes[0:n_train]\n",
    "text_test = bytes[n_train:len(bytes)]\n",
    "\n",
    "print('training length:', len(text_train))\n",
    "print('test length:', len(text_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut the text in semi-redundant 'sentences' of bytes, each of length <tt>unroll</tt>, and stepping forward a number <tt>step</tt> of bytes each time. \n",
    "\n",
    "These sentences are then converted into numpy arrays for RNN input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sequences: 2499994\n"
     ]
    }
   ],
   "source": [
    "unroll = 20\n",
    "step = 3\n",
    "sentences = []\n",
    "next_byte = []\n",
    "for i in range(0, n_train - unroll, step):\n",
    "    sentences.append(text_train[i: i + unroll])\n",
    "    next_byte.append(text_train[i + unroll])\n",
    "print('# sequences:', len(sentences))\n",
    "\n",
    "# convert to feature vector + next character:\n",
    "X = np.zeros((len(sentences), unroll, 256), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), 256), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t,b in enumerate(sentence):\n",
    "        X[i, t, byte_idx[b]] = 1\n",
    "    y[i, byte_idx[next_byte[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the RNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 16)                17472     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4352      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "=================================================================\n",
      "Total params: 21,824\n",
      "Trainable params: 21,824\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the model: 2 stacked LSTM\n",
    "\n",
    "nhidden = [16] # e.g. [512, 512]\n",
    "dropout = 0.1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(nhidden[0], return_sequences=False, input_shape=(unroll, 256)))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load existing weights into the model, or fit from random initialisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# either load weights:\n",
    "wt_path = \"../sdata/\"\n",
    "model.set_weights(np.load(wt_path+\"model_from_big_domain_string_1.gz_arch_16_unroll_20_step_3_dropout_0.1.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2499994/2499994 [==============================] - 652s - loss: 2.5898   \n",
      "Epoch 2/10\n",
      "2499994/2499994 [==============================] - 649s - loss: 2.5791   - ETA: 0s - loss: 2.5 - ETA: 0s - loss: 2.5 - ETA: 0s - loss\n",
      "Epoch 3/10\n",
      "2499994/2499994 [==============================] - 643s - loss: 2.5729   \n",
      "Epoch 4/10\n",
      "2499994/2499994 [==============================] - 640s - loss: 2.5686   \n",
      "Epoch 5/10\n",
      "2499994/2499994 [==============================] - 640s - loss: 2.5641   \n",
      "Epoch 6/10\n",
      "2499994/2499994 [==============================] - 640s - loss: 2.5607   \n",
      "Epoch 7/10\n",
      "2499994/2499994 [==============================] - 642s - loss: 2.5579   \n",
      "Epoch 8/10\n",
      "2499994/2499994 [==============================] - 641s - loss: 2.5552   - ETA\n",
      "Epoch 9/10\n",
      "2499994/2499994 [==============================] - 636s - loss: 2.5528   \n",
      "Epoch 10/10\n",
      "2499994/2499994 [==============================] - 636s - loss: 2.5513   \n"
     ]
    }
   ],
   "source": [
    "# or fit and save weights:\n",
    "wt_path = \"../sdata/\"\n",
    "wt_file = \"model_from_%s_arch\" % train_file\n",
    "for i in nhidden: \n",
    "    wt_file += \"_%d\" % i\n",
    "wt_file += \"_unroll_%d_step_%d_dropout_%g.npy\" % (unroll, step, dropout)\n",
    "\n",
    "model.fit(X, y, batch_size=128, epochs=10, verbose=1)\n",
    "np.save(wt_path + wt_file, model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eyeball the model by using it to generated a strecth of synthetic domain strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --------------------------------------------------\n",
      "Seed:\n",
      "eproniknij/\n",
      "/myaccou\n",
      " --------------------------------------------------\n",
      "eproniknij/\n",
      "/myaccouisuasyeutes/sacotegiy/meic/de1/216442015-s19f8-19/he2c22-da201f.jpt\n",
      "\n",
      "\n",
      "\n",
      "se.perwa\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bluscllestome.m\n",
      "/chespitk-321886.ht-ml_79-/hic/thema/24/yutsempahp_94fi-m/200|231744v.sufes.ong\n",
      "/mele-snoys-paryle-caderse-g/01401/slied/ckesninenuv-s1563689028767664.html\n",
      "/c-biconiey/m/2168/ged0/oumconoconchhoe/kmngrof-catearemila-roussgj-me-nafeleinirit/pocts-ork/s_8696811.2d503.jpg\n",
      "/em71/mytanf-0000/x-ail-vitinias_annie/rebravcer2/sz/\n",
      "/bromanall-merriu-2c249458/0\n",
      "/pre/C-Sonchr-fesPrtestse.png\n",
      "/polusholus/bonpbyar_cumosters/iveeci/imente-stechm.ins93_3_11b/aboens/maythieyonec.html\n",
      "/2011mededdeds-cee-elrue-droustiees/6b73e6xf05369f53/\n",
      "/celoich/zake2--pon/graten/1532/1r/1622800/118c152x014.bloge.html\n",
      "/veviegam-ifsalias-cone/avobuesants/uaten-forinashuskery-thitinge_1/posuti2-EmironInir9pu/letal-funds-comclo/9ititse\n",
      "\n",
      "\n",
      "\n",
      "ciwelncss-\n",
      "/rcpytan-venu-sseoypanlech/\n",
      "/cataytao-\n",
      "/conterr/roade.enkralcptrofif.conw\n",
      "/essen-adiss-ca/397t.efT\n",
      "/B_T6Mkre_Dsarietpanm/412570.html\n",
      "/cas/J1667550.html\n",
      "/steltestx\n",
      "/dw-c4ddeenbomis_7751e502328199.jpg\n",
      "/sul_1bx-0920610.jpg\n",
      "/omersoteur120826.com\n",
      "/desia/icons/\n",
      "/limchlifocuri-risto-loe-thidthatlally-chinu-c823719j44030125/casicegil.gil\n",
      "/cayagyeboosrorers-cated-1d/palo_product/be.html\n",
      "/vainta/ttarinyoatm-.html\n",
      "/lepel-devoc/risrongoel-brachkelebinu-siknpala\n",
      "/esasi-hot-Regousovnakroiles/019-.html\n",
      "/chitimages/alit\n",
      "/mefud.hmmd-\n",
      "\n",
      "\n",
      "\n",
      "rlrervamdraesewr.gibtefliebona.hptt\n",
      "/odb1\n",
      "/chessas_nou-conneska.png\n",
      "/jle-wmle5/hete.html\n",
      "/logal_macha-cane/ripuved.html\n",
      "/aloi/beliat.jpg\n",
      "/imca/medy-hortiezo-rregic-gatohtorg\n",
      "/epurashtal-imros-560.jpg\n",
      "\n",
      "\n",
      "\n",
      "rlu.omocesxu.omtngi9ger.com\n",
      "/aemsstlecetoroives/saril.entseppoutelfast.html\n",
      "/beter/\n",
      "\n",
      "\n",
      "\n",
      "www.mites\n",
      "/fhes/tsalt.pnp\n",
      "/tutos/woahantiony/\n",
      "/Hofesls.png\n",
      "/swa/\n",
      "/plictoshy\n",
      "/2011%4m556887683.jpg\n",
      "/tautarizobo-ctess--pontio-0e_2976x01h6d52/00/avedertemconser-dinls.htm---churnol-553I3-67isb-20.jpg\n",
      "/venkolematenals/1485303818-s-gra-edali/wowscontorny-petrfis\n",
      "/pomgassios/ausssets/359f2/135--\n",
      "/uploauetag\n",
      "/shop/dkintapero-rm/de/prosey/camuceshoniavo-suavalle/ge\n",
      " --------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "temp = 1.0\n",
    "quote_length = 2000\n",
    "\n",
    "# pick random:\n",
    "start = random.randint(0, len(text_test) - unroll - 1)\n",
    "init_quote = text_test[start : start + unroll]\n",
    "\n",
    "generated = init_quote\n",
    "print('\\n', '-' * 50)\n",
    "print(\"Seed:\")\n",
    "sys.stdout.write(''.join([unichr(int(h, 16)) for h in init_quote]))\n",
    "print('\\n', '-' * 50)\n",
    "sys.stdout.write(''.join([unichr(int(h, 16)) for h in generated]))\n",
    "for i in range(quote_length):\n",
    "    x = np.zeros((1, unroll, 256))\n",
    "    for t,b in enumerate(generated):\n",
    "        x[0, t, byte_idx[b]] = 1.\n",
    "\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_index = sample(preds, temperature=temp)\n",
    "    next_byte = hexabet[next_index]\n",
    "    generated = generated[1:] + [next_byte]\n",
    "\n",
    "    sys.stdout.write(unichr(int(next_byte, 16)))\n",
    "    sys.stdout.flush()\n",
    "print('\\n', '-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
