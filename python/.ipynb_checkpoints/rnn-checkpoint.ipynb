{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN model of URIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First check that Tensorflow is correctly installed and can see the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17918314026768173595\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11332668621\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 10818920902730735142\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the pre-amble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM, Recurrent\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import gzip\n",
    "import math\n",
    "\n",
    "def entropy(pred): \n",
    "    return sum([-p*math.log(p) for p in pred])\n",
    "\n",
    "def sample(a, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Samples an index from a probability array;\n",
    "    higher temperature raises the entropy and vice versa    \n",
    "    \"\"\"\n",
    "    a = np.log(a) / temperature\n",
    "    dist = np.exp(a) / np.sum(np.exp(a))\n",
    "    choices = range(len(a)) \n",
    "    return np.random.choice(choices, p=dist)\n",
    "\n",
    "def hx(i):\n",
    "    \"\"\"\n",
    "    Normalised 2-char hex representation of 0-255\n",
    "    \"\"\"\n",
    "    a = hex(i)[2:]\n",
    "    if len(a)<2: a = ''.join(['0',a])\n",
    "    return a\n",
    "\n",
    "hexabet = [hx(x) for x in range(256)]\n",
    "byte_idx = dict((c, i) for i, c in enumerate(hexabet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the domain string file for training. At present from cloned git repo. \n",
    "\n",
    "TO DO: read from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# bytes: 20000000\n",
      "\n",
      "\n",
      "/www868686.wyw.cn/ncontact_346701.html\n",
      "/wlrq.wyw.cn/tradelist_347993.html\n",
      "/BANTAI801.wyw.cn/ntrade_541599.html\n",
      "/bantai806.wyw.cn/ncontact_541502.html\n",
      "/www.snc.edu/assets2/images/socialmedia/insta.png\n",
      "/page-4403.html\n",
      "/goodlife.wyw.cn/tradelist_540770.html\n",
      "/www.snc.edu/assets2//images/socialmedia/face.png\n",
      "/C:/Users/Skipper/Google%20%E9%9B%B2%E7%AB%AF%E7%A1%AC%E7%A2%9F/%E8%BB%8D%E4%BA%8B%E5%BE%AE%E9%9D%A9%E5%91%BD/%E8%87%AA%E8%A3%BD%E6%BD%9B%E8%89%A6%E6%98%AF%E4%B8%80%E9%A0%85%E5%BF%85%E9%A0%88%E5%84%98%E6%97%A9%E8%90%BD%E5%AF%A6%E7%9A%84%E5%9C%8B%E5%AE%B6%E9%87%8D%E5%A4%A7%E6%94%BF%E7%AD%96.docx\n",
      "/www.snc.edu/assets3/images/saint.png\n",
      "/www.xe.com/es/currencycharts/\n",
      "/page-843.html\n",
      "/page-1568.html\n",
      "/page-2924.html\n",
      "/piwik.php\n",
      "/wlkcjj.wyw.cn/contact_352711.html\n",
      "/DIMA.wyw.cn/tradelist_350616.html\n",
      "/www.abc7.com/apps\n",
      "/page-59.html\n",
      "/page-5792.html\n",
      "/BANTAI801.wyw.cn/ncontact_541599.html\n",
      "/joyson.ru/\n",
      "/newpearl.wyw.cn/contact_353014.html\n",
      "/page-6947.html\n",
      "/summit.wyw.cn/contact_347098.html\n",
      "/C:/Users/dm\n"
     ]
    }
   ],
   "source": [
    "train_file = \"big_domain_string_1.gz\"\n",
    "path = \"../sdata/\"\n",
    "\n",
    "with gzip.open(path + train_file, 'rb') as f:\n",
    "    content = f.read()\n",
    "\n",
    "bytes = [b.encode('hex') for b in content][int(2e07):int(4e07)] #Â sample bytes for local testing\n",
    "#bytes = [b.encode('hex') for b in content]\n",
    "print('# bytes:', len(bytes))\n",
    "print(content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training and test strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training length: 15000000\n",
      "test length: 5000000\n"
     ]
    }
   ],
   "source": [
    "# divide into training and test sets:\n",
    "n_train = int(3*len(bytes)/4)\n",
    "text_train = bytes[0:n_train]\n",
    "text_test = bytes[n_train:len(bytes)]\n",
    "\n",
    "print('training length:', len(text_train))\n",
    "print('test length:', len(text_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut the text in semi-redundant 'sentences' of bytes, each of length <tt>unroll</tt>, and stepping forward a number <tt>step</tt> of bytes each time. \n",
    "\n",
    "These sentences are then converted into numpy arrays for RNN input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sequences: 4999994\n"
     ]
    }
   ],
   "source": [
    "unroll = 20\n",
    "step = 3\n",
    "sentences = []\n",
    "next_byte = []\n",
    "for i in range(0, n_train - unroll, step):\n",
    "    sentences.append(text_train[i: i + unroll])\n",
    "    next_byte.append(text_train[i + unroll])\n",
    "print('# sequences:', len(sentences))\n",
    "\n",
    "# convert to feature vector + next character:\n",
    "X = np.zeros((len(sentences), unroll, 256), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), 256), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t,b in enumerate(sentence):\n",
    "        X[i, t, byte_idx[b]] = 1\n",
    "    y[i, byte_idx[next_byte[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the RNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 16)                17472     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4352      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "=================================================================\n",
      "Total params: 21,824\n",
      "Trainable params: 21,824\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the model: 2 stacked LSTM\n",
    "\n",
    "nhidden = [16] # e.g. [512, 512]\n",
    "dropout = 0.1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(nhidden[0], return_sequences=False, input_shape=(unroll, 256)))\n",
    "#model.add(LSTM(nhidden[0], return_sequences=True, input_shape=(unroll, 256)))\n",
    "#model.add(Dropout(dropout))\n",
    "#model.add(LSTM(nhidden[1], return_sequences=False))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load existing weights into the model, or fit from random initialisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# either load weights:\n",
    "wt_path = \"../sdata/\"\n",
    "model.set_weights(np.load(wt_path+\"model_from_big_domain_string_1.gz_arch_16_unroll_20_step_3_dropout_0.1.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4999994/4999994 [==============================] - 1304s - loss: 2.6086  - ETA: 0s -\n",
      "Epoch 2/20\n",
      "4999994/4999994 [==============================] - 1301s - loss: 2.5842  - ETA: 0s - loss: 2.584\n",
      "Epoch 3/20\n",
      "4999994/4999994 [==============================] - 1301s - loss: 2.5756  \n",
      "Epoch 4/20\n",
      "4999994/4999994 [==============================] - 1331s - loss: 2.5701  \n",
      "Epoch 5/20\n",
      " 755840/4999994 [===>..........................] - ETA: 1107s - loss: 2.5696"
     ]
    }
   ],
   "source": [
    "# or fit and save weights:\n",
    "wt_path = \"../sdata/\"\n",
    "wt_file = \"model_from_%s_arch\" % train_file\n",
    "for i in nhidden: \n",
    "    wt_file += \"_%d\" % i\n",
    "wt_file += \"_unroll_%d_step_%d_dropout_%g.npy\" % (unroll, step, dropout)\n",
    "\n",
    "model.fit(X, y, batch_size=128, epochs=20, verbose=1)\n",
    "np.save(wt_path + wt_file, model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eyeball the model by using it to generate a stretch of synthetic domain strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --------------------------------------------------\n",
      "Seed:\n",
      "/116565_46_t.jpg\n",
      "/ho\n",
      " --------------------------------------------------\n",
      "/116565_46_t.jpg\n",
      "/horban//ortea/%707E_290063c_pumdy210bF63F973/sasmemazios/2017/04/13206s/chirhintillhes.doupdes/11_94_0255/1.html\n",
      "/alt/l0db11012/lual.jpg\n",
      "\n",
      "\n",
      "/merkinit/\n",
      "\n",
      "\n",
      "\n",
      "adf.cat-siat.janglLeax.n/ketices.pzatincober.ht\n",
      "/antro-viak/2846-kamzeithas2v-imcaenks/sou.sneo\n",
      "/fc-Canver-yhdemaseH.jpg\n",
      "/sisten/8894.tut\n",
      "/sebafoncand/mobiil-sens/ipstoyy-pova_ekuraat--matir-3a383.html\n",
      "/tended-aoptuutaal\n",
      "/dwbuntanerrativi-goony-uos\n",
      "/news/bicus/\n",
      "/dedlinqkovlhenture/sRyptuct/tag/deugp-asch9-omtoetyulered/14-fachitehtaaserel.psp\n",
      "/im411-i0.nigienceworneu.cig\n",
      "/bido/woarylarus-in8.html\n",
      "/camers-612055-cun-\n",
      "/ductufote/dse/507/\n",
      "/stotre-fymen/dlralrtmantromar/wigx/6feae/pernynesy/262215/3s-7.jpg\n",
      ".ex8.html\n",
      "/elscode/\n",
      "/mager-wathy.html\n",
      "/viter-crey-calonturats-be/xcuras/onavat-alrayhbi.jpjg\n",
      "/contantion/31-5.html\n",
      "/Sponivieric976.giedmaludmonbctonkow/ss/AnM0xtnemso_feedmsey/vics/Ps/bertie-betia-hitaer.deste/shoctotrers-wos/tuteryneqdocecakuar-misatb.gic\n",
      "/siot8Ad/pedics/bbxem_355902-11c3a-ndeaymeler.jpg\n",
      "/conssans/P/Malllorza-cirayele/091094ef-d02.jpg\n",
      "/artolg-pEg-uthysUks_ollrSm/conticte/images/AnwAB621/iptife0845/0/beddata-tp/kaanead-galey-omentinecners_gio-ir/2/2016/08/03_mmZ4z-tovid_\n",
      "/cotegramel3/svia-cencorr/scpovey/elwae\n",
      "/pidiones/wp/fodusceatien/wous.jpg\n",
      "/magessiom/18/.html\n",
      "/je-wockaddentskworhe/corcam.jpg\n",
      "/sedy/uskuri/puts\n",
      "/pllog_forighJO.jt0m5\n",
      "\n",
      "/4Affubays-rede-dutelud/lerr9-246/faniles--koulhrbOsl2acongan/Cei62319E81F27E255DTD3C67_ICks.ytdZisosXrJwC/\n",
      "/batapry-urece-oristane-bud2/-tigo/wolue-woy-tel-chonane-mari-cim-low-hord/157c0a38f39d14910aa41b0ba0-16C7145.sancimg\n",
      "/378487-193_25favb7zd/psm.jpgossauccaldar/tree/ficcics-indiele-dabnorkeluctsa-widgn-.html\n",
      "/hadactelia/.html\n",
      "/7-aanuzabild-alib0anb-lachios/6816739.html\n",
      "/torostint-homga/gesat/gusr\n",
      "/arklons/weirwsen-uagen/cersizat/nudemt/0966/S_972850e-r_Av2137Xx3_009xjnwaae.jpg\n",
      "/casc/2014/\n",
      "/prusi/betrs-inns-custurtirs/27/sholcuress-nstrody/201/bote-boakee-categeed-aduen/kad-f40/mropart/rodlorestel\n",
      "/Fa-uusele/rallepavatbe-6/70661438-tsarireli-jatolias/2/scest-saru-fy\n",
      " --------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "temp = 1.0\n",
    "quote_length = 2000\n",
    "\n",
    "# pick random:\n",
    "start = random.randint(0, len(text_test) - unroll - 1)\n",
    "init_quote = text_test[start : start + unroll]\n",
    "\n",
    "generated = init_quote\n",
    "print('\\n', '-' * 50)\n",
    "print(\"Seed:\")\n",
    "sys.stdout.write(''.join([unichr(int(h, 16)) for h in init_quote]))\n",
    "print('\\n', '-' * 50)\n",
    "sys.stdout.write(''.join([unichr(int(h, 16)) for h in generated]))\n",
    "for i in range(quote_length):\n",
    "    x = np.zeros((1, unroll, 256))\n",
    "    for t,b in enumerate(generated):\n",
    "        x[0, t, byte_idx[b]] = 1.\n",
    "\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_index = sample(preds, temperature=temp)\n",
    "    next_byte = hexabet[next_index]\n",
    "    generated = generated[1:] + [next_byte]\n",
    "\n",
    "    sys.stdout.write(unichr(int(next_byte, 16)))\n",
    "    sys.stdout.flush()\n",
    "print('\\n', '-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
