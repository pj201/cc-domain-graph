{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN model of URIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM, Recurrent\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# bytes: 1000000\n",
      "\n",
      "\n",
      "/www868686.wyw.cn/ncontact_346701.html\n",
      "/wlrq.wyw.cn/tradelist_347993.html\n",
      "/BANTAI801.wyw.cn/ntrade_541599.html\n",
      "/bantai806.wyw.cn/ncontact_541502.html\n",
      "/www.snc.edu/assets2/images/socialmedia/insta.png\n",
      "/page-4403.html\n",
      "/goodlife.wyw.cn/tradelist_540770.html\n",
      "/www.snc.edu/assets2//images/socialmedia/face.png\n",
      "/C:/Users/Skipper/Google%20%E9%9B%B2%E7%AB%AF%E7%A1%AC%E7%A2%9F/%E8%BB%8D%E4%BA%8B%E5%BE%AE%E9%9D%A9%E5%91%BD/%E8%87%AA%E8%A3%BD%E6%BD%9B%E8%89%A6%E6%98%AF%E4%B8%80%E9%A0%85%E5%BF%85%E9%A0%88%E5%84%98%E6%97%A9%E8%90%BD%E5%AF%A6%E7%9A%84%E5%9C%8B%E5%AE%B6%E9%87%8D%E5%A4%A7%E6%94%BF%E7%AD%96.docx\n",
      "/www.snc.edu/assets3/images/saint.png\n",
      "/www.xe.com/es/currencycharts/\n",
      "/page-843.html\n",
      "/page-1568.html\n",
      "/page-2924.html\n",
      "/piwik.php\n",
      "/wlkcjj.wyw.cn/contact_352711.html\n",
      "/DIMA.wyw.cn/tradelist_350616.html\n",
      "/www.abc7.com/apps\n",
      "/page-59.html\n",
      "/page-5792.html\n",
      "/BANTAI801.wyw.cn/ncontact_541599.html\n",
      "/joyson.ru/\n",
      "/newpearl.wyw.cn/contact_353014.html\n",
      "/page-6947.html\n",
      "/summit.wyw.cn/contact_347098.html\n",
      "/C:/Users/dm\n"
     ]
    }
   ],
   "source": [
    "train_file = \"big_domain_string_1.gz\"\n",
    "path = \"../sdata/\"\n",
    "\n",
    "with gzip.open(path + train_file, 'rb') as f:\n",
    "    content = f.read()\n",
    "\n",
    "bytes = [b.encode('hex') for b in content][:1000000] #Â 1 million bytes for local testing\n",
    "print('# bytes:', len(bytes))\n",
    "print(content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# distinct bytes: 172\n"
     ]
    }
   ],
   "source": [
    "chars = set(bytes)\n",
    "print('# distinct bytes:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training length: 750000\n",
      "test length: 250000\n"
     ]
    }
   ],
   "source": [
    "# divide into training and test sets:\n",
    "n_train = int(3*len(bytes)/4)\n",
    "text_train = bytes[0:n_train]\n",
    "text_test = bytes[n_train:len(bytes)]\n",
    "\n",
    "print('training length:', len(text_train))\n",
    "print('test length:', len(text_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sequences: 249994\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of 'unroll' characters\n",
    "unroll = 20\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, n_train - unroll, step):\n",
    "    sentences.append(text_train[i: i + unroll])\n",
    "    next_chars.append(text_train[i + unroll])\n",
    "print('# sequences:', len(sentences))\n",
    "\n",
    "# convert to feature vector + next character:\n",
    "X = np.zeros((len(sentences), unroll, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 16)                12096     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 172)               2924      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 172)               0         \n",
      "=================================================================\n",
      "Total params: 15,020\n",
      "Trainable params: 15,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the model: 2 stacked LSTM\n",
    "\n",
    "nhidden = [16] # e.g. [512, 512]\n",
    "dropout = 0.1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(nhidden[0], return_sequences=False, input_shape=(unroll, len(chars))))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# either load weights:\n",
    "model.set_weights(np.load(\"model_from_big_domain_string_1.gz_arch_16_unroll_20_step_3_dropout_0.1.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# or fit and save weights:\n",
    "wt_path = \"../sdata/\"\n",
    "wt_file = \"model_from_%s_arch\" % train_file\n",
    "for i in nhidden: \n",
    "    wt_file += \"_%d\" % i\n",
    "wt_file += \"_unroll_%d_step_%d_dropout_%g.npy\" % (unroll, step, dropout)\n",
    "\n",
    "model.fit(X, y, batch_size=128, epochs=10, verbose=0)\n",
    "np.save(wt_path + wt_file, model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def entropy(pred): \n",
    "    return sum([- p * math.log(p) for p in pred])\n",
    "\n",
    "def sample(a, temperature=1.0):\n",
    "    # samples an index from a probability array;\n",
    "    # higher temperature raises the entropy and vice versa\n",
    "    a = np.log(a) / temperature\n",
    "    dist = np.exp(a) / np.sum(np.exp(a))\n",
    "    choices = range(len(a)) \n",
    "    return np.random.choice(choices, p=dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --------------------------------------------------\n",
      "Seed:\n",
      "1368_1371.html\n",
      "/magi\n",
      " --------------------------------------------------\n",
      "1368_1371.html\n",
      "/magie/shrestiu-wiving-160094/29769/116143_pecs/064012100115_5460915.jpg\n",
      "/fn/689/setkitrens/paothoii-volcnere_krictamiao/andant-bigamsestis-unz-\n",
      "/sriEguras/mendides/c-corsandeft-ripal-ercipulelo-chotak-iwire-skiart-x-c-201-400141-0361894.html\n",
      "/mama//149387/9886791611136452_16869600.jpg\n",
      "/pc%838/Splorodwerice/\n",
      "/bont/satier-apranc-dormes/predadecae-chid-arttot-contens/\n",
      "/sices/irades/althen/\n",
      "/centeni.nt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "www.emabenher/\n",
      "prearenker.jpg\n",
      "/megopurals/wichectuiles/pechorce/chos/Elpoes/si-whoilamoveitotalasee-tont-262012748h/chices/\n",
      "/leshadter/Midsiodar/laogli-cevoe-sentiorivi-asstirht-chomng\n",
      "\n",
      "\n",
      "/radochht-p-ere-cort-n-nentem-patint-hochicile-ba-dartian-nesatteco-72b-3315289134-1m-shongs/\n",
      "/witat/rearichine-maba-konmo-v-chome-voc-4205803350004-0007801169.html\n",
      "/va\n",
      "/giict/7\n",
      "/acurid//casce/alax/\n",
      "/uodila/prord/01072/2051747514/60955997/b8fa_100a497.g/\n",
      "/contesturudi-ale-cirene//202387/\n",
      "/c-checterl/\n",
      "\n",
      "\n",
      "\n",
      "www.gechum-en2s/gusirele-coht-lp-ces-thur/met-alcot-nedpleuumeinag-cata/natD-0006197682\n",
      "/feresten/leert-aline-dad-el-t-300002018\n",
      "/isate-lelingimlen-gahte-/24/\n",
      "/romest14894044932016t819983229-1638550121.html\n",
      "/micow\n",
      "/sertsyigiol/\n",
      "/ior\n",
      "/oty-coreni-e-p--lnengina-llonteston-visolilankonke-splinek/\n",
      "/aetulus/ates/matid/4537/201/500/2000/310/204151200261780358bund-s-achen-picice/\n",
      "/lik/iloter/vadoa231/358269268563f90.gal\n",
      "/madag/art/\n",
      "/chimolt/cep-spor/14/\n",
      "/coct/\n",
      "/\n",
      "/propance-preuntiotie-jana-din-het-anterss-pore-b00-kihse-314849\n",
      "/la-cink-foro-288-prerlin-c-01-3576/\n",
      "/spliconinu-tand-dinstiatiliton-chotra/masesse-pherc-125/\n",
      "/clorestes/erchho-bact-songrifunle-hart-vibinawen-asite-archesmago-sss-pondts-crepy-comchechianal-sime-cileglori.htm\n",
      "/wthekt/utand/ostermerchics/\n",
      "/eeda-contentiel/\n",
      "/sums/3110/5/9b\n",
      "/windes/sOa2898300.jpg\n",
      "/kp/foragte-sole-oestale-ervice-cher-bile-focit-g-pic-in-borine-ate-poms-fimraslugent-wich-stten-gom-sototar8lalli-achpsind-achona-Ceinalr.pt\n",
      "/migelien/160406471837M.html\n",
      "/ce-couch-gecthren-uote-chst-wa-did-kicne/\n",
      "/sproruitand-a-gpri-regin-2037121316/2037001-1/amocaHimsharteles/\n",
      "/co\n",
      " --------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "temp = 0.75\n",
    "quote_length = 2000\n",
    "\n",
    "# pick random:\n",
    "start = random.randint(0, len(text_test) - unroll - 1)\n",
    "init_quote = text_test[start : start + unroll]\n",
    "\n",
    "generated = init_quote\n",
    "print('\\n', '-' * 50)\n",
    "print(\"Seed:\")\n",
    "sys.stdout.write(''.join([unichr(int(h, 16)) for h in init_quote]))\n",
    "print('\\n', '-' * 50)\n",
    "sys.stdout.write(''.join([unichr(int(h, 16)) for h in generated]))\n",
    "for i in range(quote_length):\n",
    "    x = np.zeros((1, unroll, len(chars)))\n",
    "    for t, char in enumerate(generated):\n",
    "        x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_index = sample(preds, temperature=temp)\n",
    "    next_char = indices_char[next_index]\n",
    "    generated = generated[1:] + [next_char]\n",
    "\n",
    "    sys.stdout.write(unichr(int(next_char, 16)))\n",
    "    sys.stdout.flush()\n",
    "print('\\n', '-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
