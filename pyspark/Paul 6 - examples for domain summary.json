{"paragraphs":[{"text":"%pyspark\n\n# Zeppelin notebook to extract host and in/out-link examples for each of the PLDs in the CommonCrawl webgraph\n# Complements summaries produced in 'Paul 5', and gets combined with these in 'Paul 7'.\n# Recomended config for complete run: 3xr4.8xlarge, and set spark.driver.maxResultSize to 16g\n# PJ - 30 October 2017\n\nimport boto\nfrom pyspark.sql.types import *\n\n# Load the saved files from Paul 5.\nloadURI=\"s3://billsdata.net/CommonCrawl/hyperlinkgraph/cc-main-2017-may-jun-jul/domaingraph/vertices/\"\npld_df_tmp=spark.read.load(loadURI)\npld_df=pld_df_tmp.select(pld_df_tmp.ID.cast(\"long\"),pld_df_tmp.PLD) # Cast IDs from String to LongInt\npld_df.show(3)\npld_df.cache()\n#print(pld_df.count()) # Should have 91M domains","user":"anonymous","dateUpdated":"2017-10-30T16:24:28+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---+-------+\n| ID|    PLD|\n+---+-------+\n|  0|  aaa.a|\n|  1| aaa.aa|\n|  2|aaa.aaa|\n+---+-------+\nonly showing top 3 rows\n\nDataFrame[ID: bigint, PLD: string]\n"}]},"apps":[],"jobName":"paragraph_1509377288980_-1315442660","id":"20170929-081624_672091334","dateCreated":"2017-10-30T15:28:08+0000","dateStarted":"2017-10-30T16:24:28+0000","dateFinished":"2017-10-30T16:25:21+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:196"},{"text":"%pyspark\n\n# Next import the PLD edges as a DataFrame - i.e. in/out links\nloadURI=\"s3://billsdata.net/CommonCrawl/hyperlinkgraph/cc-main-2017-may-jun-jul/domaingraph/edges/\"\npld_edges_df=spark.read.load(loadURI).limit(10000000).repartition(8) # TODO: Remove temp limit once avoiding spark context shutdown!!\npld_edges_df.show(3)\npld_edges_df.cache()","user":"anonymous","dateUpdated":"2017-10-30T16:24:28+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---+--------+\n|src|     dst|\n+---+--------+\n| 21|46356172|\n| 27|      33|\n| 27|      54|\n+---+--------+\nonly showing top 3 rows\n\nDataFrame[src: bigint, dst: bigint]\n"}]},"apps":[],"jobName":"paragraph_1509377288984_-1316981655","id":"20170929-095050_1324183281","dateCreated":"2017-10-30T15:28:08+0000","dateStarted":"2017-10-30T16:24:29+0000","dateFinished":"2017-10-30T16:25:43+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:197"},{"text":"%pyspark\n\n# Load the host-level graph vertices in the same way\nsaveURI=\"s3://billsdata.net/CommonCrawl/hyperlinkgraph/cc-main-2017-may-jun-jul/hostgraph/vertices/\"\nhost_df=spark.read.load(saveURI) #.repartition(64)\nhost_df.show(3)\nhost_df.cache()\n#print(host_df.count()) # Should have 1.3B hosts","user":"anonymous","dateUpdated":"2017-10-30T16:24:29+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------+-------+\n|hostid|   host|\n+------+-------+\n|     0|  aaa.a|\n|     1| aaa.aa|\n|     2|aaa.aaa|\n+------+-------+\nonly showing top 3 rows\n\nDataFrame[hostid: string, host: string]\n"}]},"apps":[],"jobName":"paragraph_1509377288984_-1316981655","id":"20170929-095310_1201506389","dateCreated":"2017-10-30T15:28:08+0000","dateStarted":"2017-10-30T16:25:22+0000","dateFinished":"2017-10-30T16:25:45+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:198"},{"text":"%pyspark\n\n# Debug partitioning of our 3 big dataframes\nprint(pld_df.rdd.getNumPartitions())\nprint(pld_edges_df.rdd.getNumPartitions())\nprint(host_df.rdd.getNumPartitions())","user":"anonymous","dateUpdated":"2017-10-30T16:24:29+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"128\n8\n128\n"}]},"apps":[],"jobName":"paragraph_1509377288985_-1317366404","id":"20171006-161509_1868852031","dateCreated":"2017-10-30T15:28:08+0000","dateStarted":"2017-10-30T16:25:43+0000","dateFinished":"2017-10-30T16:25:45+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:199"},{"text":"%pyspark\n\n# Create a dictionary of PLDs (for ID to PLD mapping of in/out links)\npld_dict=pld_df.rdd.collectAsMap()\n\n# Distribute and test\npld_dict_distrib=sc.broadcast(pld_dict)\nprint(pld_dict_distrib.value[2]) # Should be aaa.aaa\n","user":"anonymous","dateUpdated":"2017-10-30T16:24:29+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"aaa.aaa\n"}]},"apps":[],"jobName":"paragraph_1509377288985_-1317366404","id":"20171027-121229_2107241041","dateCreated":"2017-10-30T15:28:08+0000","dateStarted":"2017-10-30T16:25:45+0000","dateFinished":"2017-10-30T16:38:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:200"},{"text":"%pyspark\n\n# TODO: Save the map to disk for faster load next time\n#pld_dict_distrib.dump(pld_dict_distrib.value, \"s3://billsdata.net/CommonCrawl/domain_tmp_objects/pld_dict_distrib\")\n#help(pld_dict_distrib)","user":"anonymous","dateUpdated":"2017-10-30T17:20:15+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-7601759374216390521.py\", line 349, in <module>\n    [code.body[-(nhooks + 1)]])\nIndexError: list index out of range\n"}]},"apps":[],"jobName":"paragraph_1509381107393_461690837","id":"20171030-163147_643912317","dateCreated":"2017-10-30T16:31:47+0000","dateStarted":"2017-10-30T17:20:15+0000","dateFinished":"2017-10-30T17:20:15+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:201"},{"text":"%pyspark\n\n# Function to lookup and unreverse PLDs\nfrom pyspark.sql.functions import udf\ndef reverse_domain_from_ID(id):\n    domain=pld_dict_distrib.value[id]\n    return '.'.join(reversed(domain.split('.')))\nprint(reverse_domain_from_ID(2002))\nudf_reverse_domain_from_ID = udf(reverse_domain_from_ID, StringType())\n\n#  First, create a new edges dataframe consisting of unreversed PLDs\npld_edges_df2=pld_edges_df.withColumn(\"src2\",udf_reverse_domain_from_ID(\"src\")).drop(\"src\").withColumn(\"dst2\",udf_reverse_domain_from_ID(\"dst\")).drop(\"dst\")\npld_edges_df.unpersist()\npld_edges_df2.show(5)","user":"anonymous","dateUpdated":"2017-10-30T16:24:29+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"londonmet.ac\n+--------+--------------------+\n|    src2|                dst2|\n+--------+--------------------+\n|kxcr.net|    tsunamiwave.info|\n|kxcr.net|         archive.org|\n|kxcr.net|firstvoicesindige...|\n|kxcr.net|            kpft.org|\n|kxcr.net|         onbeing.org|\n+--------+--------------------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1509377288985_-1317366404","id":"20170929-095727_1596943627","dateCreated":"2017-10-30T15:28:08+0000","dateStarted":"2017-10-30T16:25:46+0000","dateFinished":"2017-10-30T16:39:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:202"},{"text":"%pyspark\n\n# Next use reduceByKey to aggregate and ensure no more than 10 per PLD - note we create a list for the map values (then + appends)\nout_degree_examples=pld_edges_df2.rdd.map(lambda x:(x['src2'],[x['dst2']])).reduceByKey(lambda acc,pld: acc if len(acc)>=10 else acc+pld)\nin_degree_examples=pld_edges_df2.rdd.map(lambda x:(x['dst2'],[x['src2']])).reduceByKey(lambda acc,pld: acc if len(acc)>=10 else acc+pld)\n\n# Convert back to dataframes\nout_schema = StructType([StructField('PLDout', StringType(), False),StructField('outLinkPLDs', StringType(), False)])\nout_degree_examples_df=out_degree_examples.toDF(out_schema)     \nin_schema = StructType([StructField('PLDin', StringType(), False),StructField('inLinkPLDs', StringType(), False)])\nin_degree_examples_df=in_degree_examples.toDF(in_schema)   \n\n# TODO: Investigate slave lost and SparkContext shut down errors with LIMIT>=10M edges above!!\n# Note that the below also works but not sure how to restrict to only 10 IDs per PLD:\n#from pyspark.sql.functions import collect_list\n#out_degree_examples=pld_edges_df.groupBy(\"src\").agg(collect_list(\"dst\"))\n\npld_edges_df2.unpersist()\nout_degree_examples_df.show(10)\nin_degree_examples_df.show(10)","user":"anonymous","dateUpdated":"2017-10-30T16:24:29+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+--------------------+\n|              PLDout|         outLinkPLDs|\n+--------------------+--------------------+\n|       sil.sp.gov.br|[jucesp.sp.gov.br...|\n|      lightop.com.br|[linekdin.com, li...|\n|     salehtex.com.br|[googleapis.com, ...|\n|  coopertalse.com.br|[facebook.com, go...|\n|      sobretv.com.br|[mulheresdemoto.c...|\n|    demanipulator.by|[msys.by, yandex.ru]|\n|  sebopapirus.com.br|[flickr.com, corr...|\n|rotarydecascaveli...|[institutorotaryb...|\n|babeldasartes.com.br|[bordadosdepassir...|\n|rafaelfelipesanto...|[instagram.com, c...|\n+--------------------+--------------------+\nonly showing top 10 rows\n\n+--------------------+--------------------+\n|               PLDin|          inLinkPLDs|\n+--------------------+--------------------+\n|forensicsciencete...|   [blogspot.com.br]|\n|  fernandooly.com.br|[blogspot.com.br,...|\n|      sushi.training|    [foods.business]|\n|         ixuepin.com|   [blogspot.com.br]|\n|aalborgnetwork.co...|[agenciaondaforte...|\n|         afmuseet.no|[aeol.com.br, han...|\n|        ericcarr.com|[blogspot.com.br,...|\n|     satellit.net.ua|[botecodoilgo.com...|\n|       sil.sp.gov.br|[acsincor.com.br,...|\n|   higherpages.co.uk|[linguagemclipper...|\n+--------------------+--------------------+\nonly showing top 10 rows\n\n"}]},"apps":[],"jobName":"paragraph_1509377288986_-1316212158","id":"20171027-140940_62611545","dateCreated":"2017-10-30T15:28:08+0000","dateStarted":"2017-10-30T16:38:08+0000","dateFinished":"2017-10-30T16:42:21+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:203"},{"text":"%pyspark\n\n# Join the In/Out-Link examples together\npld_df_joined=out_degree_examples_df.join(in_degree_examples_df, out_degree_examples_df.PLDout==in_degree_examples_df.PLDin, \"outer\").drop(\"PLDout\")\nout_degree_examples_df.unpersist()\nin_degree_examples_df.unpersist()\npld_df_joined.show(5)\npld_df_joined.cache()\npld_df_joined.count() # Should still be 91M","user":"anonymous","dateUpdated":"2017-10-30T16:24:29+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------------+--------------------+--------------------+\n|     outLinkPLDs|               PLDin|          inLinkPLDs|\n+----------------+--------------------+--------------------+\n|            null|           022af.com|      [mynew.com.br]|\n|[irradie.com.br]|100acoesparacapta...|[padrinhonota10.c...|\n|            null|       100kursov.com|   [blogspot.com.by]|\n|            null|         100news.net|     [fc-arsenal.by]|\n|            null|100porcentojeansu...|     [websim.com.br]|\n+----------------+--------------------+--------------------+\nonly showing top 5 rows\n\n2799227\n"}]},"apps":[],"jobName":"paragraph_1509377288986_-1316212158","id":"20171030-112424_1733367457","dateCreated":"2017-10-30T15:28:08+0000","dateStarted":"2017-10-30T16:39:31+0000","dateFinished":"2017-10-30T16:42:39+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:204"},{"text":"%pyspark\n\n# Debugging\n#help(collect_list(\"dst\"))\n#help(host_df.rdd.reduceByKey(lambda x,y: x+y))\nprint(\"Debug\")","user":"anonymous","dateUpdated":"2017-10-30T16:24:29+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Debug\n"}]},"apps":[],"jobName":"paragraph_1509377288987_-1316596907","id":"20171025-075140_290274377","dateCreated":"2017-10-30T15:28:08+0000","dateStarted":"2017-10-30T16:42:22+0000","dateFinished":"2017-10-30T16:42:39+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:205"},{"text":"%pyspark\n\n# Next, we'll construct a local dictionary from of all the PLDS (key is the PLD, value is the ID)\n# This is our truth-table of known PLDs that we'll use when extracting host examples\n\n# Create a bloom filter using a pure python package (might be a little slow)\nfrom pybloom import BloomFilter\npld_bf = BloomFilter(capacity=91000000, error_rate=0.005)\n\nfor row in pld_df.rdd.collect(): #.take(10000): # limit(10000000) # TODO: Still bad (and exceeds spark.driver.maxResultSize with all rows)!\n    pld_bf.add(row['PLD'])\n\n#print(pld_df.rdd.take(3))\n#print(pld_df.rdd.take(3)[2]['PLD'])\nprint(\"aaa.aaa\" in pld_bf) # Should be True\n\nimport sys\nprint(sys.getsizeof(pld_bf))\nprint(len(pld_bf)) # Should match number of items entered\n\n# Broadcast the bloom filter so it's available on all the slave nodes - we don't need to change\n# it any more so it's fine being immutable.\npld_bf_distrib=sc.broadcast(pld_bf)\n\nprint(\"aaa.aaa\" in pld_bf) # Should be true\nprint(\"aaa.aaa.bla\" in pld_bf) # Should be false\nprint(\"aaa.aaa\" in pld_bf_distrib.value) # Should be true\nprint(\"aaa.aaa.bla\" in pld_bf_distrib.value) # Should be false","user":"anonymous","dateUpdated":"2017-10-30T16:24:29+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"True\n64\n90751305\nTrue\nFalse\nTrue\nFalse\n"}]},"apps":[],"jobName":"paragraph_1509377288987_-1316596907","id":"20170929-100048_2070118110","dateCreated":"2017-10-30T15:28:08+0000","dateStarted":"2017-10-30T16:42:39+0000","dateFinished":"2017-10-30T17:09:06+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:206"},{"text":"%pyspark\n\n# Returns a Boolean to say whether PLD is a hostname in itself\ndef is_a_pld(hostname):\n    #if hostname in pld_lookup_table:\n    #if pld_lookup_table.filter(lambda a: a == hostname).count()>0:\n    if hostname in pld_bf_distrib.value:\n        return True\n    else:\n        return False\n\n# Function to do the hostname->pld conversion, if the reversed pld exists in our dictionary \ndef convert_hostname(hostname):\n    # Return hostname as-is, if this is already a PLD\n    #if hostname in pld_lookup_table:\n    #if pld_lookup_table.filter(lambda a: a == hostname).count()>0:\n    if hostname in pld_bf_distrib.value:\n        return hostname\n    # Otherwise we're going to have to split it up and test the parts\n    try:\n        parts=hostname.split('.')\n        if (len(parts)>4 and is_a_pld('.'.join(parts[0:4]))):\n            return '.'.join(parts[0:4])\n        if (len(parts)>3 and is_a_pld('.'.join(parts[0:3]))):\n            return '.'.join(parts[0:3])\n        if (len(parts)>2 and is_a_pld('.'.join(parts[0:2]))):\n            return '.'.join(parts[0:2])\n        if (len(parts)>1 and is_a_pld('.'.join(parts[0:1]))):\n            return '.'.join(parts[0:1])\n        return \"ERROR\" # Couldn't find a corresponding PLD - this should never happen!\n    except:\n        return \"ERROR\"\n        \n# Test\nprint(convert_hostname(\"aaa.aaa\"))\nprint(is_a_pld(\"aaa.aaa\")) # Should be true","user":"anonymous","dateUpdated":"2017-10-30T16:24:29+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"aaa.aaa\nTrue\n"}]},"apps":[],"jobName":"paragraph_1509377288988_-1318520651","id":"20171004-091447_4214261","dateCreated":"2017-10-30T15:28:08+0000","dateStarted":"2017-10-30T16:42:39+0000","dateFinished":"2017-10-30T17:09:06+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:207"},{"text":"%pyspark\n\n# Generate 10 host examples per PLD.\n\n# Firstly, define a reverse domain function\ndef reverse_domain(domain):\n    return '.'.join(reversed(domain.split('.')))\nprint(reverse_domain(\"com.facebook\"))\n#udf_reverse_domain = udf(reverse_domain, StringType())\n\n# Now reverse all host names after conversion to PLDs (including lookup) but prior to summarization.\n#host_example_rdd=unrev_host_df.rdd.map(lambda x: (convert_hostname(x['host']),[x['host']])).reduceByKey(lambda acc,host: acc if len(acc)>=10 else acc+host)\nhost_example_rdd=host_df.rdd.map(lambda x: (reverse_domain(convert_hostname(x['host'])),[reverse_domain(x['host'])])).reduceByKey(lambda acc,host: acc if len(acc)>=10 else acc+host)\nprint(host_example_rdd.take(20))\n\n#print(host_example_rdd.count())\n#host_df.unpersist()","user":"anonymous","dateUpdated":"2017-10-30T17:25:33+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"facebook.com\n[(u'savourea.be', [u'savourea.be']), (u'mywpm.com', [u'zdunex25.mywpm.com']), (u'autosportevents.com', [u'autosportevents.com']), (u'alsident.co.uk', [u'alsident.co.uk']), (u'agent-fashion.com', [u'agent-fashion.com']), (u'thepsychologist.com.ua', [u'thepsychologist.com.ua']), (u'modnihouse.co.kr', [u'modnihouse.co.kr']), (u'monclerjacketssales2012.com', [u'monclerjacketssales2012.com']), (u'business-co.ru', [u'business-co.ru']), (u'diyworkouts.com', [u'diyworkouts.com']), (u'dovira.kiev.ua', [u'dovira.kiev.ua']), (u'coldilamodigiovannaneri.com', [u'coldilamodigiovannaneri.com']), (u'virtualcycles.com', [u'virtualcycles.com']), (u'austinstarroofing.com', [u'austinstarroofing.com']), (u'labtechnika.sk', [u'labtechnika.sk']), (u'agapelive.co.za', [u'agapelive.co.za']), (u'mvin0smhny.com', [u'mvin0smhny.com']), (u'automotivesalesconsultantsofamerica.com', [u'automotivesalesconsultantsofamerica.com']), (u'microgrades.net', [u'microgrades.net']), (u'blackhattersguide.com', [u'blackhattersguide.com'])]\n"}]},"apps":[],"jobName":"paragraph_1509377288988_-1318520651","id":"20171004-092350_1522843259","dateCreated":"2017-10-30T15:28:08+0000","dateStarted":"2017-10-30T17:25:33+0000","dateFinished":"2017-10-30T17:51:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:208"},{"text":"%pyspark\n\n#print(host_example_rdd.take(100))\n\n# Convert host examples back to a dataframe\nout_schema = StructType([StructField('PLD', StringType(), False),StructField('hostExamples', StringType(), False)])\nhost_examples_df=host_example_rdd.toDF(out_schema) \nhost_examples_df.show(100)","user":"anonymous","dateUpdated":"2017-10-30T17:25:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+--------------------+\n|                 PLD|        hostExamples|\n+--------------------+--------------------+\n|         savourea.be|       [savourea.be]|\n|           mywpm.com|[zdunex25.mywpm.com]|\n| autosportevents.com|[autosportevents....|\n|      alsident.co.uk|    [alsident.co.uk]|\n|   agent-fashion.com| [agent-fashion.com]|\n|thepsychologist.c...|[thepsychologist....|\n|    modnihouse.co.kr|  [modnihouse.co.kr]|\n|monclerjacketssal...|[monclerjacketssa...|\n|      business-co.ru|    [business-co.ru]|\n|     diyworkouts.com|   [diyworkouts.com]|\n|      dovira.kiev.ua|    [dovira.kiev.ua]|\n|coldilamodigiovan...|[coldilamodigiova...|\n|   virtualcycles.com| [virtualcycles.com]|\n|austinstarroofing...|[austinstarroofin...|\n|      labtechnika.sk|    [labtechnika.sk]|\n|     agapelive.co.za|   [agapelive.co.za]|\n|      mvin0smhny.com|    [mvin0smhny.com]|\n|automotivesalesco...|[automotivesalesc...|\n|     microgrades.net|   [microgrades.net]|\n|blackhattersguide...|[blackhattersguid...|\n|     sexsexysexo.com|   [sexsexysexo.com]|\n|           depix.biz|         [depix.biz]|\n|       cdfanclub.com|     [cdfanclub.com]|\n|         cubagoa.com|       [cubagoa.com]|\n|texasestateofmind...|[texasestateofmin...|\n| therugcollector.com|[therugcollector....|\n|saveyoursightscre...|[saveyoursightscr...|\n|      diwali2013.org|    [diwali2013.org]|\n|         duenkhy.com|       [duenkhy.com]|\n|        inndeknip.nl|      [inndeknip.nl]|\n|   gamblechoices.com|[gamblechoices.co...|\n| arnhemcomingsoon.nl|[arnhemcomingsoon...|\n|fa5a8ntasyfootbal...|[fa5a8ntasyfootba...|\n|caja-kaeseveredel...|[caja-kaeseverede...|\n|           ahkui.com|         [ahkui.com]|\n|accademia-tripla-...|[accademia-tripla...|\n|personal-injury-r...|[personal-injury-...|\n|          cultlib.ru|        [cultlib.ru]|\n|     iwebsupport.com|[iwebsupport.com,...|\n|        bytmaster.by|      [bytmaster.by]|\n|     stopdecrisis.nu|   [stopdecrisis.nu]|\n|       ptmarquees.ie|     [ptmarquees.ie]|\n|mozaiekpetrapeete...|[mozaiekpetrapeet...|\n|arthousegalleryat...|[arthousegallerya...|\n|      montfermeil.fr|    [montfermeil.fr]|\n|   1sttrusttitle.com| [1sttrusttitle.com]|\n|             ma73.ir|           [ma73.ir]|\n|    kartikasposa.com|  [kartikasposa.com]|\n|           okigry.ga|         [okigry.ga]|\n|   selmabusiness.com| [selmabusiness.com]|\n|plainviewdogpound...|[plainviewdogpoun...|\n|          jucarne.es|        [jucarne.es]|\n|      newxboxone.com|[forum.newxboxone...|\n|    carraratiles.com|[carraratiles.com...|\n|alisonharrison.co.uk|[alisonharrison.c...|\n|        pgrotary.org|      [pgrotary.org]|\n| smallpressworld.com|[smallpressworld....|\n|         nabet18.org|       [nabet18.org]|\n|         weber-ld.de|       [weber-ld.de]|\n|             cac.mil|           [cac.mil]|\n|continuancehealth...|[continuancehealt...|\n|  summerstrust.co.uk|[summerstrust.co.uk]|\n|    rymanroofing.com|  [rymanroofing.com]|\n|        vesisorb.com|      [vesisorb.com]|\n|           beatix.nl|         [beatix.nl]|\n|          leverve.ch|        [leverve.ch]|\n|      lgnewmedia.net|    [lgnewmedia.net]|\n|     leticiareig.com|   [leticiareig.com]|\n|   trafo-programm.de| [trafo-programm.de]|\n|         resomnia.it|       [resomnia.it]|\n|       foxicon.co.za|     [foxicon.co.za]|\n|    wheyhouse.com.au|  [wheyhouse.com.au]|\n|         playford.jp|       [playford.jp]|\n|    usd482.k12.ks.us|[usd482.k12.ks.us...|\n|  auto-kaiser-elz.de|[auto-kaiser-elz.de]|\n|hotelbonaventure.com|[hotelbonaventure...|\n|       sterishoe.com|[sterishoe.com, b...|\n|question-voyance-...|[question-voyance...|\n|       davidesign.it|     [davidesign.it]|\n|        rosylips.net|      [rosylips.net]|\n|        serna.com.ua|      [serna.com.ua]|\n|          523225.vip|[523225.vip, lfyl...|\n|   colorsfestival.fi| [colorsfestival.fi]|\n|   tiptopshooter.com| [tiptopshooter.com]|\n|         sexfilm.com|       [sexfilm.com]|\n|         iran330.com|       [iran330.com]|\n|bagombergandassoc...|[bagombergandasso...|\n|  travelchinanow.com|[travelchinanow.com]|\n| responsiveninja.com|[responsiveninja....|\n|agence-immobilier...|[agence-immobilie...|\n|g725t2mm9sly10i01...|[g725t2mm9sly10i0...|\n|    gocreditshop.com|  [gocreditshop.com]|\n|beekeepingsuperst...|[beekeepingsupers...|\n|        rynoland.com|      [rynoland.com]|\n|   guide-site-web.fr| [guide-site-web.fr]|\n|    arenda-mebeli.su|  [arenda-mebeli.su]|\n|          shsbwyg.cn|        [shsbwyg.cn]|\n|    transdialogue.eu|  [transdialogue.eu]|\n|             sktd.it|[sktd.it, files.s...|\n| happytobenatural.nl|[happytobenatural...|\n+--------------------+--------------------+\nonly showing top 100 rows\n\n"}]},"apps":[],"jobName":"paragraph_1509377288988_-1318520651","id":"20171027-113721_1699720093","dateCreated":"2017-10-30T15:28:08+0000","dateStarted":"2017-10-30T17:25:48+0000","dateFinished":"2017-10-30T17:51:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:209"},{"text":"%pyspark\n\n# Join in/out-link summaries with host examples dataframe\nexample_df=pld_df_joined.join(host_examples_df, pld_df_joined.PLDin==host_examples_df.PLD, \"outer\").drop(\"PLDin\").select(\"PLD\",\"hostExamples\",\"inLinkPLDs\",\"outLinkPLDs\")\nexample_df.show(10)\nexample_df.cache()\nexample_df.count() # Should still be 91M!","user":"anonymous","dateUpdated":"2017-10-30T17:25:52+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+--------------------+----------+-----------+\n|                 PLD|        hostExamples|inLinkPLDs|outLinkPLDs|\n+--------------------+--------------------+----------+-----------+\n|0----------------...|[0---------------...|      null|       null|\n|           0-0la.com|         [0-0la.com]|      null|       null|\n|           0-3-6.com|         [0-3-6.com]|      null|       null|\n|           0-3ani.ro|         [0-3ani.ro]|      null|       null|\n|           0-5-1.com|         [0-5-1.com]|      null|       null|\n|       0-60times.net|     [0-60times.net]|      null|       null|\n|            0-744.cn|          [0-744.cn]|      null|       null|\n|0-ads-free-web-pa...|[0-ads-free-web-p...|      null|       null|\n|       0-artlove.net|     [0-artlove.net]|      null|       null|\n|  0-clubpenguin-0.tk|[0-clubpenguin-0.tk]|      null|       null|\n+--------------------+--------------------+----------+-----------+\nonly showing top 10 rows\n\n90948651\n"}]},"apps":[],"jobName":"paragraph_1509377288989_-1318905400","id":"20171012-142038_800861977","dateCreated":"2017-10-30T15:28:08+0000","dateStarted":"2017-10-30T17:51:15+0000","dateFinished":"2017-10-30T17:53:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:210"},{"text":"%pyspark\n\n# Save final table to S3 in parquet format, broken into smaller files (for fast reading into Paul 7 that will combine original summaries with examples)\noutputURI=\"s3://billsdata.net/CommonCrawl/domain_examples3/\"\ncodec=\"org.apache.hadoop.io.compress.GzipCodec\"\nexample_df.coalesce(1).write.format('com.databricks.spark.csv').options(header='true', codec=codec).save(outputURI) # Single GZIP initially for debugging\n#example_df.write.save(outputURI)","user":"anonymous","dateUpdated":"2017-10-30T17:26:01+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1509377288989_-1318905400","id":"20171018-175711_441001507","dateCreated":"2017-10-30T15:28:08+0000","dateStarted":"2017-10-30T17:51:18+0000","dateFinished":"2017-10-30T17:58:44+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:211"},{"text":"%pyspark\n","user":"anonymous","dateUpdated":"2017-10-30T16:24:29+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509377288990_-1317751153","id":"20171027-094657_452033266","dateCreated":"2017-10-30T15:28:08+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:212"}],"name":"Paul 6 - examples for domain summary","id":"2CWJDF5JB","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}