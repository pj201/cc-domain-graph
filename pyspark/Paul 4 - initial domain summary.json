{"paragraphs":[{"text":"%pyspark\n\n# Zeppelin notebook to create domain summaries based on the May/Jun/Jul 2017 CommonCrawl graph\n# as per description here: http://commoncrawl.org/2017/08/webgraph-2017-may-june-july/\n# PJ - 29 Sept 2017\n\nimport boto\nfrom pyspark.sql.types import *\n\nLIMIT=10000 # TODO - remove temporary limit to run full summaries!\n\n# Import the PLD vertices list as a DataFrame\npld_schema=StructType([StructField(\"ID\", StringType(), False), StructField(\"PLD\", StringType(), False)])\npld_txt=sc.textFile(\"s3://commoncrawl/projects/hyperlinkgraph/cc-main-2017-may-jun-jul/domaingraph/vertices.txt.gz\")\ntemp_pld = pld_txt.map(lambda k: k.split()) # By default, splits on whitespace, which is what we want\npld_df=temp_pld.toDF(pld_schema).limit(LIMIT) \npld_df.show(3)\npld_df.cache()\n# Should have 91M domains\n#print(pld_df.count())","user":"anonymous","dateUpdated":"2017-09-30T07:46:03+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---+-------+\n| ID|    PLD|\n+---+-------+\n|  0|  aaa.a|\n|  1| aaa.aa|\n|  2|aaa.aaa|\n+---+-------+\nonly showing top 3 rows\n\nDataFrame[ID: string, PLD: string]\n"}]},"apps":[],"jobName":"paragraph_1506672984373_1421865381","id":"20170929-081624_672091334","dateCreated":"2017-09-29T08:16:24+0000","dateStarted":"2017-09-30T07:46:03+0000","dateFinished":"2017-09-30T07:46:04+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:275"},{"text":"%pyspark\n\n# Next import the PLD edges as a DataFrame\npld_edges_schema=StructType([StructField(\"src\", StringType(), False), StructField(\"dst\", StringType(), False)])\npld_edges_txt=sc.textFile(\"s3://commoncrawl/projects/hyperlinkgraph/cc-main-2017-may-jun-jul/domaingraph/edges.txt.gz\")\ntemp_edges_pld = pld_edges_txt.map(lambda k: k.split()) # By default, splits on whitespace, which is what we want\npld_edges_df=temp_edges_pld.toDF(pld_edges_schema).limit(LIMIT*10) # TODO - remove temporary limit to run full summaries!\npld_edges_df.show(3)\npld_edges_df.cache()","user":"anonymous","dateUpdated":"2017-09-30T07:46:04+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---+--------+\n|src|     dst|\n+---+--------+\n|  2| 9193244|\n| 20|75600973|\n| 21|46356172|\n+---+--------+\nonly showing top 3 rows\n\nDataFrame[src: string, dst: string]\n"}]},"apps":[],"jobName":"paragraph_1506678650945_997871790","id":"20170929-095050_1324183281","dateCreated":"2017-09-29T09:50:50+0000","dateStarted":"2017-09-30T07:46:04+0000","dateFinished":"2017-09-30T07:46:04+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:276"},{"text":"%pyspark\n\n# Load the host-level graph vertices in the same way\nhost_schema=StructType([StructField(\"hostid\", StringType(), False), StructField(\"host\", StringType(), False)])\nhost_txt=sc.textFile(\"s3://commoncrawl/projects/hyperlinkgraph/cc-main-2017-may-jun-jul/hostgraph/vertices.txt.gz\")\ntemp_host = host_txt.map(lambda k: k.split()) # By default, splits on whitespace, which is what we want\nhost_df=temp_host.toDF(host_schema).limit(LIMIT*10) # TODO - remove temporary limit to run full summaries!\nhost_df.show(3)\nhost_df.cache()\n# Should have 1.3B hosts\n#print(host_df.count())","user":"anonymous","dateUpdated":"2017-09-30T07:46:04+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------+-------+\n|hostid|   host|\n+------+-------+\n|     0|  aaa.a|\n|     1| aaa.aa|\n|     2|aaa.aaa|\n+------+-------+\nonly showing top 3 rows\n\nDataFrame[hostid: string, host: string]\n"}]},"apps":[],"jobName":"paragraph_1506678790693_989189487","id":"20170929-095310_1201506389","dateCreated":"2017-09-29T09:53:10+0000","dateStarted":"2017-09-30T07:46:04+0000","dateFinished":"2017-09-30T07:46:05+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:277"},{"text":"%pyspark\n\n# Load in harmonic centrality and page-ranks, and join based on reverse domain name\n# Format: #hc_pos #hc_val #pr_pos #pr_val #host_rev\n#pr_schema=StructType([StructField(\"hc_pos\", StringType(), False), StructField(\"hc_val\", StringType(), False), StructField(\"pr_pos\", StringType(), False), StructField(\"pr_val\", StringType(), False), StructField(\"host_rev\", StringType(), False)])\npr_txt=sc.textFile(\"s3://commoncrawl/projects/hyperlinkgraph/cc-main-2017-may-jun-jul/domaingraph/ranks.txt.gz\")\nheader=pr_txt.first()\npr_txt=pr_txt.filter(lambda x: x!=header)\ntemp_pr = pr_txt.map(lambda k: k.split()) # By default, splits on whitespace, which is what we want\npr_df=temp_pr.toDF(header.split()).limit(LIMIT*100).withColumnRenamed(\"#host_rev\",\"host_rev\") # TODO - remove temporary limit to run full summaries!\npr_df.show(3)\npr_df.cache()\n#pr_df.count() # Should be 91M","user":"anonymous","dateUpdated":"2017-09-30T07:46:05+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+--------+-------+-------------------+--------------+\n|#hc_pos| #hc_val|#pr_pos|            #pr_val|      host_rev|\n+-------+--------+-------+-------------------+--------------+\n|      1|24989952|      1| 0.0155264576161686|  com.facebook|\n|      2|22460880|      3|0.00866038900847366|   com.twitter|\n|      3|22097514|      2| 0.0128827315785546|com.googleapis|\n+-------+--------+-------+-------------------+--------------+\nonly showing top 3 rows\n\nDataFrame[#hc_pos: string, #hc_val: string, #pr_pos: string, #pr_val: string, host_rev: string]\n"}]},"apps":[],"jobName":"paragraph_1506677522272_-1462345956","id":"20170929-093202_1772383833","dateCreated":"2017-09-29T09:32:02+0000","dateStarted":"2017-09-30T07:46:05+0000","dateFinished":"2017-09-30T07:46:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:278"},{"text":"%pyspark #--packages graphframes:graphframes:0.5.0-spark2.1-s_2.11\n\n# We now have everything we need in these four dataframes to create the summaries based on joins and counts... it's just going to take a while!\n\n# First, let's compute the in-degree and out-degree for each PLD, using GraphFrames\n\n# Rename from_id and to_id in edges to src and dst for GraphFrame\n#pld_edges_df2 = pld_edges_df.select(col(\"from_id\").alias(\"src\"), col(\"to_id\").alias(\"dst\"))\n# Make a GraphFrame and compute in-degrees\n#g = GraphFrame(pld_df, pld_edges_df2)\n#g.inDegrees.show(5)\n\n# TODO: Figure out how to use GraphFrames with Zeppelin!\nprint(\"TODO!\")","user":"anonymous","dateUpdated":"2017-09-30T07:46:05+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"TODO!\n"}]},"apps":[],"jobName":"paragraph_1506679047956_-8669083","id":"20170929-095727_1596943627","dateCreated":"2017-09-29T09:57:27+0000","dateStarted":"2017-09-30T07:46:05+0000","dateFinished":"2017-09-30T07:46:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:279"},{"text":"%pyspark\n\n# Next, let's count the number of host domains for each PLD, based on joining the host and PLD vertex data frames\nfrom pyspark.sql.functions import concat, col, when, lit\n# TODO: This is slow because it doesn't exploit the host ordering!\npld_df_tmp=pld_df.join(host_df,(host_df.host==pld_df.PLD) | (host_df.host.startswith(concat(pld_df.PLD, lit(\".\"))) ),'rightouter') # Join based on exact match, or PLD + \".\"\npld_df_tmp.show(10)\nhost_counts=pld_df_tmp.groupBy(\"PLD\").count() # Counts total number of hosts, including when host==PLD\nhost_counts.show(10)\n# Now rejoin the host counts with our original dataframe\npld_df_joined=pld_df.join(host_counts, pld_df.PLD==host_counts.PLD).drop(pld_df.PLD).withColumnRenamed(\"count\",\"NumHosts\")\npld_df_joined.show(100)\npld_df_joined.cache()\n","user":"anonymous","dateUpdated":"2017-09-30T07:46:15+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---+--------+------+-----------------+\n| ID|     PLD|hostid|             host|\n+---+--------+------+-----------------+\n|  0|   aaa.a|     0|            aaa.a|\n|  1|  aaa.aa|     1|           aaa.aa|\n|  2| aaa.aaa|     2|          aaa.aaa|\n|  2| aaa.aaa|     3|      aaa.aaa.aaa|\n|  2| aaa.aaa|     4|  aaa.aaa.aaa.aaa|\n|  2| aaa.aaa|     5| aaa.aaa.aaa.next|\n|  2| aaa.aaa|     6|aaa.aaa.aaa.other|\n|  2| aaa.aaa|     7|     aaa.aaa.aaaa|\n|  3|aaa.aaaa|     8|         aaa.aaaa|\n|  3|aaa.aaaa|     9|     aaa.aaaa.aaa|\n+---+--------+------+-----------------+\nonly showing top 10 rows\n\n+--------------------+-----+\n|                 PLD|count|\n+--------------------+-----+\n|             abc.web|    1|\n|             ac.8411|    1|\n|              ac.bgc|    1|\n|          ac.casinos|    1|\n|ac.cosmopolitanun...|    1|\n|            ac.dibru|    1|\n|          ac.gorilla|    1|\n|          ac.philter|    1|\n|              ac.ula|    1|\n|         ac.umedalen|    2|\n+--------------------+-----+\nonly showing top 10 rows\n\n+----+--------------------+--------+\n|  ID|                 PLD|NumHosts|\n+----+--------------------+--------+\n| 120|             abc.web|       1|\n| 311|             ac.8411|       1|\n| 713|              ac.bgc|       1|\n| 871|          ac.casinos|       1|\n|1014|ac.cosmopolitanun...|       1|\n|1089|            ac.dibru|       1|\n|1435|          ac.gorilla|       1|\n|2476|          ac.philter|       1|\n|3138|              ac.ula|       1|\n|3145|         ac.umedalen|       2|\n|3373|              ac.yui|       2|\n|3484|   academy.alphastar|       1|\n|3768|    academy.cirulnik|       1|\n|3787|       academy.cocoa|       1|\n|3882|academy.dental-coach|       1|\n|4157|         academy.ger|       1|\n|4410|academy.investmen...|       2|\n|4769|     academy.newtown|       1|\n|5224|        academy.talk|       2|\n|6064|accountant.buy-mo...|       1|\n|6198|accountant.buyfur...|       1|\n|6445|     accountant.c0eu|       4|\n|6483|accountant.canadi...|       1|\n|6776|    accountant.czmht|       1|\n|6826|accountant.devoch...|       1|\n|6863|   accountant.dkeiil|       1|\n|7269|accountant.generi...|       1|\n|7285|accountant.generi...|       1|\n|7369|  accountant.gvykeed|       3|\n|7386|    accountant.hbpnj|       1|\n|7412|accountant.hghgro...|       1|\n|8048|accountant.online...|       1|\n|8236|   accountant.petoug|       6|\n|8417|  accountant.rhjmheq|       3|\n|8482|  accountant.semdzof|       1|\n|8769|accountant.tradin...|       1|\n|8857|   accountant.ukobis|       1|\n|8937|    accountant.vhmfv|       3|\n|8975|accountant.viagra...|       1|\n|9241|   accountant.zgstbs|       1|\n|9342|aco.architekten-p...|       1|\n|9498|             ad.2005|       1|\n|9552|              ad.acg|       1|\n|9793|            ad.ashme|       1|\n|9815|         ad.auditori|       1|\n|9910|       ad.bio-centre|       1|\n|9914|     ad.blatantmedia|       1|\n|7863|  accountant.mm370cr|       1|\n|  70|               abc.b|       1|\n| 404|             ac.aero|       1|\n| 451|             ac.alfa|       1|\n| 472|          ac.ambrosi|       1|\n| 675|             ac.base|       1|\n| 736|              ac.biz|       1|\n|1214|           ac.edubee|       1|\n|2047|            ac.magic|       2|\n|2183|      ac.mp3download|       1|\n|2341|           ac.nurden|       1|\n|2605|              ac.rdg|       3|\n|2956|ac.supreme-2007-d...|       1|\n|3106|           ac.uchida|       1|\n|3459|academy.agribusiness|       2|\n|3531|        academy.arks|       1|\n|3615|      academy.bemore|       1|\n|3855|        academy.dama|       1|\n|3861| academy.dariuslukas|       1|\n|3993|    academy.eloboost|       1|\n|4059|academy.fearlesss...|       1|\n|4166|       academy.ghost|       1|\n|4224|     academy.growthx|       1|\n|4259|    academy.heeldier|       1|\n|4278|         academy.hip|       1|\n|4367|   academy.incubator|       3|\n|4442|      academy.janson|       1|\n|4536|       academy.later|       1|\n|4588|        academy.livi|       1|\n|4668|academy.mercurypr...|       1|\n|4749|  academy.nadabrahma|       1|\n|5551|     accountant.3l79|       3|\n|5624|accountant.acompl...|       1|\n|5634|accountant.adocto...|       1|\n|5688|   accountant.alyans|       1|\n|5830|    accountant.bazjk|       1|\n|6257|accountant.buypre...|       1|\n|6310|accountant.buyvas...|       1|\n|6679|accountant.clarke...|       1|\n|6811|accountant.demo-f...|       1|\n|6878| accountant.donyasas|       1|\n|6886| accountant.downhedt|       1|\n|7348|accountant.glucop...|       1|\n|7411|    accountant.hfyvr|       3|\n|7498|accountant.infore...|       1|\n|7674|accountant.la-fucker|      18|\n|7862|    accountant.mksye|       1|\n|8006|   accountant.odocet|       1|\n|8371|    accountant.qoxjb|       1|\n|8455|    accountant.rwxtb|       1|\n|8762|accountant.tousac...|       1|\n|8828|     accountant.ubuc|       1|\n|8918|    accountant.vcvqv|       3|\n+----+--------------------+--------+\nonly showing top 100 rows\n\nDataFrame[ID: string, PLD: string, NumHosts: bigint]\n"}]},"apps":[],"jobName":"paragraph_1506679248984_1301075826","id":"20170929-100048_2070118110","dateCreated":"2017-09-29T10:00:48+0000","dateStarted":"2017-09-30T07:46:15+0000","dateFinished":"2017-09-30T07:50:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:280"},{"text":"%pyspark\n\n# Next, compute whether each pld appears as a host by itself using a leftOuter join and append as an extra column\nfrom pyspark.sql.functions import col, when, lit\npld_host_test = when(col(\"host\").isNull(), lit(\"false\")).otherwise(lit(\"true\"))\npld_df_joined2=pld_df_joined.join(host_df, pld_df_joined.PLD==host_df.host, 'leftOuter').drop(\"hostid\").withColumn('PLDisHost?', pld_host_test).drop(\"host\")\npld_df_joined2.sort(\"NumHosts\", ascending=False).show(20)\npld_df_joined2.cache()\n#pld_df_joined2.groupBy(\"PLDisHost?\").count().show()","user":"anonymous","dateUpdated":"2017-09-30T07:46:03+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----+--------------------+--------+----------+\n|  ID|                 PLD|NumHosts|PLDisHost?|\n+----+--------------------+--------+----------+\n|1426|              ac.goe|    4106|      true|\n|6750|    accountant.cp613|     691|      true|\n|6749|    accountant.cp568|     691|      true|\n|1339|            ac.forum|     362|      true|\n|8874|accountant.unlock...|     272|      true|\n|3027|             ac.thai|     249|      true|\n|8873|accountant.unlockpro|     222|      true|\n|3178|              ac.uoj|     169|      true|\n|1919|            ac.labos|     121|      true|\n|1715|           ac.island|      95|      true|\n|4454|         academy.jnv|      83|      true|\n|9328|  accountants.portal|      67|      true|\n|1095|ac.digitaluniversity|      53|      true|\n|1534|          ac.hoikuen|      47|     false|\n|2347|           ac.o-hara|      40|      true|\n|2624|          ac.regency|      33|      true|\n| 383|              ac.acs|      33|      true|\n|1734|             ac.itss|      31|     false|\n|3088|              ac.tyo|      30|      true|\n|1830|              ac.kcu|      28|      true|\n+----+--------------------+--------+----------+\nonly showing top 20 rows\n\nDataFrame[ID: string, PLD: string, NumHosts: bigint, PLDisHost?: string]\n"}]},"apps":[],"jobName":"paragraph_1506676503325_-1252325607","id":"20170929-091503_880987778","dateCreated":"2017-09-29T09:15:03+0000","dateStarted":"2017-09-30T07:46:16+0000","dateFinished":"2017-09-30T07:52:30+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:281"},{"text":"%pyspark\n\n# Next, join with the harmonic centrality and page-rank for each domain\npld_df_joined3=pld_df_joined2.join(pr_df, pr_df.host_rev==pld_df_joined2.PLD, \"leftOuter\").drop(\"#hc_pos\").drop(\"#pr_pos\").drop(\"host_rev\").withColumnRenamed(\"#hc_val\",\"HarmonicCentrality\").withColumnRenamed(\"#pr_val\",\"PageRank\")\npld_df_joined3.show(20)\npld_df_joined3.cache()","user":"anonymous","dateUpdated":"2017-09-30T07:46:03+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----+--------------------+--------+----------+------------------+--------+\n|  ID|                 PLD|NumHosts|PLDisHost?|HarmonicCentrality|PageRank|\n+----+--------------------+--------+----------+------------------+--------+\n| 120|             abc.web|       1|     false|              null|    null|\n| 311|             ac.8411|       1|     false|              null|    null|\n| 713|              ac.bgc|       1|     false|              null|    null|\n| 871|          ac.casinos|       1|      true|              null|    null|\n|1014|ac.cosmopolitanun...|       1|      true|              null|    null|\n|1089|            ac.dibru|       1|      true|              null|    null|\n|1435|          ac.gorilla|       1|      true|              null|    null|\n|2476|          ac.philter|       1|      true|              null|    null|\n|3138|              ac.ula|       1|     false|              null|    null|\n|3145|         ac.umedalen|       2|      true|              null|    null|\n|3373|              ac.yui|       2|      true|              null|    null|\n|3484|   academy.alphastar|       1|      true|              null|    null|\n|3768|    academy.cirulnik|       1|      true|              null|    null|\n|3787|       academy.cocoa|       1|      true|              null|    null|\n|3882|academy.dental-coach|       1|      true|              null|    null|\n|4157|         academy.ger|       1|      true|              null|    null|\n|4410|academy.investmen...|       2|      true|              null|    null|\n|4769|     academy.newtown|       1|      true|              null|    null|\n|5224|        academy.talk|       2|      true|              null|    null|\n|6064|accountant.buy-mo...|       1|      true|              null|    null|\n+----+--------------------+--------+----------+------------------+--------+\nonly showing top 20 rows\n\nDataFrame[ID: string, PLD: string, NumHosts: bigint, PLDisHost?: string, HarmonicCentrality: string, PageRank: string]\n"}]},"apps":[],"jobName":"paragraph_1506687940382_587577792","id":"20170929-122540_264490752","dateCreated":"2017-09-29T12:25:40+0000","dateStarted":"2017-09-30T07:50:15+0000","dateFinished":"2017-09-30T07:52:44+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:282"},{"text":"%pyspark\n\n# Save final table to S3 in compressed CSV format\noutputURI=\"s3://billsdata.net/CommonCrawl/domain_summaries/\"\ncodec=\"org.apache.hadoop.io.compress.GzipCodec\"\npld_df_joined3.coalesce(1).write.format('com.databricks.spark.csv').options(header='true', codec=codec).save(outputURI)","user":"anonymous","dateUpdated":"2017-09-30T07:46:03+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1506688714184_1025528188","id":"20170929-123834_882164555","dateCreated":"2017-09-29T12:38:34+0000","dateStarted":"2017-09-30T07:52:31+0000","dateFinished":"2017-09-30T07:52:51+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:283","results":{"code":"SUCCESS","msg":[]}},{"text":"%pyspark\n","user":"anonymous","dateUpdated":"2017-09-29T13:39:55+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1506690701711_-954353546","id":"20170929-131141_1281692933","dateCreated":"2017-09-29T13:11:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:284"}],"name":"Paul 4 - initial domain summary","id":"2CUW8R7WT","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}