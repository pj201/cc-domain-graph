{"paragraphs":[{"text":"%pyspark\n\n# Zeppelin notebook to create domain summaries based on the May/Jun/Jul 2017 CommonCrawl graph\n# as per description here: http://commoncrawl.org/2017/08/webgraph-2017-may-june-july/\n# PJ - 29 Sept 2017\n\nimport boto\nfrom pyspark.sql.types import *\n\nLIMIT=100000 # TODO - remove temporary limit to run full summaries!\n\n# Import the PLD vertices list as a DataFrame\npld_schema=StructType([StructField(\"ID\", StringType(), False), StructField(\"PLD\", StringType(), False)])\npld_txt=sc.textFile(\"s3://commoncrawl/projects/hyperlinkgraph/cc-main-2017-may-jun-jul/domaingraph/vertices.txt.gz\")\ntemp_pld = pld_txt.map(lambda k: k.split()) # By default, splits on whitespace, which is what we want\npld_df=temp_pld.toDF(pld_schema).limit(LIMIT) \npld_df.show(3)\npld_df.cache()\n# Should have 91M domains\n#print(pld_df.count())","user":"anonymous","dateUpdated":"2017-09-30T11:41:38+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---+-------+\n| ID|    PLD|\n+---+-------+\n|  0|  aaa.a|\n|  1| aaa.aa|\n|  2|aaa.aaa|\n+---+-------+\nonly showing top 3 rows\n\nDataFrame[ID: string, PLD: string]\n"}]},"apps":[],"jobName":"paragraph_1506758839614_22781068","id":"20170929-081624_672091334","dateCreated":"2017-09-30T08:07:19+0000","dateStarted":"2017-09-30T11:41:38+0000","dateFinished":"2017-09-30T11:41:39+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:390"},{"text":"%pyspark\n\n# Next import the PLD edges as a DataFrame\npld_edges_schema=StructType([StructField(\"src\", StringType(), False), StructField(\"dst\", StringType(), False)])\npld_edges_txt=sc.textFile(\"s3://commoncrawl/projects/hyperlinkgraph/cc-main-2017-may-jun-jul/domaingraph/edges.txt.gz\")\ntemp_edges_pld = pld_edges_txt.map(lambda k: k.split()) # By default, splits on whitespace, which is what we want\npld_edges_df=temp_edges_pld.toDF(pld_edges_schema).limit(LIMIT*10) # TODO - remove temporary limit to run full summaries!\npld_edges_df.show(3)\npld_edges_df.cache()","user":"anonymous","dateUpdated":"2017-09-30T11:41:38+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---+--------+\n|src|     dst|\n+---+--------+\n|  2| 9193244|\n| 20|75600973|\n| 21|46356172|\n+---+--------+\nonly showing top 3 rows\n\nDataFrame[src: string, dst: string]\n"}]},"apps":[],"jobName":"paragraph_1506758839620_6621614","id":"20170929-095050_1324183281","dateCreated":"2017-09-30T08:07:19+0000","dateStarted":"2017-09-30T11:41:38+0000","dateFinished":"2017-09-30T11:41:39+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:391"},{"text":"%pyspark\n\n# Load the host-level graph vertices in the same way\nhost_schema=StructType([StructField(\"hostid\", StringType(), False), StructField(\"host\", StringType(), False)])\nhost_txt=sc.textFile(\"s3://commoncrawl/projects/hyperlinkgraph/cc-main-2017-may-jun-jul/hostgraph/vertices.txt.gz\")\ntemp_host = host_txt.map(lambda k: k.split()) # By default, splits on whitespace, which is what we want\nhost_df=temp_host.toDF(host_schema).limit(LIMIT*10) # TODO - remove temporary limit to run full summaries!\nhost_df.show(3)\nhost_df.cache()\n# Should have 1.3B hosts\n#print(host_df.count())","user":"anonymous","dateUpdated":"2017-09-30T11:41:38+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------+-------+\n|hostid|   host|\n+------+-------+\n|     0|  aaa.a|\n|     1| aaa.aa|\n|     2|aaa.aaa|\n+------+-------+\nonly showing top 3 rows\n\nDataFrame[hostid: string, host: string]\n"}]},"apps":[],"jobName":"paragraph_1506758839621_6236865","id":"20170929-095310_1201506389","dateCreated":"2017-09-30T08:07:19+0000","dateStarted":"2017-09-30T11:41:39+0000","dateFinished":"2017-09-30T11:41:40+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:392"},{"text":"%pyspark\n\n# Load in harmonic centrality and page-ranks, and join based on reverse domain name\n# Format: #hc_pos #hc_val #pr_pos #pr_val #host_rev\n#pr_schema=StructType([StructField(\"hc_pos\", StringType(), False), StructField(\"hc_val\", StringType(), False), StructField(\"pr_pos\", StringType(), False), StructField(\"pr_val\", StringType(), False), StructField(\"host_rev\", StringType(), False)])\npr_txt=sc.textFile(\"s3://commoncrawl/projects/hyperlinkgraph/cc-main-2017-may-jun-jul/domaingraph/ranks.txt.gz\")\nheader=pr_txt.first()\npr_txt=pr_txt.filter(lambda x: x!=header)\ntemp_pr = pr_txt.map(lambda k: k.split()) # By default, splits on whitespace, which is what we want\npr_df=temp_pr.toDF(header.split()).limit(LIMIT*100).withColumnRenamed(\"#host_rev\",\"host_rev\") # TODO - remove temporary limit to run full summaries!\npr_df.show(3)\npr_df.cache()\n#pr_df.count() # Should be 91M","user":"anonymous","dateUpdated":"2017-09-30T11:41:38+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+--------+-------+-------------------+--------------+\n|#hc_pos| #hc_val|#pr_pos|            #pr_val|      host_rev|\n+-------+--------+-------+-------------------+--------------+\n|      1|24989952|      1| 0.0155264576161686|  com.facebook|\n|      2|22460880|      3|0.00866038900847366|   com.twitter|\n|      3|22097514|      2| 0.0128827315785546|com.googleapis|\n+-------+--------+-------+-------------------+--------------+\nonly showing top 3 rows\n\nDataFrame[#hc_pos: string, #hc_val: string, #pr_pos: string, #pr_val: string, host_rev: string]\n"}]},"apps":[],"jobName":"paragraph_1506758839622_7391112","id":"20170929-093202_1772383833","dateCreated":"2017-09-30T08:07:19+0000","dateStarted":"2017-09-30T11:41:40+0000","dateFinished":"2017-09-30T11:43:26+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:393"},{"text":"%pyspark #--packages graphframes:graphframes:0.5.0-spark2.1-s_2.11\n\n# We now have everything we need in these four dataframes to create the summaries based on joins and counts... it's just going to take a while!\n\n# First, let's compute the in-degree and out-degree for each PLD, using GraphFrames\n\n# Rename from_id and to_id in edges to src and dst for GraphFrame\n#pld_edges_df2 = pld_edges_df.select(col(\"from_id\").alias(\"src\"), col(\"to_id\").alias(\"dst\"))\n# Make a GraphFrame and compute in-degrees\n#g = GraphFrame(pld_df, pld_edges_df2)\n#g.inDegrees.show(5)\n\n# TODO: Figure out how to use GraphFrames with Zeppelin!\nprint(\"TODO!\")","user":"anonymous","dateUpdated":"2017-09-30T11:41:38+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"TODO!\n"}]},"apps":[],"jobName":"paragraph_1506758839623_7006363","id":"20170929-095727_1596943627","dateCreated":"2017-09-30T08:07:19+0000","dateStarted":"2017-09-30T11:41:40+0000","dateFinished":"2017-09-30T11:43:26+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:394"},{"text":"%pyspark\n\n# Next, let's count the number of host domains for each PLD, based on joining the host and PLD vertex data frames\nfrom pyspark.sql.functions import concat, col, when, lit\n# TODO: This is slow because it doesn't exploit the host ordering!\npld_df_tmp=pld_df.join(host_df,(host_df.host==pld_df.PLD) | (host_df.host.startswith(concat(pld_df.PLD, lit(\".\"))) ),'rightouter') # Join based on exact match, or PLD + \".\"\npld_df_tmp.show(10)\nhost_counts=pld_df_tmp.groupBy(\"PLD\").count() # Counts total number of hosts, including when host==PLD\nhost_counts.show(10)\n# Now rejoin the host counts with our original dataframe\npld_df_joined=pld_df.join(host_counts, pld_df.PLD==host_counts.PLD).drop(pld_df.PLD).withColumnRenamed(\"count\",\"NumHosts\")\npld_df_joined.show(100)\npld_df_joined.cache()\n","user":"anonymous","dateUpdated":"2017-09-30T11:41:38+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---+--------+------+-----------------+\n| ID|     PLD|hostid|             host|\n+---+--------+------+-----------------+\n|  0|   aaa.a|     0|            aaa.a|\n|  1|  aaa.aa|     1|           aaa.aa|\n|  2| aaa.aaa|     2|          aaa.aaa|\n|  2| aaa.aaa|     3|      aaa.aaa.aaa|\n|  2| aaa.aaa|     4|  aaa.aaa.aaa.aaa|\n|  2| aaa.aaa|     5| aaa.aaa.aaa.next|\n|  2| aaa.aaa|     6|aaa.aaa.aaa.other|\n|  2| aaa.aaa|     7|     aaa.aaa.aaaa|\n|  3|aaa.aaaa|     8|         aaa.aaaa|\n|  3|aaa.aaaa|     9|     aaa.aaaa.aaa|\n+---+--------+------+-----------------+\nonly showing top 10 rows\n\n+--------------------+-----+\n|                 PLD|count|\n+--------------------+-----+\n|             abc.web|    1|\n|             ac.8411|    1|\n|              ac.bgc|    1|\n|          ac.casinos|    1|\n|ac.cosmopolitanun...|    1|\n|            ac.dibru|    1|\n|          ac.gorilla|    1|\n|          ac.philter|    1|\n|              ac.ula|    1|\n|         ac.umedalen|    2|\n+--------------------+-----+\nonly showing top 10 rows\n\n+-----+--------------------+--------+\n|   ID|                 PLD|NumHosts|\n+-----+--------------------+--------+\n|  120|             abc.web|       1|\n|  311|             ac.8411|       1|\n|  713|              ac.bgc|       1|\n|  871|          ac.casinos|       1|\n| 1014|ac.cosmopolitanun...|       1|\n| 1089|            ac.dibru|       1|\n| 1435|          ac.gorilla|       1|\n| 2476|          ac.philter|       1|\n| 3138|              ac.ula|       1|\n| 3145|         ac.umedalen|       2|\n| 3373|              ac.yui|       2|\n| 3484|   academy.alphastar|       1|\n| 3768|    academy.cirulnik|       1|\n| 3787|       academy.cocoa|       1|\n| 3882|academy.dental-coach|       1|\n| 4157|         academy.ger|       1|\n| 4410|academy.investmen...|       2|\n| 4769|     academy.newtown|       1|\n| 5224|        academy.talk|       2|\n| 6064|accountant.buy-mo...|       1|\n| 6198|accountant.buyfur...|       1|\n| 6445|     accountant.c0eu|       4|\n| 6483|accountant.canadi...|       1|\n| 6776|    accountant.czmht|       1|\n| 6826|accountant.devoch...|       1|\n| 6863|   accountant.dkeiil|       1|\n| 7269|accountant.generi...|       1|\n| 7285|accountant.generi...|       1|\n| 7369|  accountant.gvykeed|       3|\n| 7386|    accountant.hbpnj|       1|\n| 7412|accountant.hghgro...|       1|\n| 8048|accountant.online...|       1|\n| 8236|   accountant.petoug|       6|\n| 8417|  accountant.rhjmheq|       3|\n| 8482|  accountant.semdzof|       1|\n| 8769|accountant.tradin...|       1|\n| 8857|   accountant.ukobis|       1|\n| 8937|    accountant.vhmfv|       3|\n| 8975|accountant.viagra...|       1|\n| 9241|   accountant.zgstbs|       1|\n| 9342|aco.architekten-p...|       1|\n| 9498|             ad.2005|       1|\n| 9552|              ad.acg|       1|\n| 9793|            ad.ashme|       1|\n| 9815|         ad.auditori|       1|\n| 9910|       ad.bio-centre|       1|\n| 9914|     ad.blatantmedia|       1|\n|10157|        ad.crowdland|       1|\n|10254|       ad.eatupthero|       1|\n|10377|             ad.feva|       1|\n|11022|            ad.piman|       1|\n|11373|           ad.tennis|       1|\n|11423|           ad.tshirt|       1|\n|11478|         ad.verisure|       1|\n|11662|     adult.education|       1|\n|11680|      adult.milftube|       1|\n|12617|    ae.advancevision|       1|\n|13502|   ae.almutahedgroup|       1|\n|14070|      ae.antennariid|       1|\n|14106|              ae.aol|       1|\n|14213|        ae.aquametro|       1|\n|14562|         ae.ascdubai|       1|\n|14996|     ae.backtoscahoo|       1|\n|15062|     ae.baloskionace|       1|\n|15121|        ae.bartscher|       1|\n|15491|        ae.bitstream|       1|\n|15547|      ae.bloggerspot|       1|\n|16453|         ae.chatspin|       1|\n|16576|        ae.cirocaffe|       1|\n|16689|       ae.climatexpo|       1|\n|16763|     ae.co.adonc-dis|       1|\n|17248| ae.co.sadiqbrothers|       1|\n|17253|          ae.co.satt|       1|\n|17333|           ae.co.uic|       1|\n|17401|          ae.collage|       1|\n|17558|       ae.copenhagen|       1|\n|17965|              ae.dat|       1|\n|18197|   ae.designandprint|       1|\n|18376|        ae.diglossia|       1|\n|18534|       ae.dollarauto|       1|\n|18713|              ae.dsc|       1|\n|19224|             ae.ears|       1|\n|19731|         ae.emirates|       1|\n|19749|    ae.emiratesboats|       1|\n|19869|           ae.empost|       1|\n|19884|           ae.emtech|       2|\n|20391|           ae.ezajel|       1|\n|21102|ae.furnitureabudhabi|       1|\n|21273|        ae.gboslaser|       1|\n|21559|ae.gluten-free-su...|       1|\n|21847|      ae.gov.economy|       2|\n|22069|    ae.gov.shjmuseum|       1|\n|22106|     ae.gov.uae-icao|       1|\n|22419|  ae.gwgonlinedegree|       1|\n|22525| ae.hamriyahfreezone|       1|\n|22815|      ae.hobbycentre|       1|\n|22893|   ae.horizonacademy|       1|\n|23128|            ae.iceme|       1|\n|23266|             ae.iicd|       1|\n|23691|             ae.iris|       1|\n+-----+--------------------+--------+\nonly showing top 100 rows\n\nDataFrame[ID: string, PLD: string, NumHosts: bigint]\n"}]},"apps":[],"jobName":"paragraph_1506758839623_7006363","id":"20170929-100048_2070118110","dateCreated":"2017-09-30T08:07:19+0000","dateStarted":"2017-09-30T11:43:26+0000","dateFinished":"2017-09-30T19:55:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:395"},{"text":"%pyspark\n\n# Next, compute whether each pld appears as a host by itself using a leftOuter join and append as an extra column\nfrom pyspark.sql.functions import col, when, lit\npld_host_test = when(col(\"host\").isNull(), lit(\"false\")).otherwise(lit(\"true\"))\npld_df_joined2=pld_df_joined.join(host_df, pld_df_joined.PLD==host_df.host, 'leftOuter').drop(\"hostid\").withColumn('PLDisHost?', pld_host_test).drop(\"host\")\npld_df_joined2.sort(\"NumHosts\", ascending=False).show(20)\npld_df_joined2.cache()\n#pld_df_joined2.groupBy(\"PLDisHost?\").count().show()","user":"anonymous","dateUpdated":"2017-09-30T11:41:38+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----+--------------+--------+----------+\n|   ID|           PLD|NumHosts|PLDisHost?|\n+-----+--------------+--------+----------+\n|81492|        ar.com|  523509|      true|\n|69342|         am.do|   10416|      true|\n|15549|   ae.blogspot|    9702|      true|\n|50431|         ai.id|    7574|      true|\n| 1426|        ac.goe|    4106|      true|\n|73298|         am.mm|    3384|      true|\n|82254|  ar.com.2sexy|    2101|      true|\n|98239|ar.com.anunico|    1956|      true|\n|68693|        am.cms|    1792|      true|\n|65544|       am.1905|    1754|      true|\n|77376|     am.weblog|    1660|      true|\n|73281|         am.mj|    1626|      true|\n|52047|         ai.of|    1445|      true|\n|83250|  ar.com.a-e-a|    1363|     false|\n|75471| am.schoolsite|    1243|      true|\n|51928|         ai.nl|    1241|      true|\n|12115|         ae.ac|     998|      true|\n|79023|         ao.co|     939|      true|\n|26929|         ae.nl|     887|      true|\n|69329|         am.dl|     703|      true|\n+-----+--------------+--------+----------+\nonly showing top 20 rows\n\nDataFrame[ID: string, PLD: string, NumHosts: bigint, PLDisHost?: string]\n"}]},"apps":[],"jobName":"paragraph_1506758839624_5082619","id":"20170929-091503_880987778","dateCreated":"2017-09-30T08:07:19+0000","dateStarted":"2017-09-30T11:43:27+0000","dateFinished":"2017-10-01T00:21:52+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:396"},{"text":"%pyspark\n\n# Next, join with the harmonic centrality and page-rank for each domain\npld_df_joined3=pld_df_joined2.join(pr_df, pr_df.host_rev==pld_df_joined2.PLD, \"leftOuter\").drop(\"#hc_pos\").drop(\"#pr_pos\").drop(\"host_rev\").withColumnRenamed(\"#hc_val\",\"HarmonicCentrality\").withColumnRenamed(\"#pr_val\",\"PageRank\")\npld_df_joined3.show(20)\npld_df_joined3.cache()","user":"anonymous","dateUpdated":"2017-09-30T11:41:38+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----+--------------------+--------+----------+------------------+--------------------+\n|  ID|                 PLD|NumHosts|PLDisHost?|HarmonicCentrality|            PageRank|\n+----+--------------------+--------+----------+------------------+--------------------+\n| 120|             abc.web|       1|     false|              null|                null|\n| 311|             ac.8411|       1|     false|              null|                null|\n| 713|              ac.bgc|       1|     false|              null|                null|\n| 871|          ac.casinos|       1|      true|              null|                null|\n|1014|ac.cosmopolitanun...|       1|      true|          12615973|5.85933334251156e-09|\n|1089|            ac.dibru|       1|      true|              null|                null|\n|1435|          ac.gorilla|       1|      true|              null|                null|\n|2476|          ac.philter|       1|      true|              null|                null|\n|3138|              ac.ula|       1|     false|              null|                null|\n|3145|         ac.umedalen|       2|      true|          12093009|4.69402844088012e-09|\n|3373|              ac.yui|       2|      true|          12105217|5.09160908953513e-09|\n|3484|   academy.alphastar|       1|      true|              null|                null|\n|3768|    academy.cirulnik|       1|      true|              null|                null|\n|3787|       academy.cocoa|       1|      true|              null|                null|\n|3882|academy.dental-coach|       1|      true|              null|                null|\n|4157|         academy.ger|       1|      true|              null|                null|\n|4410|academy.investmen...|       2|      true|          12299180|1.31584108265683e-08|\n|4769|     academy.newtown|       1|      true|              null|                null|\n|5224|        academy.talk|       2|      true|              null|                null|\n|6064|accountant.buy-mo...|       1|      true|              null|                null|\n+----+--------------------+--------+----------+------------------+--------------------+\nonly showing top 20 rows\n\nDataFrame[ID: string, PLD: string, NumHosts: bigint, PLDisHost?: string, HarmonicCentrality: string, PageRank: string]\n"}]},"apps":[],"jobName":"paragraph_1506758839625_4697870","id":"20170929-122540_264490752","dateCreated":"2017-09-30T08:07:19+0000","dateStarted":"2017-09-30T19:55:59+0000","dateFinished":"2017-10-01T00:24:10+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:397"},{"text":"%pyspark\n\n# Save final table to S3 in compressed CSV format\noutputURI=\"s3://billsdata.net/CommonCrawl/domain_summaries/\"\ncodec=\"org.apache.hadoop.io.compress.GzipCodec\"\npld_df_joined3.coalesce(1).write.format('com.databricks.spark.csv').options(header='true', codec=codec).save(outputURI)","user":"anonymous","dateUpdated":"2017-09-30T11:41:38+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1506758839626_5852116","id":"20170929-123834_882164555","dateCreated":"2017-09-30T08:07:19+0000","dateStarted":"2017-10-01T00:21:52+0000","dateFinished":"2017-10-01T00:24:38+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:398"},{"text":"%pyspark\n","user":"anonymous","dateUpdated":"2017-09-30T11:41:38+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1506761138114_493576328","id":"20170930-084538_879594277","dateCreated":"2017-09-30T08:45:38+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:399"}],"name":"Paul 4 - initial domain summary","id":"2CX1W8ZGA","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}