{"paragraphs":[{"text":"%pyspark\n\n# Simple script to demonstrate evaluation of CommonCrawl-derived domain vectors by using them to\n# classify domains according to high-level topic in the DMOZ dataset. Currently configured to load\n# Bill's domain hex feature vectors from the 'Bill 6' notebook.\n# TODO: Should we really be trying to predict domain links instead?\n# PJ - 14 Sept 2017\n\nimport csv\nimport boto\nfrom pyspark.sql.types import *\n\n# Import the DMOZ domain category dataset\n# (downloaded from https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/OMV93V)\n\ndmoz_labels=sc.textFile('s3://billsdata.net/CommonCrawl/DMOZ/dmoz_domain_category.csv')\nheader = dmoz_labels.first() # extract header\ndmoz_labels = dmoz_labels.filter(lambda row: row != header) # remove header row\ndmoz_labels.take(1)","dateUpdated":"2017-09-14T14:59:35+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[u'\"sdcastroverde.com\",\"Top/World/Galego/regional/Galicia/Lugo/municipalities/Castroverde\"']\n"}]},"apps":[],"jobName":"paragraph_1505397371793_-1901756071","id":"20170908-135610_63929491","dateCreated":"2017-09-14T13:56:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:278","user":"anonymous","dateFinished":"2017-09-14T14:59:37+0000","dateStarted":"2017-09-14T14:59:35+0000"},{"text":"%pyspark\n\n# For now, collect all labels into a list on one node\n# TODO: Could probably do this much faster using map-reduce!\ndmoz_labels_list = dmoz_labels.collect()\n\n# Take a look at one record\ndmoz_labels_list[1]","dateUpdated":"2017-09-14T14:59:49+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"u'\"www.232analyzer.com\",\"Top/Computers/Hardware/Test_Equipment/Analyzers\"'\n"}]},"apps":[],"jobName":"paragraph_1505397371796_-1902910317","id":"20170908-135822_22719920","dateCreated":"2017-09-14T13:56:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:279","user":"anonymous","dateFinished":"2017-09-14T15:00:04+0000","dateStarted":"2017-09-14T14:59:49+0000"},{"text":"%pyspark\n\n# Make a dictionary of short domains (without www.) to top-level category label, as per this page:\n# http://dmoztools.net\nlabels={}\nprefix=\"www.\"\n\n# TODO: Could probably do this much faster using map-reduce!\nprint(len(dmoz_labels_list))\nfor row in dmoz_labels_list[1:900000]: # Sample initially for speed (increasing to 1M causes an indexing error, TODO: Investigate this)\n    row = row.replace('\"','').split(',')\n    fulldomain = row[0]\n    shortdomain = fulldomain[len(prefix):] if fulldomain.startswith(prefix) else fulldomain\n    label = row[1].split(\"/\")[1].split(\"|\")[0]\n    labels[shortdomain]=label  \n    #print(shortdomain + \" \" + label)\n\n# Take a look at the category for one domain from our dictionary\nlabels['232analyzer.com']","dateUpdated":"2017-09-14T15:30:00+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"2488259\nu'Computers'\n"}]},"apps":[],"jobName":"paragraph_1505397371797_-1903295066","id":"20170908-144404_840192591","dateCreated":"2017-09-14T13:56:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:280","user":"anonymous","dateFinished":"2017-09-14T15:30:05+0000","dateStarted":"2017-09-14T15:30:00+0000"},{"text":"%pyspark\n\n# Summarize categories in the DMOZ data\nfrom collections import Counter\nCounter(labels.values())","dateUpdated":"2017-09-14T15:30:31+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Counter({u'World': 462130, u'Regional': 231978, u'Business': 54054, u'Society': 28807, u'Arts': 24093, u'Shopping': 19102, u'Recreation': 16737, u'Computers': 16513, u'Sports': 12248, u'Science': 9857, u'Health': 8874, u'Reference': 7934, u'Games': 3730, u'Home': 2549, u'News': 1383})\n"}]},"apps":[],"jobName":"paragraph_1505397371797_-1903295066","id":"20170908-150338_1273147128","dateCreated":"2017-09-14T13:56:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:281","user":"anonymous","dateFinished":"2017-09-14T15:30:32+0000","dateStarted":"2017-09-14T15:30:31+0000"},{"text":"%pyspark\n\n# Load Bill's domain feature vectors from s3, in the following format:\n# (u'www.angelinajolin.com', [4.30406509320417, 0.02702702702702703, 0.0, 0.13513513513513514, 0.0, 0.06756756756756757, 0.0])\n\nnfiles=128\n\n# Load feature vectors from WAT files (from 'Bill 6' notebook):\ninputURI = \"s3://billsdata.net/CommonCrawl/domain_hex_feature_vectors_from_%d_WAT_files\" % nfiles\nfeatures_rdd = sc.textFile(inputURI).map(eval)\nfeatures_rdd.cache()\nprint(\"Nr domains:\", features_rdd.count())\nprint(features_rdd.take(1))","dateUpdated":"2017-09-14T14:31:28+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"('Nr domains:', 2626203)\n[(u'www.iggl.de', [3.6375861597263857, 0.5, 0.0, 0.0, 0.02564102564102564, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.358974358974359, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05128205128205128, 0.0, 0.0, 0.0, 0.05128205128205128, 0.0, 0.02564102564102564, 0.02564102564102564, 0.15384615384615385, 0.20512820512820512, 0.0, 0.02564102564102564, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02564102564102564, 0.0, 0.05128205128205128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])]\n"}]},"apps":[],"jobName":"paragraph_1505397371798_-1902140820","id":"20170914-093439_1131502776","dateCreated":"2017-09-14T13:56:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:282","user":"anonymous","dateFinished":"2017-09-14T14:02:15+0000","dateStarted":"2017-09-14T14:00:58+0000"},{"text":"%pyspark\n\n# Convert to a python dictionary for ease-of-use initially\n# TODO: Find a better Spark way to do this!\nfeatures_sample = features_rdd.sample(0, 0.15, seed=42) # TODO: Investigate memory error with >15% samples!\nfeatures_dict = features_sample.collectAsMap()\n#features_dict['232analyzer.com']\nprint(len(features_dict.keys()))\nfeatures_dict.itervalues().next() # Output one vector for testing","dateUpdated":"2017-09-14T15:31:29+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1505397371799_-1902525569","id":"20170914-105124_2107496973","dateCreated":"2017-09-14T13:56:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:283","user":"anonymous","dateFinished":"2017-09-14T15:31:19+0000","dateStarted":"2017-09-14T15:30:46+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"393245\n[3.912023005428146, 0.48, 0.0, 0.0, 0.0196078431372549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35294117647058826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0392156862745098, 0.0, 0.0196078431372549, 0.0, 0.0784313725490196, 0.0, 0.0196078431372549, 0.0196078431372549, 0.13725490196078433, 0.17647058823529413, 0.0, 0.0196078431372549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.058823529411764705, 0.058823529411764705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"}]}},{"text":"%pyspark\n\n# Filter embeddings for only those vectors that have entries in the DMOZ dictionary (i.e. ground truth labels)\nnew_vec_ids=[]\nnew_vec_embs=[]\nground_truth=[]\n\ndef intersect(a, b):\n     return list(set(a) & set(b))\n     \ncommon_domains=intersect(features_dict.keys(), labels.keys())\nprint(len(common_domains))\nprint(common_domains[1])\n\n# Iterate over all the domain IDs for which we also have a vector embedding\nfor domain in common_domains:\n    \n    new_vec_ids.append(domain)\n    new_vec_embs.append(features_dict[domain])\n    ground_truth.append(labels[domain])\n\n# Verify lengths of each list\nprint(str(len(new_vec_ids)) + \" \" + str(len(new_vec_embs)) + \" \" + str(len(ground_truth)))","dateUpdated":"2017-09-14T15:31:30+0000","config":{"colWidth":12,"editorMode":"ace/mode/text","results":{},"enabled":true,"editorSetting":{"language":"text","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1505397371799_-1902525569","id":"20170914-122753_1677347656","dateCreated":"2017-09-14T13:56:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:284","user":"anonymous","dateFinished":"2017-09-14T15:31:30+0000","dateStarted":"2017-09-14T15:31:30+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"3057\nprivateerpress.com\n3057 3057 3057\n"}]}},{"text":"%pyspark\n\n# Split into training and test sets\nfrom sklearn.cross_validation import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(new_vec_embs, ground_truth, test_size=0.5, random_state=42)","user":"anonymous","dateUpdated":"2017-09-14T15:31:34+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1505398368253_1824589577","id":"20170914-141248_1548737052","dateCreated":"2017-09-14T14:12:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1265","dateFinished":"2017-09-14T15:31:34+0000","dateStarted":"2017-09-14T15:31:34+0000","results":{"code":"SUCCESS","msg":[]}},{"text":"%pyspark\n\n# Summarize labels in our test data\nCounter(y_test)","user":"anonymous","dateUpdated":"2017-09-14T15:31:37+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1505398585624_1095614650","id":"20170914-141625_481082287","dateCreated":"2017-09-14T14:16:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1358","dateFinished":"2017-09-14T15:31:37+0000","dateStarted":"2017-09-14T15:31:37+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Counter({u'World': 587, u'Regional': 283, u'Computers': 103, u'Arts': 87, u'Society': 86, u'Business': 71, u'Reference': 69, u'Recreation': 49, u'Science': 41, u'Shopping': 29, u'Sports': 28, u'Health': 25, u'Games': 25, u'News': 23, u'Home': 23})\n"}]}},{"text":"%pyspark\n\n# Fit KNN classifier to the training data and report results on test set\nfrom sklearn.neighbors import KNeighborsClassifier\nneigh = KNeighborsClassifier(n_neighbors=3, metric='cosine', algorithm='brute')\nneigh.fit(X_train, y_train) \nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, neigh.predict(X_test)))","user":"anonymous","dateUpdated":"2017-09-14T15:33:26+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1505398600244_-2007369906","id":"20170914-141640_1522668331","dateCreated":"2017-09-14T14:16:40+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1442","dateFinished":"2017-09-14T15:33:18+0000","dateStarted":"2017-09-14T15:33:18+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"             precision    recall  f1-score   support\n\n       Arts       0.05      0.13      0.07        87\n   Business       0.09      0.17      0.12        71\n  Computers       0.11      0.17      0.13       103\n      Games       0.02      0.04      0.03        25\n     Health       0.00      0.00      0.00        25\n       Home       0.03      0.04      0.04        23\n       News       0.06      0.04      0.05        23\n Recreation       0.03      0.02      0.02        49\n  Reference       0.07      0.09      0.08        69\n   Regional       0.23      0.22      0.23       283\n    Science       0.11      0.05      0.07        41\n   Shopping       0.00      0.00      0.00        29\n    Society       0.16      0.06      0.09        86\n     Sports       0.00      0.00      0.00        28\n      World       0.50      0.38      0.43       587\n\navg / total       0.27      0.22      0.24      1529\n\n"}]}},{"text":"%pyspark\n\n# Fit Random Forest classifier to the training data and report results on test set\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(max_depth=2, random_state=0)\nrf.fit(X_train, y_train)\nprint(classification_report(y_test, rf.predict(X_test)))","user":"anonymous","dateUpdated":"2017-09-14T15:34:04+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1505398616885_376949677","id":"20170914-141656_232271883","dateCreated":"2017-09-14T14:16:56+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1514","dateFinished":"2017-09-14T15:34:04+0000","dateStarted":"2017-09-14T15:34:04+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"             precision    recall  f1-score   support\n\n       Arts       0.00      0.00      0.00        87\n   Business       0.00      0.00      0.00        71\n  Computers       0.00      0.00      0.00       103\n      Games       0.00      0.00      0.00        25\n     Health       0.00      0.00      0.00        25\n       Home       0.00      0.00      0.00        23\n       News       0.00      0.00      0.00        23\n Recreation       0.00      0.00      0.00        49\n  Reference       0.00      0.00      0.00        69\n   Regional       0.00      0.00      0.00       283\n    Science       0.00      0.00      0.00        41\n   Shopping       0.00      0.00      0.00        29\n    Society       0.00      0.00      0.00        86\n     Sports       0.00      0.00      0.00        28\n      World       0.38      1.00      0.55       587\n\navg / total       0.15      0.38      0.21      1529\n\n"}]}},{"text":"%pyspark\n","user":"anonymous","dateUpdated":"2017-09-14T14:17:13+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1505398633679_2007500715","id":"20170914-141713_903756751","dateCreated":"2017-09-14T14:17:13+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1586"}],"name":"201709 evaluate CC vectors","id":"2CTRDNFEY","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}