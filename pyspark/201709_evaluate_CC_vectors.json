{"paragraphs":[{"text":"%pyspark\n\n# Simple script to demonstrate evaluation of CommonCrawl-derived domain vectors by using them to\n# classify domains according to high-level topic in the DMOZ dataset. Currently configured to load\n# Bill's domain hex feature vectors from the 'Bill 6' notebook.\n# TODO: Should we really be trying to predict domain links instead? Or predicting bad domains from known dictionary?\n# PJ - 20 Sept 2017\n\nimport csv\nimport boto\nfrom pyspark.sql.types import *\n\n# Import the DMOZ domain category dataset as an RDD\n# (downloaded from https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/OMV93V)\n\ndmoz_labels=sc.textFile('s3://billsdata.net/CommonCrawl/DMOZ/dmoz_domain_category.csv')\nheader = dmoz_labels.first() # extract header\ndmoz_labels = dmoz_labels.filter(lambda row: row != header).map(lambda row: row.replace('\"','').split(',',1)) # remove header row, quotes and split on (only the first) comma\ndmoz_labels.take(3)","dateUpdated":"2017-09-20T10:24:19+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[[u'sdcastroverde.com', u'Top/World/Galego/regional/Galicia/Lugo/municipalities/Castroverde'], [u'www.232analyzer.com', u'Top/Computers/Hardware/Test_Equipment/Analyzers'], [u'zschachwitz-tischtennis.de', u'Top/World/Deutsch/Sport/ball_Sports/table_tennis/Teams/Germany/Saxony']]\n"}]},"apps":[],"jobName":"paragraph_1505897986189_1695561000","id":"20170908-135610_63929491","dateCreated":"2017-09-20T08:59:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:174","user":"anonymous","dateFinished":"2017-09-20T10:14:54+0000","dateStarted":"2017-09-20T10:14:44+0000"},{"text":"%pyspark\n\n# Convert our labels RDD into a Spark DataFrame with a schema - neither column can be Null\n\nschema=StructType([StructField(\"domain\", StringType(), False), StructField(\"categories\", StringType(), False)])\ndmoz_labels_df=spark.createDataFrame(dmoz_labels,schema)\ndmoz_labels_df.printSchema()\nprint(dmoz_labels_df.count())\ndmoz_labels_df.show(1)\ndmoz_labels_df.cache()","user":"anonymous","dateUpdated":"2017-09-20T10:24:57+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1505898275676_697318205","id":"20170920-090435_466600213","dateCreated":"2017-09-20T09:04:35+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1134","dateFinished":"2017-09-20T10:16:07+0000","dateStarted":"2017-09-20T10:15:55+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- domain: string (nullable = false)\n |-- categories: string (nullable = false)\n\n2488259\n+-----------------+--------------------+\n|           domain|          categories|\n+-----------------+--------------------+\n|sdcastroverde.com|Top/World/Galego/...|\n+-----------------+--------------------+\nonly showing top 1 row\n\nDataFrame[domain: string, categories: string]\n"}]}},{"text":"%pyspark\n\n# Make a dictionary of short domains (removing www. prefix) to top-level category label, as per this page: http://dmoztools.net\nprefix=\"www.\"\nlabels=dmoz_labels_df.rdd.map(lambda row: ((row['domain'][len(prefix):] if row['domain'].startswith(prefix) else row['domain']),\\\n                                            row['categories'].split(\"/\")[1].split(\"|\")[0])).collectAsMap()\n\n# OLD CODE IN PURE PYTHON - YUK!\n#for row in dmoz_labels_list[1:900000]: # Sample initially for speed (increasing to 1M causes an indexing error, TODO: Investigate this)\n#    row = row.replace('\"','').split(',')\n#    fulldomain = row[0]\n#    shortdomain = fulldomain[len(prefix):] if fulldomain.startswith(prefix) else fulldomain\n#    label = row[1].split(\"/\")[1].split(\"|\")[0]\n#    labels[shortdomain]=label  \n#    print(shortdomain + \" \" + label)\n\n# Take a look at the category for one domain from our dictionary\nlabels['232analyzer.com']","dateUpdated":"2017-09-20T10:26:52+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"u'Computers'\n"}]},"apps":[],"jobName":"paragraph_1505897986194_1707488216","id":"20170908-144404_840192591","dateCreated":"2017-09-20T08:59:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:176","user":"anonymous","dateFinished":"2017-09-20T10:17:46+0000","dateStarted":"2017-09-20T10:17:20+0000"},{"text":"%pyspark\n\n# Summarize categories in the DMOZ data\nfrom collections import Counter\nCounter(labels.values())","dateUpdated":"2017-09-20T10:18:00+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Counter({u'World': 1273938, u'Regional': 642158, u'Business': 148142, u'Society': 82072, u'Arts': 66715, u'Shopping': 54062, u'Recreation': 46095, u'Computers': 45193, u'Sports': 34885, u'Science': 28135, u'Health': 24218, u'Reference': 21663, u'Games': 10246, u'Home': 6951, u'News': 3710})\n"}]},"apps":[],"jobName":"paragraph_1505897986195_1707103467","id":"20170908-150338_1273147128","dateCreated":"2017-09-20T08:59:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:177","user":"anonymous","dateFinished":"2017-09-20T10:18:02+0000","dateStarted":"2017-09-20T10:18:00+0000"},{"text":"%pyspark\n\n# Load Bill's domain feature vectors from s3, in the following format:\n# (u'www.angelinajolin.com', [4.30406509320417, 0.02702702702702703, 0.0, 0.13513513513513514, 0.0, 0.06756756756756757, 0.0])\n\nnfiles=128\n\n# Load feature vectors from WAT files (from 'Bill 6' notebook) as an RDD:\ninputURI = \"s3://billsdata.net/CommonCrawl/domain_hex_feature_vectors_from_%d_WAT_files\" % nfiles\nfeatures_rdd = sc.textFile(inputURI).map(eval)\nfeatures_rdd.cache()\nprint(\"Nr domains:\", features_rdd.count())\nprint(features_rdd.take(1))","dateUpdated":"2017-09-20T10:35:25+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-780339602779874189.py\", line 343, in <module>\n    sc.setJobGroup(jobGroup, \"Zeppelin\")\n  File \"/usr/lib/spark/python/pyspark/context.py\", line 929, in setJobGroup\n    self._jsc.setJobGroup(groupId, description, interruptOnCancel)\nAttributeError: 'NoneType' object has no attribute 'setJobGroup'\n"}]},"apps":[],"jobName":"paragraph_1505897986196_1705179723","id":"20170914-093439_1131502776","dateCreated":"2017-09-20T08:59:46+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:178","user":"anonymous","dateFinished":"2017-09-20T10:35:25+0000","dateStarted":"2017-09-20T10:35:25+0000"},{"text":"%pyspark\n\n#features_sample = features_rdd.sample(0, 0.15, seed=42) # TODO: Investigate memory error with >15% samples!\n\n# Increase max result size so we can hold all the vectors in a map\n# TODO: Find a better Spark way to do this!\n#from pyspark import SparkConf, SparkContext\n#sc.stop()\n#conf = (SparkConf().set(\"spark.driver.maxResultSize\", \"2g\"))\n#sc = SparkContext(conf=conf)\n\n#spark.driver.maxResultSize=2g\n\n# Convert to a python dictionary for ease-of-use initially\nfeatures_dict = features_rdd.collectAsMap()\nprint(len(features_dict.keys()))\nfeatures_dict.itervalues().next() # Output one vector for testing","dateUpdated":"2017-09-20T10:35:41+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-780339602779874189.py\", line 343, in <module>\n    sc.setJobGroup(jobGroup, \"Zeppelin\")\n  File \"/usr/lib/spark/python/pyspark/context.py\", line 929, in setJobGroup\n    self._jsc.setJobGroup(groupId, description, interruptOnCancel)\nAttributeError: 'NoneType' object has no attribute 'setJobGroup'\n"}]},"apps":[],"jobName":"paragraph_1505897986197_1704794974","id":"20170914-105124_2107496973","dateCreated":"2017-09-20T08:59:46+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:179","user":"anonymous","dateFinished":"2017-09-20T10:35:41+0000","dateStarted":"2017-09-20T10:35:41+0000"},{"text":"%pyspark\n\n# Filter embeddings for only those vectors that have entries in the DMOZ dictionary (i.e. ground truth labels)\nnew_vec_ids=[]\nnew_vec_embs=[]\nground_truth=[]\n\ndef intersect(a, b):\n     return list(set(a) & set(b))\n     \ncommon_domains=intersect(features_dict.keys(), labels.keys())\nprint(len(common_domains))\nprint(common_domains[1])\n\n# Iterate over all the domain IDs for which we also have a vector embedding\nfor domain in common_domains:\n    \n    new_vec_ids.append(domain)\n    new_vec_embs.append(features_dict[domain])\n    ground_truth.append(labels[domain])\n\n# Verify lengths of each list\nprint(str(len(new_vec_ids)) + \" \" + str(len(new_vec_embs)) + \" \" + str(len(ground_truth)))","dateUpdated":"2017-09-20T10:22:06+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"8503\nkoeln-nachrichten.de\n8503 8503 8503\n"}]},"apps":[],"jobName":"paragraph_1505897986198_1705949220","id":"20170914-122753_1677347656","dateCreated":"2017-09-20T08:59:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:180","user":"anonymous","dateFinished":"2017-09-20T10:22:07+0000","dateStarted":"2017-09-20T10:22:06+0000"},{"text":"%pyspark\n\n# Split into training and test sets\nfrom sklearn.cross_validation import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(new_vec_embs, ground_truth, test_size=0.5, random_state=42)","dateUpdated":"2017-09-20T10:22:16+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"/usr/local/lib64/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n  \"This module will be removed in 0.20.\", DeprecationWarning)\n"}]},"apps":[],"jobName":"paragraph_1505897986198_1705949220","id":"20170914-141248_1548737052","dateCreated":"2017-09-20T08:59:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:181","user":"anonymous","dateFinished":"2017-09-20T10:22:19+0000","dateStarted":"2017-09-20T10:22:16+0000"},{"text":"%pyspark\n\n# Summarize labels in our test data\nCounter(y_test)","dateUpdated":"2017-09-20T10:22:23+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Counter({u'World': 1657, u'Regional': 829, u'Computers': 285, u'Society': 245, u'Arts': 228, u'Reference': 201, u'Business': 190, u'Science': 138, u'Recreation': 105, u'Shopping': 78, u'Sports': 75, u'Health': 72, u'News': 55, u'Games': 52, u'Home': 42})\n"}]},"apps":[],"jobName":"paragraph_1505897986199_1705564472","id":"20170914-141625_481082287","dateCreated":"2017-09-20T08:59:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:182","user":"anonymous","dateFinished":"2017-09-20T10:22:23+0000","dateStarted":"2017-09-20T10:22:23+0000"},{"text":"%pyspark\n\n# Fit KNN classifier to the training data and report results on test set\nfrom sklearn.neighbors import KNeighborsClassifier\nneigh = KNeighborsClassifier(n_neighbors=3, metric='cosine', algorithm='brute')\nneigh.fit(X_train, y_train) \nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, neigh.predict(X_test)))","dateUpdated":"2017-09-20T10:22:33+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"             precision    recall  f1-score   support\n\n       Arts       0.06      0.16      0.09       228\n   Business       0.05      0.12      0.07       190\n  Computers       0.10      0.16      0.13       285\n      Games       0.04      0.06      0.05        52\n     Health       0.05      0.07      0.06        72\n       Home       0.00      0.00      0.00        42\n       News       0.05      0.07      0.06        55\n Recreation       0.03      0.04      0.03       105\n  Reference       0.13      0.17      0.15       201\n   Regional       0.23      0.22      0.22       829\n    Science       0.00      0.00      0.00       138\n   Shopping       0.05      0.01      0.02        78\n    Society       0.08      0.02      0.03       245\n     Sports       0.14      0.01      0.02        75\n      World       0.55      0.37      0.44      1657\n\navg / total       0.29      0.22      0.24      4252\n\n"}]},"apps":[],"jobName":"paragraph_1505897986200_1703640727","id":"20170914-141640_1522668331","dateCreated":"2017-09-20T08:59:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:183","user":"anonymous","dateFinished":"2017-09-20T10:22:34+0000","dateStarted":"2017-09-20T10:22:33+0000"},{"text":"%pyspark\n\n# Fit Random Forest classifier to the training data and report results on test set\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(max_depth=2, random_state=0)\nrf.fit(X_train, y_train)\nprint(classification_report(y_test, rf.predict(X_test)))","dateUpdated":"2017-09-20T10:22:53+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"/usr/local/lib64/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n             precision    recall  f1-score   support\n\n       Arts       0.00      0.00      0.00       228\n   Business       0.00      0.00      0.00       190\n  Computers       0.00      0.00      0.00       285\n      Games       0.00      0.00      0.00        52\n     Health       0.00      0.00      0.00        72\n       Home       0.00      0.00      0.00        42\n       News       0.00      0.00      0.00        55\n Recreation       0.00      0.00      0.00       105\n  Reference       0.00      0.00      0.00       201\n   Regional       0.00      0.00      0.00       829\n    Science       0.00      0.00      0.00       138\n   Shopping       0.00      0.00      0.00        78\n    Society       0.00      0.00      0.00       245\n     Sports       0.00      0.00      0.00        75\n      World       0.39      1.00      0.56      1657\n\navg / total       0.15      0.39      0.22      4252\n\n"}]},"apps":[],"jobName":"paragraph_1505897986200_1703640727","id":"20170914-141656_232271883","dateCreated":"2017-09-20T08:59:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:184","user":"anonymous","dateFinished":"2017-09-20T10:22:53+0000","dateStarted":"2017-09-20T10:22:53+0000"},{"text":"%pyspark\n","dateUpdated":"2017-09-20T08:59:46+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1505897986201_1703255978","id":"20170914-141713_903756751","dateCreated":"2017-09-20T08:59:46+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:185"}],"name":"201709 evaluate CC vectors","id":"2CW37U4P7","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}