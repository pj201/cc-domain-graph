{"paragraphs":[{"text":"%pyspark\n\n# Zeppelin notebook to create domain summaries based on the May/Jun/Jul 2017 CommonCrawl graph\n# as per description here: http://commoncrawl.org/2017/08/webgraph-2017-may-june-july/\n# PJ - 4 October 2017\n\nimport boto\nfrom pyspark.sql.types import *\n\n#LIMIT=1000000 # TODO - remove temporary limit to run full summaries!\n\n# Import the PLD vertices list as a DataFrame\npld_schema=StructType([StructField(\"ID\", StringType(), False), StructField(\"PLD\", StringType(), False)])\npld_txt=sc.textFile(\"s3://commoncrawl/projects/hyperlinkgraph/cc-main-2017-may-jun-jul/domaingraph/vertices.txt.gz\")\ntemp_pld = pld_txt.map(lambda k: k.split()) # By default, splits on whitespace, which is what we want\npld_df=temp_pld.toDF(pld_schema) #.limit(LIMIT) \npld_df.show(3)\npld_df.cache()\n# Should have 91M domains\n#print(pld_df.count())","user":"anonymous","dateUpdated":"2017-10-05T09:34:38+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---+-------+\n| ID|    PLD|\n+---+-------+\n|  0|  aaa.a|\n|  1| aaa.aa|\n|  2|aaa.aaa|\n+---+-------+\nonly showing top 3 rows\n\nDataFrame[ID: string, PLD: string]\n"}]},"apps":[],"jobName":"paragraph_1507196047326_-17681123","id":"20170929-081624_672091334","dateCreated":"2017-10-05T09:34:07+0000","dateStarted":"2017-10-05T09:34:39+0000","dateFinished":"2017-10-05T09:35:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:288"},{"text":"%pyspark\n\n# Next import the PLD edges as a DataFrame\npld_edges_schema=StructType([StructField(\"src\", StringType(), False), StructField(\"dst\", StringType(), False)])\npld_edges_txt=sc.textFile(\"s3://commoncrawl/projects/hyperlinkgraph/cc-main-2017-may-jun-jul/domaingraph/edges.txt.gz\")\ntemp_edges_pld = pld_edges_txt.map(lambda k: k.split()) # By default, splits on whitespace, which is what we want\npld_edges_df=temp_edges_pld.toDF(pld_edges_schema) #.limit(LIMIT*10) # TODO - remove temporary limit to run full summaries!\npld_edges_df.show(3)\npld_edges_df.cache()","user":"anonymous","dateUpdated":"2017-10-05T09:35:57+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---+--------+\n|src|     dst|\n+---+--------+\n|  2| 9193244|\n| 20|75600973|\n| 21|46356172|\n+---+--------+\nonly showing top 3 rows\n\nDataFrame[src: string, dst: string]\n"}]},"apps":[],"jobName":"paragraph_1507196047330_-31532083","id":"20170929-095050_1324183281","dateCreated":"2017-10-05T09:34:07+0000","dateStarted":"2017-10-05T09:35:57+0000","dateFinished":"2017-10-05T09:35:58+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:289"},{"text":"%pyspark\n\n# Load the host-level graph vertices in the same way\nhost_schema=StructType([StructField(\"hostid\", StringType(), False), StructField(\"host\", StringType(), False)])\nhost_txt=sc.textFile(\"s3://commoncrawl/projects/hyperlinkgraph/cc-main-2017-may-jun-jul/hostgraph/vertices.txt.gz\")\ntemp_host = host_txt.map(lambda k: k.split()) # By default, splits on whitespace, which is what we want\nhost_df=temp_host.toDF(host_schema) #.limit(LIMIT*10) # TODO - remove temporary limit to run full summaries!\nhost_df.show(3)\nhost_df.cache()\n# Should have 1.3B hosts\n#print(host_df.count())","user":"anonymous","dateUpdated":"2017-10-05T09:36:01+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------+-------+\n|hostid|   host|\n+------+-------+\n|     0|  aaa.a|\n|     1| aaa.aa|\n|     2|aaa.aaa|\n+------+-------+\nonly showing top 3 rows\n\nDataFrame[hostid: string, host: string]\n"}]},"apps":[],"jobName":"paragraph_1507196047331_-31916832","id":"20170929-095310_1201506389","dateCreated":"2017-10-05T09:34:07+0000","dateStarted":"2017-10-05T09:36:01+0000","dateFinished":"2017-10-05T09:36:01+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:290"},{"text":"%pyspark\n\n# Load in all harmonic centrality and page-ranks, and join based on reverse domain name\n# Format: #hc_pos #hc_val #pr_pos #pr_val #host_rev\n#pr_schema=StructType([StructField(\"hc_pos\", StringType(), False), StructField(\"hc_val\", StringType(), False), StructField(\"pr_pos\", StringType(), False), StructField(\"pr_val\", StringType(), False), StructField(\"host_rev\", StringType(), False)])\npr_txt=sc.textFile(\"s3://commoncrawl/projects/hyperlinkgraph/cc-main-2017-may-jun-jul/domaingraph/ranks.txt.gz\")\nheader=pr_txt.first()\npr_txt=pr_txt.filter(lambda x: x!=header)\ntemp_pr = pr_txt.map(lambda k: k.split()) # By default, splits on whitespace, which is what we want\npr_df=temp_pr.toDF(header.split()).withColumnRenamed(\"#host_rev\",\"host_rev\")\npr_df.show(3)\npr_df.cache()\n#pr_df.count() # Should be 91M","dateUpdated":"2017-10-05T09:34:07+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+--------+-------+-------------------+--------------+\n|#hc_pos| #hc_val|#pr_pos|            #pr_val|      host_rev|\n+-------+--------+-------+-------------------+--------------+\n|      1|24989952|      1| 0.0155264576161686|  com.facebook|\n|      2|22460880|      3|0.00866038900847366|   com.twitter|\n|      3|22097514|      2| 0.0128827315785546|com.googleapis|\n+-------+--------+-------+-------------------+--------------+\nonly showing top 3 rows\n\nDataFrame[#hc_pos: string, #hc_val: string, #pr_pos: string, #pr_val: string, host_rev: string]\n"}]},"apps":[],"jobName":"paragraph_1507196047331_-31916832","id":"20170929-093202_1772383833","dateCreated":"2017-10-05T09:34:07+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:291"},{"text":"%pyspark #--packages graphframes:graphframes:0.5.0-spark2.1-s_2.11\n\n# We now have everything we need in these four dataframes to create the summaries we need.\n\n# This code can't handle the complete edge lists, and produces this exception:\n# java.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE\n#out_degrees_=dict(pld_edges_df.groupBy(\"src\").count().collect())\n#in_degrees=dict(pld_edges_df.groupBy(\"dst\").count().collect())\n#print(out_degrees['846558'])\n#print(in_degrees['846558'])\n\n# Instead, just create RDDs and use lookup()\nout_degrees=pld_edges_df.groupBy(\"src\").count()\nin_degrees=pld_edges_df.groupBy(\"dst\").count()\nprint(out_degrees.rdd.lookup(\"846558\"))\nprint(in_degrees.rdd.lookup(\"846558\"))","user":"anonymous","dateUpdated":"2017-10-05T09:38:08+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[1]\n[156]\n"}]},"apps":[],"jobName":"paragraph_1507196047332_-33840576","id":"20170929-095727_1596943627","dateCreated":"2017-10-05T09:34:07+0000","dateStarted":"2017-10-05T09:38:08+0000","dateFinished":"2017-10-05T13:53:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:292"},{"text":"%pyspark\n\n# Next, we'll construct a local dictionary from of all the PLDS (key is the PLD, value is the ID)\n# This is our truth-table of known PLDs that we'll use when counting hosts\n# This code can't handle the full PLD list and produces this exception:\n# Stack trace: ExitCodeException exitCode=52\n#pld_lookup_table=dict(pld_df.rdd.map(lambda x: (x['PLD'], x['ID'])).collect())\n#print(pld_lookup_table[\"aaa.aaa\"])\n\n# Instead, just create an RDD and use lookup()\npld_lookup_table=pld_df.rdd.map(lambda x: (x['PLD'], x['ID']))\nprint(pld_lookup_table.lookup(\"aaa.aaa\"))\n\n# Next, broadcast this map so it's available on all the slave nodes - this seems to break map access later!\n#pld_map=sc.broadcast(pld_lookup_table)","dateUpdated":"2017-10-05T16:16:59+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1507196047333_-34225325","id":"20170929-100048_2070118110","dateCreated":"2017-10-05T09:34:07+0000","status":"RUNNING","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:293","user":"anonymous","dateFinished":"2017-10-05T16:16:49+0000","dateStarted":"2017-10-05T16:16:59+0000"},{"text":"%pyspark\n\n# Returns a Boolean to say whether PLD is a hostname in itself\ndef is_a_pld(hostname):\n    #if hostname in pld_lookup_table:\n    if pld_lookup_table.filter(lambda a: a == hostname).count()>0:\n        return True\n    else:\n        return False\n        \n# Define a function to do the hostname->pld conversion, if the pld exists in our dictionary \ndef convert_hostname(hostname):\n    # Return hostname as-is, if this is already a PLD\n    #if hostname in pld_lookup_table:\n    if pld_lookup_table.filter(lambda a: a == hostname).count()>0:\n        return hostname\n    # Otherwise we're going to have to split it up and test the parts\n    try:\n        parts=hostname.split('.')\n        if (len(parts)>4 and is_a_pld('.'.join(parts[0:4]))):\n            return '.'.join(parts[0:4])\n        if (len(parts)>3 and is_a_pld('.'.join(parts[0:3]))):\n            return '.'.join(parts[0:3])\n        if (len(parts)>2 and is_a_pld('.'.join(parts[0:2]))):\n            return '.'.join(parts[0:2])\n        if (len(parts)>1 and is_a_pld('.'.join(parts[0:1]))):\n            return '.'.join(parts[0:1])\n        return \"ERROR\" # Couldn't find a corresponding PLD - this should never happen!\n    except:\n        return \"ERROR\"\n        \n# Test\nprint(convert_hostname(\"aaa.aaa\"))\nprint(is_a_pld(\"aaa.aaa\"))","dateUpdated":"2017-10-05T16:27:28+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1507196047334_-33071079","id":"20171004-091447_4214261","dateCreated":"2017-10-05T09:34:07+0000","status":"PENDING","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:294","user":"anonymous","dateStarted":"2017-10-05T16:27:28+0000"},{"text":"%pyspark\n\n# Now count the number of hosts per PLD in a scalable way, and create another dictionary\n# Takes 5mins for first 10M rows -> approx 8 hours for all 1.3B rows?\ncount_table=host_df.drop('hostid').rdd.map(lambda x: (convert_hostname(x['host']),1)).reduceByKey(lambda x,y: x+y).collectAsMap()\nbool_table=host_df.drop('hostid').rdd.map(lambda x: (x['host'], is_a_pld(x['host']))).filter(lambda x: x[1]==True).collectAsMap()\nprint(count_table['aaa.aaa'])\nprint(bool_table['aaa.aaa'])\nprint(count_table['ERROR']) # Should be zero once we've loaded all the PLDs!\n\n# TODO: Fix error in collect()\n# java.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE\n","dateUpdated":"2017-10-05T16:27:56+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-861814422310073205.py\", line 367, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-861814422310073205.py\", line 355, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 1570, in collectAsMap\n    return dict(self.collect())\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 809, in collect\n    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())\n  File \"/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n    answer, self.gateway_client, self.target_id, self.name)\n  File \"/usr/lib/spark/python/pyspark/sql/utils.py\", line 63, in deco\n    return f(*a, **kw)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 319, in get_return_value\n    format(target_id, \".\", name), value)\nPy4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 36.0 failed 4 times, most recent failure: Lost task 0.3 in stage 36.0 (TID 102, ip-172-31-42-45.ec2.internal, executor 3): java.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE\n\tat sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:869)\n\tat org.apache.spark.storage.DiskStore$$anonfun$getBytes$4.apply(DiskStore.scala:125)\n\tat org.apache.spark.storage.DiskStore$$anonfun$getBytes$4.apply(DiskStore.scala:124)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)\n\tat org.apache.spark.storage.DiskStore.getBytes(DiskStore.scala:126)\n\tat org.apache.spark.storage.BlockManager.getLocalValues(BlockManager.scala:520)\n\tat org.apache.spark.storage.BlockManager.get(BlockManager.scala:693)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:753)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:285)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:395)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1569)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1557)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1556)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1556)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:815)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:815)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:815)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1784)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1739)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1728)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:631)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2022)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2043)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2062)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2087)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:935)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:458)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE\n\tat sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:869)\n\tat org.apache.spark.storage.DiskStore$$anonfun$getBytes$4.apply(DiskStore.scala:125)\n\tat org.apache.spark.storage.DiskStore$$anonfun$getBytes$4.apply(DiskStore.scala:124)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)\n\tat org.apache.spark.storage.DiskStore.getBytes(DiskStore.scala:126)\n\tat org.apache.spark.storage.BlockManager.getLocalValues(BlockManager.scala:520)\n\tat org.apache.spark.storage.BlockManager.get(BlockManager.scala:693)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:753)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:285)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:395)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n\n\n"}]},"apps":[],"jobName":"paragraph_1507196047334_-33071079","id":"20171004-092350_1522843259","dateCreated":"2017-10-05T09:34:07+0000","status":"PENDING","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:295","user":"anonymous"},{"text":"%pyspark\n\nfrom pyspark.sql.types import IntegerType\nfrom pyspark.sql.functions import udf, col, when, lit\n\n# Define a UDF to perform column-based lookup\ndef translate(mapping):\n    def translate_(col):\n        if not mapping.get(col):\n            return 0\n        else:\n            return mapping.get(col)\n    return udf(translate_, IntegerType())\n\n# And a similar function for the Boolean map\ndef translate_bool(mapping):\n    def translate_bool_(col):\n        if not mapping.get(col):\n            return False\n        else:\n            return mapping.get(col)\n    return udf(translate_bool_, BooleanType())\n    \n# Insert our count column back into the host summary dataframe, along with a boolean to say whether the PLD is a host in itself\n# While we're at it, let's add in the in and out-degrees too, and an indicator of whether the site has been crawled.\ncrawled_test=when(col(\"OutDegree\")==0, lit(False)).otherwise(lit(True))\npld_df_joined=pld_df.withColumn('NumHosts', translate(count_table)(\"PLD\"))\\\n                    .withColumn('PLDisHost?', translate_bool(bool_table)(\"PLD\"))\\\n                    .withColumn('InDegree', translate(in_degrees)(\"ID\"))\\\n                    .withColumn('OutDegree', translate(out_degrees)(\"ID\"))\\\n                    .withColumn('Crawled?', crawled_test)\npld_df_joined.sort(\"NumHosts\", ascending=False).show(100)\npld_df_joined.cache()","dateUpdated":"2017-10-05T09:34:07+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------+--------------------+--------+----------+--------+---------+--------+\n|    ID|                 PLD|NumHosts|PLDisHost?|InDegree|OutDegree|Crawled?|\n+------+--------------------+--------+----------+--------+---------+--------+\n|846558|              au.com|  813989|      true|      12|        1|    true|\n|600347|          at.ibooked|  275515|      true|       1|       28|    true|\n|948740|     au.com.blogspot|  126110|      true|    1299|  1124067|    true|\n|114523|     ar.com.blogspot|   97052|      true|    4044|   462744|    true|\n|482699|      at.co.blogspot|   29811|      true|    2306|   270569|    true|\n|723578|            at.radio|   24659|      true|      49|     1188|    true|\n|723512|            at.radio|   24659|      true|      19|       35|    true|\n|739424|       at.safedomain|   15202|      true|      22|        3|    true|\n| 69342|               am.do|   10416|      true|      60|    31745|    true|\n| 15549|         ae.blogspot|    9702|      true|      61|   103731|    true|\n| 50431|               ai.id|    7574|      true|       0|     1907|    true|\n|739460|         at.safesite|    7565|      true|       5|        4|    true|\n|865746|   au.com.adelaidebd|    4978|      true|       3|      154|    true|\n|794268|   at.topdestination|    4935|      true|       0|       29|    true|\n|  1426|              ac.goe|    4106|      true|       0|      564|    true|\n|963776|   au.com.brisbanebd|    3983|      true|       1|       45|    true|\n|769111| at.stadtausstellung|    3683|      true|     599|     2331|    true|\n|192540|     ar.com.fullblog|    3627|      true|      47|    13025|    true|\n| 73298|               am.mm|    3384|      true|       0|        7|    true|\n|327854|        ar.com.t-a-u|    3148|     false|       0|        0|   false|\n|198509|        ar.com.goate|    3079|     false|       0|        0|   false|\n|165587|        ar.com.ehbol|    2983|     false|       0|        0|   false|\n|351200|        ar.com.waxed|    2973|     false|       0|        0|   false|\n|669871|           at.mobapp|    2721|      true|      24|       38|    true|\n|151713|        ar.com.de-ed|    2586|     false|       0|        0|   false|\n|842629|attorney.oilfield...|    2503|      true|       0|        5|    true|\n|343039|        ar.com.unuid|    2389|     false|       0|        0|   false|\n|308300|        ar.com.ruckl|    2387|     false|       0|        0|   false|\n|132542|        ar.com.chous|    2372|     false|       0|        0|   false|\n|692982|           at.opendi|    2367|      true|       4|       13|    true|\n|235552|        ar.com.lauko|    2343|     false|       0|        0|   false|\n|327536|        ar.com.swoos|    2283|     false|       0|        0|   false|\n|349149|        ar.com.visze|    2231|     false|       0|        0|   false|\n|596306|    at.hotelwebseite|    2155|      true|      30|       10|    true|\n|162668|        ar.com.dybex|    2130|     false|       0|        0|   false|\n|352268|        ar.com.widia|    2130|     false|       0|        0|   false|\n|269928|       ar.com.nnteen|    2102|      true|       3|      296|    true|\n| 82254|        ar.com.2sexy|    2101|      true|       2|      237|    true|\n|282995|   ar.com.perfectass|    2101|      true|       3|      224|    true|\n|354979|         ar.com.xttc|    2084|     false|       0|        0|   false|\n|305610|         ar.com.rjfm|    2081|     false|       0|        0|   false|\n|299501|         ar.com.rbbn|    2057|     false|       0|        0|   false|\n|111277|         ar.com.bekn|    2039|     false|       0|        0|   false|\n|302307|         ar.com.reoc|    2024|     false|       0|        0|   false|\n|320901|        ar.com.smmkt|    2013|     false|       0|        0|   false|\n|110900|         ar.com.bddp|    1993|     false|       0|        0|   false|\n|270152|        ar.com.noddl|    1968|     false|       0|        0|   false|\n|340110|        ar.com.tummi|    1968|     false|       0|        0|   false|\n| 98239|      ar.com.anunico|    1956|      true|      16|       86|    true|\n|322353|   ar.com.solostocks|    1947|      true|       8|       19|    true|\n|276073|        ar.com.orrio|    1930|     false|       0|        0|   false|\n|496704|at.cylex-oesterreich|    1842|      true|      33|      536|    true|\n|281578|        ar.com.paxia|    1807|     false|       0|        0|   false|\n|800139|          at.tyre100|    1799|      true|       6|       14|    true|\n| 68693|              am.cms|    1792|      true|       1|      732|    true|\n|259221|        ar.com.missk|    1776|     false|       0|        0|   false|\n|418169|        at.ac.univie|    1771|      true|    2467|    22933|    true|\n|276867|        ar.com.outvi|    1756|     false|       0|        0|   false|\n| 65544|             am.1905|    1754|      true|       0|      716|    true|\n|972854|au.com.businessfo...|    1747|      true|       2|       48|    true|\n|670795|            at.modoo|    1733|      true|       1|      352|    true|\n|213441|         ar.com.illl|    1695|     false|       0|        0|   false|\n|116514|        ar.com.bp-it|    1691|     false|       0|        0|   false|\n|220021|        ar.com.irmar|    1683|     false|       0|        0|   false|\n| 77376|           am.weblog|    1660|      true|       1|      731|    true|\n|110774|        ar.com.bbede|    1642|     false|       0|        0|   false|\n| 73281|               am.mj|    1626|      true|      10|        0|   false|\n|585428|             at.heim|    1617|      true|     220|        9|    true|\n|585413|             at.heim|    1617|      true|       7|       24|    true|\n|351195|         ar.com.wavi|    1616|     false|       0|        0|   false|\n|678655|          at.mywoman|    1600|      true|      10|      200|    true|\n|347623|        ar.com.vidha|    1585|     false|       0|        0|   false|\n|301857|        ar.com.remaz|    1565|     false|       0|        0|   false|\n|331120| ar.com.tedeartistas|    1559|      true|       6|      484|    true|\n|769140|at.stadtbranchenbuch|    1534|      true|      41|      301|    true|\n|769146|at.stadtbranchenbuch|    1534|      true|      19|     1052|    true|\n|315616|        ar.com.serle|    1533|     false|       0|        0|   false|\n|238794|        ar.com.licuo|    1472|      true|       1|    10429|    true|\n|204872|         ar.com.hayn|    1468|     false|       0|        0|   false|\n|255455| ar.com.mercadoshops|    1459|      true|     655|     1161|    true|\n| 52047|               ai.of|    1445|      true|       0|      578|    true|\n|111651|        ar.com.belor|    1421|     false|       0|        0|   false|\n|116300|        ar.com.bothi|    1389|     false|       0|        0|   false|\n|195824|        ar.com.geads|    1384|      true|       2|       18|    true|\n|135662|      ar.com.clicads|    1379|      true|       3|       41|    true|\n|293592|ar.com.publicargr...|    1377|      true|       1|       14|    true|\n|308619|        ar.com.ruoff|    1370|     false|       0|        0|   false|\n| 83250|        ar.com.a-e-a|    1363|     false|       0|        0|   false|\n|244970|        ar.com.lyros|    1356|     false|       0|        0|   false|\n|818378|          at.webnode|    1347|      true|     372|      988|    true|\n|385848|           asia.6eha|    1344|     false|       0|        0|   false|\n|324057|        ar.com.speis|    1337|     false|       0|        0|   false|\n|293172|         ar.com.psdi|    1323|     false|       0|        0|   false|\n|276548|        ar.com.ostiz|    1322|     false|       0|        0|   false|\n|357313|         ar.com.zonq|    1294|     false|       0|        0|   false|\n|349896|        ar.com.vmnet|    1292|     false|       0|        0|   false|\n|192232|        ar.com.fsgsa|    1248|     false|       0|        0|   false|\n| 75471|       am.schoolsite|    1243|      true|       5|       95|    true|\n| 51928|               ai.nl|    1241|      true|       0|        0|   false|\n|186154|        ar.com.fimct|    1237|     false|       0|        0|   false|\n+------+--------------------+--------+----------+--------+---------+--------+\nonly showing top 100 rows\n\nDataFrame[ID: string, PLD: string, NumHosts: int, PLDisHost?: boolean, InDegree: int, OutDegree: int, Crawled?: boolean]\n"}]},"apps":[],"jobName":"paragraph_1507196047335_-33455828","id":"20171004-100819_284908525","dateCreated":"2017-10-05T09:34:07+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:296"},{"text":"%pyspark\n\n# Finally, join with the harmonic centrality and page-rank for each domain\n# Note: could probably speed this up using something like above techniques, or by presorting (but we don't really need to since this is only 91Mx91M)\npld_df_joined2=pld_df_joined.join(pr_df, pr_df.host_rev==pld_df_joined.PLD, \"leftOuter\").drop(\"#hc_pos\").drop(\"#pr_pos\").drop(\"host_rev\").withColumnRenamed(\"#hc_val\",\"HarmonicCentrality\").withColumnRenamed(\"#pr_val\",\"PageRank\")\npld_df_joined2.show(20)\npld_df_joined2.cache()","dateUpdated":"2017-10-05T09:34:07+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----+--------------------+--------+----------+--------+---------+--------+------------------+--------------------+\n|  ID|                 PLD|NumHosts|PLDisHost?|InDegree|OutDegree|Crawled?|HarmonicCentrality|            PageRank|\n+----+--------------------+--------+----------+--------+---------+--------+------------------+--------------------+\n| 120|             abc.web|       1|     false|       0|        0|   false|          10015440|3.78405976859536e-08|\n| 311|             ac.8411|       1|     false|       1|        0|   false|           9082498|4.76481484534919e-09|\n| 713|              ac.bgc|       1|     false|       0|        0|   false|           9237769|4.90517712841288e-09|\n| 871|          ac.casinos|       1|      true|       0|        2|    true|         7839579.5|7.68640254732439e-09|\n|1014|ac.cosmopolitanun...|       1|      true|       1|        0|   false|          12615973|5.85933334251156e-09|\n|1089|            ac.dibru|       1|      true|       0|        0|   false|          12012666|4.49359706049864e-09|\n|1435|          ac.gorilla|       1|      true|       0|        0|   false|           9114256|4.50619088846452e-09|\n|2476|          ac.philter|       1|      true|       0|        0|   false|          10434785|4.44625601709852e-09|\n|3138|              ac.ula|       1|     false|       0|        0|   false|          10046531| 4.5521807953781e-09|\n|3145|         ac.umedalen|       2|      true|       0|        0|   false|          12093009|4.69402844088012e-09|\n|3373|              ac.yui|       2|      true|       0|        0|   false|          12105217|5.09160908953513e-09|\n|3484|   academy.alphastar|       1|      true|       0|        5|    true|           9816919|4.91209890117111e-09|\n|3768|    academy.cirulnik|       1|      true|       0|        0|   false|         7967335.5|6.12220241367047e-09|\n|3787|       academy.cocoa|       1|      true|       0|        3|    true|          10196119|6.02409896712952e-09|\n|3882|academy.dental-coach|       1|      true|       0|        0|   false|          10981495|4.43152551513855e-09|\n|4157|         academy.ger|       1|      true|       1|        7|    true|           8087047|1.37105166301547e-08|\n|4410|academy.investmen...|       2|      true|       4|        2|    true|          12299180|1.31584108265683e-08|\n|4769|     academy.newtown|       1|      true|       0|        1|    true|          10334425|8.54845369040491e-09|\n|5224|        academy.talk|       2|      true|       0|        5|    true|          12012667|5.30628234199031e-09|\n|6064|accountant.buy-mo...|       1|      true|       0|        0|   false|          10192661|5.29716249291459e-09|\n+----+--------------------+--------+----------+--------+---------+--------+------------------+--------------------+\nonly showing top 20 rows\n\nDataFrame[ID: string, PLD: string, NumHosts: int, PLDisHost?: boolean, InDegree: int, OutDegree: int, Crawled?: boolean, HarmonicCentrality: string, PageRank: string]\n"}]},"apps":[],"jobName":"paragraph_1507196047336_-35379572","id":"20170929-122540_264490752","dateCreated":"2017-10-05T09:34:07+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:297"},{"text":"%pyspark\n\n# Save final table to S3 in compressed CSV format\noutputURI=\"s3://billsdata.net/CommonCrawl/domain_summaries/\"\ncodec=\"org.apache.hadoop.io.compress.GzipCodec\"\npld_df_joined2.coalesce(1).write.format('com.databricks.spark.csv').options(header='true', codec=codec).save(outputURI)","dateUpdated":"2017-10-05T09:34:07+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1507196047336_-35379572","id":"20170929-123834_882164555","dateCreated":"2017-10-05T09:34:07+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:298"},{"text":"%pyspark\n","dateUpdated":"2017-10-05T09:34:07+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1507196047337_-35764321","id":"20170930-084538_879594277","dateCreated":"2017-10-05T09:34:07+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:299"}],"name":"Paul 5 - faster domain summary","id":"2CWFMQ7AZ","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}