{"paragraphs":[{"text":"%pyspark\n\n# Zeppelin notebook to create domain summaries based on the May/Jun/Jul 2017 CommonCrawl graph\n# as per description here: http://commoncrawl.org/2017/08/webgraph-2017-may-june-july/\n# PJ - 27 November 2017\n\nimport boto\nfrom pyspark.sql.types import *\n\n#LIMIT=10000000 # Temporary limit while developing code.\n\n# Import the PLD vertices list as a DataFrame\npld_schema=StructType([StructField(\"ID\", StringType(), False), StructField(\"PLD\", StringType(), False)])\n#pld_txt=sc.textFile(\"s3://commoncrawl/projects/hyperlinkgraph/cc-main-2017-may-jun-jul/domaingraph/vertices.txt.gz\")\npld_txt=sc.textFile(\"s3://commoncrawl/projects/hyperlinkgraph/cc-main-2017-aug-sep-oct/domaingraph/vertices.txt.gz\")\ntemp_pld = pld_txt.map(lambda k: k.split()) # By default, splits on whitespace, which is what we want\npld_df=temp_pld.toDF(pld_schema) #.limit(LIMIT) #.repartition(4)\npld_df.show(3)\n\n# Load in an uncompressed, partitioned format, for fast reading in the future\n#saveURI=\"s3://billsdata.net/CommonCrawl/hyperlinkgraph/cc-main-2017-may-jun-jul/domaingraph/vertices/\"\nsaveURI=\"s3://billsdata.net/CommonCrawl/hyperlinkgraph/cc-main-2017-aug-sep-oct/domaingraph/vertices/\"\npld_df.coalesce(64).write.save(saveURI) # Use all default options\n#pld_df=spark.read.load(saveURI)\n#pld_df.show(3)\n#pld_df.cache()\nprint(pld_df.count()) # Should have 91M domains, Aug-Sep-Oct now 93M domains","dateUpdated":"2017-11-27T16:26:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---+-----+\n| ID|  PLD|\n+---+-----+\n|  0|aaa.1|\n|  1|aaa.2|\n|  2|aaa.3|\n+---+-----+\nonly showing top 3 rows\n\n93111025\n"}]},"apps":[],"jobName":"paragraph_1511800007296_2054519265","id":"20170929-081624_672091334","dateCreated":"2017-11-27T16:26:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:13881"},{"text":"%pyspark\n\n# Next import the PLD edges as a DataFrame\npld_edges_schema=StructType([StructField(\"src\", LongType(), False), StructField(\"dst\", LongType(), False)])\n#pld_edges_txt=sc.textFile(\"s3://commoncrawl/projects/hyperlinkgraph/cc-main-2017-may-jun-jul/domaingraph/edges.txt.gz\")\npld_edges_txt=sc.textFile(\"s3://commoncrawl/projects/hyperlinkgraph/cc-main-2017-aug-sep-oct/domaingraph/edges.txt.gz\")\ntemp_edges_pld = pld_edges_txt.map(lambda k: map(int, k.split())) # By default, splits on whitespace, which is what we want\npld_edges_df=temp_edges_pld.toDF(pld_edges_schema) #.limit(LIMIT*10) #.repartition(8)\n#pld_edges_df.show(3)\n\n# Load in an uncompressed, partitioned format, for fast reading in the future\n#saveURI=\"s3://billsdata.net/CommonCrawl/hyperlinkgraph/cc-main-2017-may-jun-jul/domaingraph/edges/\"\nsaveURI=\"s3://billsdata.net/CommonCrawl/hyperlinkgraph/cc-main-2017-aug-sep-oct/domaingraph/edges/\"\npld_edges_df.coalesce(64).write.save(saveURI) # Use all default options\n#pld_edges_df=spark.read.load(saveURI)\npld_edges_df.show(3)\npld_edges_df.cache()","dateUpdated":"2017-11-27T16:26:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---+--------+\n|src|     dst|\n+---+--------+\n|  8| 9843173|\n| 27| 9843173|\n| 27|79323140|\n+---+--------+\nonly showing top 3 rows\n\nDataFrame[src: bigint, dst: bigint]\n"}]},"apps":[],"jobName":"paragraph_1511800007300_2052980270","id":"20170929-095050_1324183281","dateCreated":"2017-11-27T16:26:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:13882"},{"text":"%pyspark\n\nimport boto\nfrom boto.s3.key import Key\nfrom gzipstream import GzipStreamFile\nfrom pyspark.sql.types import *\nimport warc\n\n# New host graph is in file-index format, so can be parallelized.\nnodefiles = sc.textFile(\"s3://commoncrawl/projects/hyperlinkgraph/cc-main-2017-aug-sep-oct/hostgraph/vertices.paths.gz\") # 48 files (27.9GB)\nnodefiles.cache()\n    \ndef unpack(uri):\n    conn = boto.connect_s3(anon=True, host='s3.amazonaws.com')\n    bucket = conn.get_bucket('commoncrawl')\n    key_ = Key(bucket, uri)\n    print(key_)\n    file_ = GzipStreamFile(key_)\n    return file_\n\ndef process_nodes(id_, iterator):\n    for uri in iterator:\n        file = unpack(uri)\n        for record in file:\n            try:\n                (hostid, rev_host) = record.split()\n                yield hostid, rev_host\n            except Exception as e:\n                yield e\n        \nfiles = sc.parallelize(nodefiles.take(48), numSlices=48) # 48 total\nprint(files.getNumPartitions())\nrdd=files.mapPartitionsWithIndex(process_nodes)\n\nprint(str(rdd))\nrdd.take(3)\nhost_df = rdd.toDF([\"hostid\", \"host\"])\nhost_df.show(3)\n\n# NO! Load the host-level graph vertices in the same way\n#host_schema=StructType([StructField(\"hostid\", StringType(), False), StructField(\"host\", StringType(), False)])\n#host_txt=sc.textFile(\"s3://commoncrawl/projects/hyperlinkgraph/cc-main-2017-may-jun-jul/hostgraph/vertices.txt.gz\")\n#host_txt=sc.textFile(\"s3://commoncrawl/projects/hyperlinkgraph/cc-main-2017-aug-sep-oct/hostgraph/vertices.txt.gz\")\n#temp_host = host_txt.map(lambda k: k.split()) # By default, splits on whitespace, which is what we want\n#host_df=temp_host.toDF(host_schema) #.repartition(4)\n#host_df.show(3)\n\n# Save in an uncompressed, partitioned format, for fast reading in the future\n#saveURI=\"s3://billsdata.net/CommonCrawl/hyperlinkgraph/cc-main-2017-may-jun-jul/hostgraph/vertices/\"\nsaveURI=\"s3://billsdata.net/CommonCrawl/hyperlinkgraph/cc-main-2017-aug-sep-oct/hostgraph/vertices/\"\nhost_df.coalesce(64).write.save(saveURI) # Use all default options\n#host_df=spark.read.load(saveURI).repartition(64)\n#host_df.show(3)\nhost_df.cache()\nprint(host_df.count()) # Should have 1.3B hosts, or 5.6B!","user":"anonymous","dateUpdated":"2017-11-27T17:35:44+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"msg":[{"data":"","type":"TEXT"}]},"apps":[],"jobName":"paragraph_1511800007301_2052595521","id":"20170929-095310_1201506389","dateCreated":"2017-11-27T16:26:47+0000","dateStarted":"2017-11-27T17:35:44+0000","dateFinished":"2017-11-27T17:30:43+0000","status":"RUNNING","progressUpdateIntervalMs":500,"$$hashKey":"object:13883","errorMessage":""},{"text":"%pyspark\n\nimport boto\nfrom pyspark.sql.types import *\n\n# Load in all harmonic centrality and page-ranks, and join based on reverse domain name\n# Format: #hc_pos #hc_val #pr_pos #pr_val #host_rev\npr_schema=StructType([StructField(\"hc_pos\", StringType(), False), StructField(\"hc_val\", StringType(), False), StructField(\"pr_pos\", StringType(), False), StructField(\"pr_val\", StringType(), False), StructField(\"host_rev\", StringType(), False)])\n#pr_txt=sc.textFile(\"s3://commoncrawl/projects/hyperlinkgraph/cc-main-2017-may-jun-jul/domaingraph/ranks.txt.gz\")\npr_txt=sc.textFile(\"s3://commoncrawl/projects/hyperlinkgraph/cc-main-2017-aug-sep-oct/domaingraph/ranks.txt.gz\")\nheader=pr_txt.first()\npr_txt=pr_txt.filter(lambda x: x!=header)\ntemp_pr = pr_txt.map(lambda k: k.split()) # By default, splits on whitespace, which is what we want\npr_df=temp_pr.toDF(header.split()).withColumnRenamed(\"#host_rev\",\"host_rev\") #.limit(LIMIT*10) #.repartition(8)\n#pr_df.show(3)\n\n# Save in an uncompressed, partitioned format, for fast reading in the future\n#saveURI=\"s3://billsdata.net/CommonCrawl/hyperlinkgraph/cc-main-2017-may-jun-jul/domaingraph/ranks/\"\nsaveURI=\"s3://billsdata.net/CommonCrawl/hyperlinkgraph/cc-main-2017-aug-sep-oct/domaingraph/ranks/\"\npr_df.coalesce(64).write.save(saveURI) # Use all default options\n#pr_df=spark.read.load(saveURI)\npr_df.show(3)\npr_df.cache()\npr_df.count() # Should be 91M/93M","user":"anonymous","dateUpdated":"2017-11-27T16:32:40+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1511800007301_2052595521","id":"20170929-093202_1772383833","dateCreated":"2017-11-27T16:26:47+0000","dateStarted":"2017-11-27T16:32:40+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:13884","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+-----------+-------+--------------------+------------+\n|#hc_pos|    #hc_val|#pr_pos|             #pr_val|    host_rev|\n+-------+-----------+-------+--------------------+------------+\n|      1|2.4624394E7|      1| 0.01616200977123703|com.facebook|\n|      2|2.2489142E7|      3|0.009681990632289922|  com.google|\n|      3|2.2230666E7|      4|0.009430538325706608| com.twitter|\n+-------+-----------+-------+--------------------+------------+\nonly showing top 3 rows\n\n93111025\n"}]},"dateFinished":"2017-11-27T16:54:28+0000"},{"text":"%pyspark\n\n# Debug partitioning of our 4 big dataframes\nsc.getConf().getAll() #.mkString(\"\\n\")\nprint(pld_df.rdd.getNumPartitions())\nprint(pld_edges_df.rdd.getNumPartitions())\nprint(host_df.rdd.getNumPartitions())\npr_df.rdd.getNumPartitions()","dateUpdated":"2017-11-27T16:57:12+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-1281961651351408007.py\", line 367, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-1281961651351408007.py\", line 355, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 2, in <module>\nNameError: name 'pld_df' is not defined\n\n"}]},"apps":[],"jobName":"paragraph_1511800007301_2052595521","id":"20171006-161509_1868852031","dateCreated":"2017-11-27T16:26:47+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:13885","user":"anonymous","dateFinished":"2017-11-27T16:57:12+0000","dateStarted":"2017-11-27T16:57:12+0000"},{"text":"%pyspark #--packages graphframes:graphframes:0.5.0-spark2.1-s_2.11\n\n# We now have everything we need in these four dataframes to create the summaries we need.\n\n# This code can't handle the complete edge lists, and produces this exception:\n# java.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE\n#out_degrees_=dict(pld_edges_df.groupBy(\"src\").count().collect())\n#in_degrees=dict(pld_edges_df.groupBy(\"dst\").count().collect())\n#print(out_degrees['846558'])\n#print(in_degrees['846558'])\n\n# Instead, just create RDDs and use lookup()\nout_degrees=pld_edges_df.groupBy(\"src\").count()\nin_degrees=pld_edges_df.groupBy(\"dst\").count()\npld_edges_df.unpersist()\nout_degrees.show(3)\nin_degrees.show(3)\n#print(out_degrees.rdd.lookup(846558))\n#print(in_degrees.rdd.lookup(846558))","dateUpdated":"2017-11-27T16:26:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+-----+\n|     src|count|\n+--------+-----+\n|13208927|    3|\n|13209857|    1|\n|13210113|   12|\n+--------+-----+\nonly showing top 3 rows\n\n+--------+-----+\n|     dst|count|\n+--------+-----+\n|      29|   40|\n|36750820|    5|\n|61427989| 3242|\n+--------+-----+\nonly showing top 3 rows\n\n"}]},"apps":[],"jobName":"paragraph_1511800007301_2052595521","id":"20170929-095727_1596943627","dateCreated":"2017-11-27T16:26:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:13886"},{"text":"%pyspark\n\n# Next, we'll construct a local dictionary from of all the PLDS (key is the PLD, value is the ID)\n# This is our truth-table of known PLDs that we'll use when counting hosts\n# This code can't handle the full PLD list and produces this exception:\n# Stack trace: ExitCodeException exitCode=52\n#pld_lookup_table=dict(pld_df.rdd.map(lambda x: (x['PLD'], x['ID'])).collect()) # Bad!\n#print(pld_lookup_table[\"aaa.aaa\"])\n\n# Instead, just create an RDD and use lookup()\n#pld_lookup_table=pld_df.rdd.map(lambda x: (x['PLD'], x['ID']))\n#print(pld_lookup_table.lookup(\"aaa.aaa\")) # Very bad!\n\n# Or let's try creating as a BloomFilter, since we only want to record presence of a PLD\n#pld_bf = pld_df.stat.bloomFilter(\"PLD\", expectedNumItems, fpp) # Doesn't exist in pyspark API!\n#pld_bf.mightContain(\"aaa.aaa\")\n\n# Create a bloom filter using a pure python package (might be a little slow)\nfrom pybloom import BloomFilter\npld_bf = BloomFilter(capacity=91000000, error_rate=0.005)\n\nfor row in pld_df.rdd.collect(): # limit(10000000) # TODO: Still bad (and exceeds spark.driver.maxResultSize with all rows)!\n    pld_bf.add(row['PLD'])\n\nprint(pld_df.rdd.take(3))\nprint(pld_df.rdd.take(3)[2]['PLD'])\n#pld_bf.add(pld_df.rdd.take(3)[2]['PLD'])\nprint(\"aaa.aaa\" in pld_bf) # Should be True\n\n# TODO: Fix this distributed BloomFilter implementation - can't figure out how to properly combine BFs in a reduce operation!\n#tmp=pld_df.rdd.map(lambda x: pld_bf.add(x['PLD'])) # Very bad - pld_bf gets copied to each of the workers then discarded!\n#tmp=pld_df.rdd.map(lambda x: (pld_bf.add(x['PLD']), pld_bf)).reduce(lambda x,y: x[1].union(y[1])) # Should work but complains that BloomFilter isn't iterable!\n#print(tmp.take(3))\n#print(tmp.count()) # Ensure it runs the map across the entire dataframe\n\nimport sys\nprint(sys.getsizeof(pld_bf))\nprint(len(pld_bf)) # Should match number of items entered\n\n# Broadcast the bloom filter so it's available on all the slave nodes - we don't need to change\n# it any more so it's fine being immutable.\npld_bf_distrib=sc.broadcast(pld_bf)\n\nprint(\"aaa.aaa\" in pld_bf) # Should be true\nprint(\"aaa.aaa.bla\" in pld_bf) # Should be false\nprint(\"aaa.aaa\" in pld_bf_distrib.value) # Should be true\nprint(\"aaa.aaa.bla\" in pld_bf_distrib.value) # Should be false","dateUpdated":"2017-11-27T16:26:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[Row(ID=u'0', PLD=u'aaa.a'), Row(ID=u'1', PLD=u'aaa.aa'), Row(ID=u'2', PLD=u'aaa.aaa')]\naaa.aaa\nTrue\n64\n90751305\nTrue\nFalse\nTrue\nFalse\n"}]},"apps":[],"jobName":"paragraph_1511800007302_2053749768","id":"20170929-100048_2070118110","dateCreated":"2017-11-27T16:26:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:13887"},{"text":"%pyspark\n\n# Returns a Boolean to say whether PLD is a hostname in itself\ndef is_a_pld(hostname):\n    #if hostname in pld_lookup_table:\n    #if pld_lookup_table.filter(lambda a: a == hostname).count()>0:\n    if hostname in pld_bf_distrib.value:\n        return True\n    else:\n        return False\n        \n# Define a function to do the hostname->pld conversion, if the pld exists in our dictionary \ndef convert_hostname(hostname):\n    # Return hostname as-is, if this is already a PLD\n    #if hostname in pld_lookup_table:\n    #if pld_lookup_table.filter(lambda a: a == hostname).count()>0:\n    if hostname in pld_bf_distrib.value:\n        return hostname\n    # Otherwise we're going to have to split it up and test the parts\n    try:\n        parts=hostname.split('.')\n        if (len(parts)>4 and is_a_pld('.'.join(parts[0:4]))):\n            return '.'.join(parts[0:4])\n        if (len(parts)>3 and is_a_pld('.'.join(parts[0:3]))):\n            return '.'.join(parts[0:3])\n        if (len(parts)>2 and is_a_pld('.'.join(parts[0:2]))):\n            return '.'.join(parts[0:2])\n        if (len(parts)>1 and is_a_pld('.'.join(parts[0:1]))):\n            return '.'.join(parts[0:1])\n        return \"ERROR\" # Couldn't find a corresponding PLD - this should never happen!\n    except:\n        return \"ERROR\"\n        \n# Test\nprint(convert_hostname(\"aaa.aaa\"))\nprint(is_a_pld(\"aaa.aaa\")) # Should be true","dateUpdated":"2017-11-27T16:26:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"aaa.aaa\nTrue\n"}]},"apps":[],"jobName":"paragraph_1511800007302_2053749768","id":"20171004-091447_4214261","dateCreated":"2017-11-27T16:26:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:13888"},{"text":"%pyspark\n\n# Now count the number of hosts per PLD in a scalable way, and create another dictionary\n# Still takes over an hour since host_df contains 1.3B rows but should complete without errors.\n# (An attempt to collectAsMap at the end results in java Integer.MAX_VALUE or memory errors!)\ncount_rdd=host_df.drop('hostid').rdd.map(lambda x: (convert_hostname(x['host']),1)).reduceByKey(lambda x,y: x+y) #.collectAsMap() # Consider using a CountMin sketch here in future?\nbool_rdd=host_df.drop('hostid').rdd.map(lambda x: (x['host'], is_a_pld(x['host']))).filter(lambda x: x[1]==True) #.collectAsMap() # Only outputs PLD hosts (so <91M rows)\n\nprint(count_rdd.take(3))\nprint(bool_rdd.take(3))\nprint(count_rdd.count())\nprint(bool_rdd.count())\n\nhost_df.unpersist()\n\n# Debugging\nprint(count_rdd.filter(lambda x: x[0]=='aaa.aaa').collect())\nprint(len(count_rdd.filter(lambda x: x[0]=='ERROR').collect())) # Should be zero once we've loaded all the PLDs!","dateUpdated":"2017-11-27T16:26:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[(u'jp.kids-labo', 1), (u'org.g7fyp39crg0065nzu94cq1m4e35k793os', 1), (u'org.palletizer', 1)]\n[(u'cn.bjbworld', True), (u'cn.bjcnw', True), (u'cn.bjcxbz36', True)]\n90839924\n89276336\n[(u'aaa.aaa', 6)]\n1\n"}]},"apps":[],"jobName":"paragraph_1511800007302_2053749768","id":"20171004-092350_1522843259","dateCreated":"2017-11-27T16:26:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:13889"},{"text":"%pyspark\n\nfrom pyspark.sql.functions import col, when, lit\n\n# The following code works well when the data is small enough to collect into a python dictionary but our data is too big:\n# Define a UDF to perform column-based lookup\n#def translate(mapping):\n#    def translate_(col):\n#        if not mapping.get(col):\n#            return 0\n#        else:\n#            return mapping.get(col)\n#    return udf(translate_, IntegerType())\n# And a similar function for the Boolean map\n#def translate_bool(mapping):\n#    def translate_bool_(col):\n#        if not mapping.get(col):\n#            return False\n#        else:\n#            return mapping.get(col)\n#    return udf(translate_bool_, BooleanType())\n# Insert our count column back into the host summary dataframe, along with a boolean to say whether the PLD is a host in itself\n# While we're at it, let's add in the in and out-degrees too, and an indicator of whether the site has been crawled.\n#crawled_test=when(col(\"OutDegree\")==0, lit(False)).otherwise(lit(True))\n#pld_df_joined=pld_df.withColumn('NumHosts', translate(count_table)(\"PLD\"))\\\n                    #.withColumn('PLDisHost?', translate_bool(bool_table)(\"PLD\"))\n                    #.withColumn('InDegree', translate(in_degrees)(\"ID\"))\\\n                    #.withColumn('OutDegree', translate(out_degrees)(\"ID\"))\\\n                    #.withColumn('Crawled?', crawled_test)\n                    \n# Convert the result RDDs to dataframes, ready for joining\ncountschema=StructType([StructField(\"PLD2\", StringType(), False), StructField(\"numHosts\", LongType(), False)])\ncount_df=count_rdd.toDF(countschema)\ncount_df.show(3)\nboolschema=StructType([StructField(\"PLD2\", StringType(), False), StructField(\"PLDtest\", BooleanType(), False)])\nbool_df=bool_rdd.toDF(boolschema)\nbool_df.show(3)\n\n# Join these new dataframes with the original dataframe (using fast equi-joins)\npld_df2=pld_df.join(count_df, count_df.PLD2==pld_df.PLD, \"leftOuter\").drop(\"PLD2\")\nbool_test=when(col(\"PLDtest\").isNull(), lit(False)).otherwise(lit(True))\npld_df_joined=pld_df2.join(bool_df, bool_df.PLD2==pld_df2.PLD, \"leftOuter\").drop(\"PLD2\").withColumn('pldIsHostFlag', bool_test).drop(\"PLDtest\")\n\npld_df.unpersist()\npld_df_joined.sort(\"numHosts\", ascending=False).show(100)\npld_df_joined.cache()","dateUpdated":"2017-11-27T16:26:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+--------+\n|                PLD2|numHosts|\n+--------------------+--------+\n|        jp.kids-labo|       1|\n|org.g7fyp39crg006...|       1|\n|      org.palletizer|       1|\n+--------------------+--------+\nonly showing top 3 rows\n\n+-----------+-------+\n|       PLD2|PLDtest|\n+-----------+-------+\n|  aaa.bzzzz|   true|\n|   abc.2020|   true|\n|abc.tenmien|   true|\n+-----------+-------+\nonly showing top 3 rows\n\n+--------+--------------------+--------+-------------+\n|      ID|                 PLD|numHosts|pldIsHostFlag|\n+--------+--------------------+--------+-------------+\n| 8851519|           com.533b8|24285866|         true|\n|17565198|     com.composesite|15089842|         true|\n|23766155|com.getrichandgiv...|14513586|         true|\n|15069492|      com.bumpbabyme|13727426|         true|\n|35854802|        com.ourssite|12917619|         true|\n|14175746|        com.blogspot|12717586|         true|\n|14175787|        com.blogspot|12717586|         true|\n|13107744|          com.bbddaa|12620057|         true|\n|23394611|   com.game-stalkers|11675096|         true|\n|49161638|          com.zzmmaa|11535747|         true|\n|46884574|       com.w3cdomain|10147845|         true|\n|49160413|          com.zzjxtz| 9339180|        false|\n|47797089|       com.wordpress| 8883234|         true|\n|47797448|       com.wordpress| 8883234|         true|\n|30438975|           com.liao1| 8443777|         true|\n|42173462|          com.ssygjy| 7565218|         true|\n|45502088|          com.tumblr| 6636904|         true|\n|45502107|          com.tumblr| 6636904|         true|\n|42654327|     com.sucicurtain| 6566229|         true|\n|78999209|   org.securityscans| 6124364|         true|\n|41411386|         com.skyrock| 4951491|         true|\n|41411388|         com.skyrock| 4951491|         true|\n|19286912|      com.deviantart| 3265581|         true|\n|19286914|      com.deviantart| 3265581|         true|\n|28105741|           com.jnhgy| 2936233|         true|\n|31223538|com.luohaophotogr...| 2761719|         true|\n|47973485|          com.wwwbfh| 2409961|         true|\n|49150863|          com.zynews| 2340181|         true|\n|75514852|        online.yh834| 2279716|         true|\n|75514972|        online.yh989| 2279497|         true|\n|23267769|        com.fuzhouwl| 2138973|         true|\n|30739332|     com.livejournal| 2017689|         true|\n|31184970|    com.lugechuanmei| 1987046|         true|\n|71673306|            net.skur| 1981307|         true|\n|75514789|        online.yh759| 1919211|         true|\n|75514841|        online.yh821| 1918662|         true|\n|75514875|        online.yh861| 1918563|         true|\n|75514808|        online.yh784| 1917710|         true|\n|75514834|        online.yh812| 1917362|         true|\n|75514937|        online.yh944| 1915955|         true|\n|75514885|        online.yh874| 1915907|         true|\n|75514882|        online.yh871| 1915649|         true|\n|75514976|        online.yh995| 1913024|         true|\n|12689286|    com.backstagefix| 1860924|         true|\n|76377021|        org.chinamsg| 1847439|         true|\n|76377277|         org.chinapy| 1845723|         true|\n|22288972|     com.filetransit| 1821935|         true|\n|46885624|         com.w3snoop| 1792685|         true|\n|12642852|   com.babesvsrobots| 1756975|         true|\n|23595664|    com.geekgivepeek| 1750995|         true|\n|26613929|     com.iklangadget| 1746655|         true|\n|46799259|        com.voterlux| 1742350|         true|\n|30566518|       com.limemouse| 1736312|         true|\n|12747003|    com.bailedeltubo| 1726284|         true|\n|13320770|  com.beijingyourway| 1721778|         true|\n|42803824|    com.superkyuhyun| 1719247|         true|\n|17754673|      com.coolgigllc| 1710996|         true|\n|38584376|        com.recrocon| 1709465|         true|\n|19751104|           com.dnwjw| 1695455|         true|\n|39895366| com.samjonessextape| 1692086|         true|\n|27322776|      com.isignmeout| 1687903|         true|\n|19943989|    com.dotnetmaniac| 1679625|         true|\n|27736708|      com.jba-engine| 1679069|         true|\n|14864319|      com.brolithium| 1675511|         true|\n|19674265|          com.djixas| 1671565|         true|\n|44242732|       com.theoxhorn| 1655233|         true|\n|21350113|       com.ericneill| 1598189|         true|\n|75514851|        online.yh833| 1551012|         true|\n|75514801|        online.yh776| 1550725|         true|\n|75514847|        online.yh827| 1550570|         true|\n|75514962|        online.yh976| 1549767|         true|\n|75514895|        online.yh887| 1549574|         true|\n|75514793|        online.yh763| 1549447|         true|\n|75514933|        online.yh940| 1549330|         true|\n|75514892|        online.yh882| 1549150|         true|\n|75514795|        online.yh767| 1549021|         true|\n|75514898|        online.yh892| 1548588|         true|\n|75514922|        online.yh923| 1548043|         true|\n|75514956|        online.yh969| 1547897|         true|\n|75514873|        online.yh859| 1545915|         true|\n|75514857|        online.yh839| 1543871|         true|\n|38109522|        com.queit21g| 1503882|         true|\n|12635969|          com.babajj| 1468376|         true|\n| 7830191|        co.caller-id| 1381571|         true|\n|22090737|             com.fc2| 1360713|         true|\n|22090711|             com.fc2| 1360713|         true|\n|69702382|        net.eachtong| 1340854|         true|\n| 7182925|         cn.fjmeilun| 1338282|         true|\n| 7147207|           cn.dq2918| 1329916|        false|\n| 7358421|          cn.jinwolf| 1329710|        false|\n|32134194|     com.mayienglish| 1325006|         true|\n| 7332379|           cn.hzhemu| 1320528|        false|\n| 6920418|        cn.cnzhizhen| 1317289|        false|\n| 7201787|           cn.gdlswy| 1307459|         true|\n| 6917185|            cn.cn-oy| 1306957|         true|\n| 7130482|    cn.datongcompany| 1306765|        false|\n| 7143733|         cn.dmmarket| 1304280|        false|\n| 7288576|     cn.hailinfengde| 1300478|        false|\n| 7148929|           cn.dsenta| 1299703|         true|\n| 7205524|          cn.giantcn| 1297858|         true|\n+--------+--------------------+--------+-------------+\nonly showing top 100 rows\n\nDataFrame[ID: string, PLD: string, numHosts: bigint, pldIsHostFlag: boolean]\n"}]},"apps":[],"jobName":"paragraph_1511800007303_2053365019","id":"20171004-100819_284908525","dateCreated":"2017-11-27T16:26:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:13890"},{"text":"%pyspark\n\n# Join with in-degree and out-degree dataframes\npld_df_joined2=pld_df_joined.join(out_degrees, out_degrees.src==pld_df_joined.ID, \"leftOuter\").drop(\"src\").withColumnRenamed(\"count\",\"pldLinksOut\")\npld_df_joined.unpersist()\npld_df_joined3=pld_df_joined2.join(in_degrees, in_degrees.dst==pld_df_joined2.ID, \"leftOuter\").drop(\"dst\").withColumnRenamed(\"count\",\"pldLinksIn\")\npld_df_joined2.unpersist()\npld_df_joined3.show(5)\npld_df_joined3.cache()","dateUpdated":"2017-11-27T16:26:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----+--------------------+--------+-------------+-----------+----------+\n|  ID|                 PLD|numHosts|pldIsHostFlag|pldLinksOut|pldLinksIn|\n+----+--------------------+--------+-------------+-----------+----------+\n|  26|             abb.nic|       3|         true|          2|         3|\n|  29|abbott.corelabora...|       2|         true|         34|        40|\n| 474|     ac.americancars|       1|         true|       null|         3|\n| 964|              ac.cmt|       1|        false|          1|      null|\n|1677|          ac.insight|       1|         true|          7|         1|\n+----+--------------------+--------+-------------+-----------+----------+\nonly showing top 5 rows\n\nDataFrame[ID: string, PLD: string, numHosts: bigint, pldIsHostFlag: boolean, pldLinksOut: bigint, pldLinksIn: bigint]\n"}]},"apps":[],"jobName":"paragraph_1511800007303_2053365019","id":"20171006-152234_1487383953","dateCreated":"2017-11-27T16:26:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:13891"},{"text":"%pyspark\n\n# Insert a flag to indicate whether the PLD has been crawled\ncrawled_test=when(col(\"pldLinksOut\").isNull(), lit(False)).otherwise(lit(True))\npld_df_joined4=pld_df_joined3.withColumn('wasCrawledFlag', crawled_test)\npld_df_joined3.unpersist()\npld_df_joined4.show(5)\npld_df_joined4.cache()","dateUpdated":"2017-11-27T16:26:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----+--------------------+--------+-------------+-----------+----------+--------------+\n|  ID|                 PLD|numHosts|pldIsHostFlag|pldLinksOut|pldLinksIn|wasCrawledFlag|\n+----+--------------------+--------+-------------+-----------+----------+--------------+\n|  26|             abb.nic|       3|         true|          2|         3|          true|\n|  29|abbott.corelabora...|       2|         true|         34|        40|          true|\n| 474|     ac.americancars|       1|         true|       null|         3|         false|\n| 964|              ac.cmt|       1|        false|          1|      null|          true|\n|1677|          ac.insight|       1|         true|          7|         1|          true|\n+----+--------------------+--------+-------------+-----------+----------+--------------+\nonly showing top 5 rows\n\nDataFrame[ID: string, PLD: string, numHosts: bigint, pldIsHostFlag: boolean, pldLinksOut: bigint, pldLinksIn: bigint, wasCrawledFlag: boolean]\n"}]},"apps":[],"jobName":"paragraph_1511800007303_2053365019","id":"20171006-155148_681542412","dateCreated":"2017-11-27T16:26:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:13892"},{"text":"%pyspark\n\n# Finally, join with the harmonic centrality and page-rank for each domain\n# Note: could probably speed this up using something like above techniques, or by presorting (but we don't really need to since this is only 91Mx91M)\npld_df_joined5=pld_df_joined4.join(pr_df, pr_df.host_rev==pld_df_joined4.PLD, \"leftOuter\").drop(\"host_rev\")\\\n                             .withColumnRenamed(\"#hc_val\",\"HarmonicCentrality\").withColumnRenamed(\"#pr_val\",\"PageRank\")\\\n                             .withColumnRenamed(\"#hc_pos\",\"hc_pos\").withColumnRenamed(\"#pr_pos\",\"pr_pos\")\npld_df_joined4.unpersist()\npld_df_joined5.show(5)\npld_df_joined5.cache()","dateUpdated":"2017-11-27T16:26:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----+--------------------+--------+-------------+-----------+----------+--------------+--------+------------------+--------+--------------------+\n|  ID|                 PLD|numHosts|pldIsHostFlag|pldLinksOut|pldLinksIn|wasCrawledFlag|  hc_pos|HarmonicCentrality|  pr_pos|            PageRank|\n+----+--------------------+--------+-------------+-----------+----------+--------------+--------+------------------+--------+--------------------+\n| 120|             abc.web|       1|        false|       null|         1|         false|38991028|          10015440| 1478887|3.78405976859536e-08|\n| 311|             ac.8411|       1|        false|       null|         1|         false|69935624|           9082498|36930613|4.76481484534919e-09|\n| 713|              ac.bgc|       1|        false|       null|         1|         false|63729192|           9237769|32796120|4.90517712841288e-09|\n| 871|          ac.casinos|       1|         true|          2|         1|          true|78150671|         7839579.5|12855010|7.68640254732439e-09|\n|1014|ac.cosmopolitanun...|       1|         true|       null|        18|         false| 1636792|          12615973|20034471|5.85933334251156e-09|\n+----+--------------------+--------+-------------+-----------+----------+--------------+--------+------------------+--------+--------------------+\nonly showing top 5 rows\n\nDataFrame[ID: string, PLD: string, numHosts: bigint, pldIsHostFlag: boolean, pldLinksOut: bigint, pldLinksIn: bigint, wasCrawledFlag: boolean, hc_pos: string, HarmonicCentrality: string, pr_pos: string, PageRank: string]\n"}]},"apps":[],"jobName":"paragraph_1511800007304_2051441274","id":"20170929-122540_264490752","dateCreated":"2017-11-27T16:26:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:13893"},{"text":"%pyspark\n\n# Save final table to S3 in compressed CSV format, broken into smaller files\noutputURI=\"s3://billsdata.net/CommonCrawl/domain_summaries5/\"\ncodec=\"org.apache.hadoop.io.compress.GzipCodec\"\n#pld_df_joined5.coalesce(1).write.format('com.databricks.spark.csv').options(header='true', codec=codec).save(outputURI)\npld_df_joined5.write.save(outputURI)","dateUpdated":"2017-11-27T16:26:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1511800007304_2051441274","id":"20170929-123834_882164555","dateCreated":"2017-11-27T16:26:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:13894"},{"text":"%pyspark\n\n# Clean up some objects to free memory if needed!\ncount_rdd.unpersist()\ncount_df.unpersist()\nbool_rdd.unpersist()\nbool_df.unpersist()\nin_degrees.unpersist()\nout_degrees.unpersist()\npld_edges_df.unpersist()\npld_bf_distrib.unpersist()\n\n# Encourage a garbage collection!\nimport gc\ncollected = gc.collect()\nprint \"Garbage collector: collected %d objects.\" % collected","dateUpdated":"2017-11-27T16:26:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Garbage collector: collected 312 objects.\n"}]},"apps":[],"jobName":"paragraph_1511800007304_2051441274","id":"20170930-084538_879594277","dateCreated":"2017-11-27T16:26:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:13895"},{"text":"%pyspark\n\nfrom pyspark.sql.functions import udf, col, when, lit\ndef reverse_domain(domain):\n    return '.'.join(reversed(domain.split('.')))\nprint(reverse_domain(\"com.facebook.abc\"))\n\nudf_reverse_domain = udf(reverse_domain, StringType())\nsummary_df2=pld_df_joined5.drop(\"ID\").withColumnRenamed(\"PLD\",\"PLD_rev\").withColumn(\"payLevelDomain\",udf_reverse_domain(\"PLD_rev\")).drop(\"PLD_rev\").drop(\"HarmonicCentrality\").drop(\"PageRank\")\nsummary_df2.show(3)\nsummary_df2.cache()","dateUpdated":"2017-11-27T16:26:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"abc.facebook.com\n+--------+-------------+-----------+----------+--------------+--------+--------+--------------+\n|numHosts|pldIsHostFlag|pldLinksOut|pldLinksIn|wasCrawledFlag|  hc_pos|  pr_pos|payLevelDomain|\n+--------+-------------+-----------+----------+--------------+--------+--------+--------------+\n|       1|        false|       null|         1|         false|38991028| 1478887|       web.abc|\n|       1|        false|       null|         1|         false|69935624|36930613|       8411.ac|\n|       1|        false|       null|         1|         false|63729192|32796120|        bgc.ac|\n+--------+-------------+-----------+----------+--------------+--------+--------+--------------+\nonly showing top 3 rows\n\nDataFrame[numHosts: bigint, pldIsHostFlag: boolean, pldLinksOut: bigint, pldLinksIn: bigint, wasCrawledFlag: boolean, hc_pos: string, pr_pos: string, payLevelDomain: string]\n"}]},"apps":[],"jobName":"paragraph_1511800007305_2051056525","id":"20171012-142038_800861977","dateCreated":"2017-11-27T16:26:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:13896"},{"text":"%pyspark\n\n# Convert HC and PR positions to a rank (with 3dp, out of 100, where 100 is the most popular)\nCOUNT=int(91034128)\ndef rank(pos):\n    return \"{0:.3f}\".format(((COUNT-float(pos))/COUNT)*100)\nprint(rank(1478887))\n\nudf_rank=udf(rank, StringType())\n\nsummary_df3=summary_df2.withColumn(\"hcRank\", udf_rank(\"hc_pos\")).drop(\"hc_pos\").withColumn(\"prRank\", udf_rank(\"pr_pos\")).drop(\"pr_pos\")\nsummary_df2.unpersist()\nsummary_df3.show(3)\nsummary_df3.cache()","dateUpdated":"2017-11-27T16:26:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"98.375\n+--------+-------------+-----------+----------+--------------+--------------+------+------+\n|numHosts|pldIsHostFlag|pldLinksOut|pldLinksIn|wasCrawledFlag|payLevelDomain|hcRank|prRank|\n+--------+-------------+-----------+----------+--------------+--------------+------+------+\n|       1|        false|       null|         1|         false|       web.abc|57.169|98.375|\n|       1|        false|       null|         1|         false|       8411.ac|23.176|59.432|\n|       1|        false|       null|         1|         false|        bgc.ac|29.994|63.974|\n+--------+-------------+-----------+----------+--------------+--------------+------+------+\nonly showing top 3 rows\n\nDataFrame[numHosts: bigint, pldIsHostFlag: boolean, pldLinksOut: bigint, pldLinksIn: bigint, wasCrawledFlag: boolean, payLevelDomain: string, hcRank: string, prRank: string]\n"}]},"apps":[],"jobName":"paragraph_1511800007305_2051056525","id":"20171018-084715_2002456320","dateCreated":"2017-11-27T16:26:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:13897"},{"text":"%pyspark\n\n# Re-order the columns for final output\nsummary_df4=summary_df3.select(\"payLevelDomain\",\"numHosts\",\"pldIsHostFlag\",\"pldLinksIn\",\"pldLinksOut\",\"wasCrawledFlag\",\"hcRank\",\"prRank\")\nsummary_df3.unpersist()\nsummary_df4.show(3)\nsummary_df4.cache()","dateUpdated":"2017-11-27T16:26:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------+--------+-------------+----------+-----------+--------------+------+------+\n|payLevelDomain|numHosts|pldIsHostFlag|pldLinksIn|pldLinksOut|wasCrawledFlag|hcRank|prRank|\n+--------------+--------+-------------+----------+-----------+--------------+------+------+\n|       web.abc|       1|        false|         1|       null|         false|57.169|98.375|\n|       8411.ac|       1|        false|         1|       null|         false|23.176|59.432|\n|        bgc.ac|       1|        false|         1|       null|         false|29.994|63.974|\n+--------------+--------+-------------+----------+-----------+--------------+------+------+\nonly showing top 3 rows\n\nDataFrame[payLevelDomain: string, numHosts: bigint, pldIsHostFlag: boolean, pldLinksIn: bigint, pldLinksOut: bigint, wasCrawledFlag: boolean, hcRank: string, prRank: string]\n"}]},"apps":[],"jobName":"paragraph_1511800007305_2051056525","id":"20171018-162242_1138437034","dateCreated":"2017-11-27T16:26:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:13898"},{"text":"%pyspark\n\n# Let's take a look at the final table before saving it\nsummary_df4.sort(\"numHosts\", ascending=False).show(100)","dateUpdated":"2017-11-27T16:26:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+--------+-------------+----------+-----------+--------------+-------+-------+\n|      payLevelDomain|numHosts|pldIsHostFlag|pldLinksIn|pldLinksOut|wasCrawledFlag| hcRank| prRank|\n+--------------------+--------+-------------+----------+-----------+--------------+-------+-------+\n|           533b8.com|24285866|         true|        11|         25|          true| 91.060| 54.579|\n|     composesite.com|15089842|         true|        35|         16|          true| 77.693| 97.294|\n|getrichandgivebac...|14513586|         true|         4|         91|          true| 81.341| 50.058|\n|      bumpbabyme.com|13727426|         true|        22|         27|          true| 94.114| 74.273|\n|        ourssite.com|12917619|         true|        50|         15|          true| 76.082| 97.610|\n|        blogspot.com|12717586|         true|   1588452|   14903607|          true|100.000|100.000|\n|        blogspot.com|12717586|         true|     22960|          1|          true|100.000|100.000|\n|          bbddaa.com|12620057|         true|       283|        318|          true| 74.704| 99.109|\n|   game-stalkers.com|11675096|         true|        11|         15|          true| 97.684| 96.532|\n|          zzmmaa.com|11535747|         true|       204|        318|          true| 71.988| 98.013|\n|       w3cdomain.com|10147845|         true|        24|          3|          true| 81.954| 79.761|\n|          zzjxtz.com| 9339180|        false|      null|          5|          true|  7.409|  7.408|\n|       wordpress.com| 8883234|         true|   1680789|   10061978|          true|100.000|100.000|\n|       wordpress.com| 8883234|         true|    411945|        253|          true|100.000|100.000|\n|           liao1.com| 8443777|         true|       453|        130|          true| 98.699| 99.741|\n|          ssygjy.com| 7565218|         true|         1|          5|          true| 20.913| 14.404|\n|          tumblr.com| 6636904|         true|    309366|       2132|          true|100.000|100.000|\n|          tumblr.com| 6636904|         true|    736900|         11|          true|100.000|100.000|\n|     sucicurtain.com| 6566229|         true|        11|         28|          true| 65.689| 40.605|\n|   securityscans.org| 6124364|         true|         4|        781|          true| 38.616| 98.862|\n|         skyrock.com| 4951491|         true|     24320|       3424|          true| 99.998| 99.994|\n|         skyrock.com| 4951491|         true|      1637|        453|          true| 99.998| 99.994|\n|      deviantart.com| 3265581|         true|    109767|       6720|          true|100.000| 99.999|\n|      deviantart.com| 3265581|         true|     22672|        295|          true|100.000| 99.999|\n|           jnhgy.com| 2936233|         true|         1|          5|          true| 44.808| 24.634|\n|luohaophotography...| 2761719|         true|         6|         21|          true| 75.716| 79.923|\n|          wwwbfh.com| 2409961|         true|         1|         32|          true| 64.351| 30.241|\n|          zynews.com| 2340181|         true|      1080|        290|          true| 98.749| 99.921|\n|        yh834.online| 2279716|         true|         6|         25|          true| 10.912| 95.202|\n|        yh989.online| 2279497|         true|         5|         25|          true| 10.900| 94.175|\n|        fuzhouwl.com| 2138973|         true|      null|        602|          true|  8.277|  8.277|\n|     livejournal.com| 2017689|         true|    180898|     434556|          true|100.000|100.000|\n|    lugechuanmei.com| 1987046|         true|      null|        602|          true|  8.017|  8.016|\n|            skur.net| 1981307|         true|         4|         32|          true| 85.484| 50.971|\n|        yh759.online| 1919211|         true|         5|         25|          true| 10.900| 92.278|\n|        yh821.online| 1918662|         true|         5|         25|          true| 10.900| 93.866|\n|        yh861.online| 1918563|         true|         5|         25|          true| 10.900| 95.454|\n|        yh784.online| 1917710|         true|         5|         25|          true| 10.900| 94.059|\n|        yh812.online| 1917362|         true|         5|         25|          true| 10.900| 93.866|\n|        yh944.online| 1915955|         true|         5|         25|          true| 10.900| 94.513|\n|        yh874.online| 1915907|         true|         5|         25|          true| 10.900| 94.674|\n|        yh871.online| 1915649|         true|         5|         25|          true| 10.900| 93.566|\n|        yh995.online| 1913024|         true|         5|         25|          true| 10.900| 94.674|\n|    backstagefix.com| 1860924|         true|         3|      29091|          true| 99.166| 98.500|\n|        chinamsg.org| 1847439|         true|         9|       1462|          true| 99.023| 92.681|\n|         chinapy.org| 1845723|         true|         7|       1467|          true| 72.504| 82.554|\n|     filetransit.com| 1821935|         true|      1194|         46|          true| 99.774| 99.951|\n|         w3snoop.com| 1792685|         true|       297|         25|          true| 99.849| 99.761|\n|   babesvsrobots.com| 1756975|         true|        50|       8678|          true| 93.384| 82.110|\n|    geekgivepeek.com| 1750995|         true|        43|       8672|          true| 76.116| 85.664|\n|     iklangadget.com| 1746655|         true|       109|       2216|          true| 95.270| 93.765|\n|        voterlux.com| 1742350|         true|       123|       2216|          true| 95.917| 90.592|\n|       limemouse.com| 1736312|         true|        47|       8636|          true| 76.256| 86.655|\n|    bailedeltubo.com| 1726284|         true|        92|       2216|          true| 70.923| 92.059|\n|  beijingyourway.com| 1721778|         true|        99|       2216|          true| 96.968| 93.221|\n|    superkyuhyun.com| 1719247|         true|        33|       8620|          true| 86.896| 77.339|\n|      coolgigllc.com| 1710996|         true|        97|       2216|          true| 77.721| 98.688|\n|        recrocon.com| 1709465|         true|        52|       8581|          true| 75.128| 82.991|\n|           dnwjw.com| 1695455|         true|         1|         16|          true| 49.091| 33.037|\n| samjonessextape.com| 1692086|         true|       109|       2216|          true| 76.231| 93.531|\n|      isignmeout.com| 1687903|         true|        48|       8544|          true| 75.380| 90.637|\n|    dotnetmaniac.com| 1679625|         true|        93|       2216|          true| 77.628| 99.350|\n|      jba-engine.com| 1679069|         true|        50|       8509|          true| 67.851| 78.952|\n|      brolithium.com| 1675511|         true|       122|       2216|          true| 96.480| 90.073|\n|          djixas.com| 1671565|         true|        69|       8252|          true| 97.747| 96.701|\n|       theoxhorn.com| 1655233|         true|       103|       2216|          true| 86.427| 91.722|\n|       ericneill.com| 1598189|         true|       117|       2216|          true| 96.209| 92.870|\n|        yh833.online| 1551012|         true|         4|         25|          true| 10.878| 93.020|\n|        yh776.online| 1550725|         true|         4|         25|          true| 10.878| 92.868|\n|        yh827.online| 1550570|         true|         4|         25|          true| 11.440| 91.728|\n|        yh976.online| 1549767|         true|         4|         25|          true| 10.878| 91.034|\n|        yh887.online| 1549574|         true|         4|         25|          true| 10.878| 93.020|\n|        yh763.online| 1549447|         true|         4|         25|          true| 10.878| 90.172|\n|        yh940.online| 1549330|         true|         4|         25|          true| 10.878| 93.983|\n|        yh882.online| 1549150|         true|         4|         25|          true| 11.877| 93.331|\n|        yh767.online| 1549021|         true|         4|         25|          true| 10.878| 91.034|\n|        yh892.online| 1548588|         true|         4|         25|          true| 10.878| 94.950|\n|        yh923.online| 1548043|         true|         4|         25|          true| 10.878| 91.034|\n|        yh969.online| 1547897|         true|         4|         25|          true| 10.878| 93.566|\n|        yh859.online| 1545915|         true|         4|         25|          true| 12.741| 90.365|\n|        yh839.online| 1543871|         true|         4|         25|          true| 10.878| 93.783|\n|        queit21g.com| 1503882|         true|        89|       2218|          true| 74.690| 92.201|\n|          babajj.com| 1468376|         true|         1|         32|          true| 47.524| 23.596|\n|        caller-id.co| 1381571|         true|         3|          4|          true| 98.902| 93.463|\n|             fc2.com| 1360713|         true|    173366|    2413473|          true|100.000|100.000|\n|             fc2.com| 1360713|         true|      1533|         29|          true|100.000|100.000|\n|        eachtong.net| 1340854|         true|        24|        312|          true| 71.649| 88.935|\n|         fjmeilun.cn| 1338282|         true|       215|      20799|          true| 12.546| 38.905|\n|           dq2918.cn| 1329916|        false|       219|      20800|          true| 12.546| 40.579|\n|          jinwolf.cn| 1329710|        false|       215|      20800|          true| 12.546| 37.739|\n|     mayienglish.com| 1325006|         true|      null|         39|          true|  7.984|  7.983|\n|           hzhemu.cn| 1320528|        false|       212|      20799|          true| 12.546| 33.839|\n|        cnzhizhen.cn| 1317289|        false|       215|      20800|          true| 12.546| 39.860|\n|           gdlswy.cn| 1307459|         true|       215|      20800|          true| 12.546| 33.840|\n|            cn-oy.cn| 1306957|         true|       221|      20800|          true| 12.546| 38.811|\n|    datongcompany.cn| 1306765|        false|       210|      20800|          true| 12.546| 37.323|\n|         dmmarket.cn| 1304280|        false|       214|      20800|          true| 12.546| 37.330|\n|     hailinfengde.cn| 1300478|        false|       213|      20799|          true| 12.546| 34.066|\n|           dsenta.cn| 1299703|         true|       215|      20800|          true| 12.546| 40.149|\n|          giantcn.cn| 1297858|         true|       211|      20798|          true| 12.546| 34.402|\n+--------------------+--------+-------------+----------+-----------+--------------+-------+-------+\nonly showing top 100 rows\n\n"}]},"apps":[],"jobName":"paragraph_1511800007306_2052210772","id":"20171018-160102_1527600638","dateCreated":"2017-11-27T16:26:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:13899"},{"text":"%pyspark\n\n# Save final table to S3 in compressed CSV format, broken into smaller files\noutputURI=\"s3://billsdata.net/CommonCrawl/domain_summaries7/\"\ncodec=\"org.apache.hadoop.io.compress.GzipCodec\"\nsummary_df4.coalesce(10).write.format('com.databricks.spark.csv').options(header='true', codec=codec).save(outputURI)","dateUpdated":"2017-11-27T16:26:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1511800007306_2052210772","id":"20171018-085036_2082191695","dateCreated":"2017-11-27T16:26:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:13900"},{"text":"%pyspark\n","dateUpdated":"2017-11-27T16:26:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1511800007307_2051826023","id":"20171018-175711_441001507","dateCreated":"2017-11-27T16:26:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:13901"}],"name":"Paul 5 - faster domain summary","id":"2D1UPX4D2","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}