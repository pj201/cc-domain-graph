{"paragraphs":[{"text":"%pyspark\n\n# PySpark CommonCrawl Topic Modelling\n# Tom V - 21/10/2017\n\nimport boto\nfrom boto.s3.key import Key\nfrom gzipstream import GzipStreamFile\nfrom pyspark.sql.types import *\nimport warc\nimport ujson as json\nfrom urlparse import urlparse\nfrom langdetect import detect_langs\n\nwetlist = sc.textFile(\"s3://commoncrawl/crawl-data/CC-MAIN-2017-04/wet.paths.gz\")\nwetlist.cache()\n\ndef unpack(uri):\n    conn = boto.connect_s3(anon=True, host='s3.amazonaws.com')\n    bucket = conn.get_bucket('commoncrawl')\n    key_ = Key(bucket, uri)\n    file_ = warc.WARCFile(fileobj=GzipStreamFile(key_))\n    return file_\n\ndef detect(x):\n    try:\n        return detect_langs(x[:300])[0].lang\n    except Exception as e:\n        return None\n\ndef process_wet(id_, iterator):\n    for uri in iterator:\n        file = unpack(uri)\n        for record in file:\n            try:\n                #url = record.rec_headers.get_header('WARC-Target-URI')\n                #yield record, record.content_stream().read().decode('utf-8')\n                url = record.url\n                domain = None if not url  else urlparse(url).netloc\n                text = record.payload.read().decode('utf-8')\n                lang = detect(text)\n                yield domain, url, lang, text\n            except Exception as e:\n                yield e","user":"anonymous","dateUpdated":"2017-10-21T08:27:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1508512401358_1750191306","id":"20171020-102243_1718178582","dateCreated":"2017-10-20T15:13:21+0000","dateStarted":"2017-10-21T08:27:48+0000","dateFinished":"2017-10-21T08:27:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:267"},{"text":"%pyspark\n# PARAMETER - number of input files\nnfiles = 256\n\n# PARAMETER - slices / partitions of input\nfiles = sc.parallelize(wetlist.take(nfiles), numSlices=64)\n\n# TODO: Make this use more than one CPU!\nprint(files.getNumPartitions())\nrdd = files.mapPartitionsWithIndex(process_wet)\n\ndocs = rdd.toDF([\"domain\", \"url\", \"lang\", \"text\"])\ndocs.cache()\n\ndocs.show()","user":"anonymous","dateUpdated":"2017-10-21T08:27:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"msg":[{"data":"","type":"TEXT"}]},"apps":[],"jobName":"paragraph_1508512401361_1759810028","id":"20171020-101220_2022546189","dateCreated":"2017-10-20T15:13:21+0000","dateStarted":"2017-10-21T08:27:48+0000","dateFinished":"2017-10-20T16:19:14+0000","status":"RUNNING","progressUpdateIntervalMs":500,"$$hashKey":"object:268","errorMessage":""},{"text":"%pyspark\n\ndocs_en = docs.filter(docs.lang == 'en')\n\n# PARAMETER - possibly set partitions?\ndocs_en = docs_en.repartition(64)","user":"anonymous","dateUpdated":"2017-10-21T08:27:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1508512401361_1759810028","id":"20171020-110218_1507019685","dateCreated":"2017-10-20T15:13:21+0000","dateStarted":"2017-10-21T08:27:48+0000","dateFinished":"2017-10-20T16:19:14+0000","status":"PENDING","progressUpdateIntervalMs":500,"$$hashKey":"object:269","errorMessage":""},{"text":"%pyspark\n\nstopwords_english = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn']\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import RegexTokenizer, CountVectorizer, StopWordsRemover\n\n# PARAMETER - regex tokenization\ntokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"\\\\p{L}{3,}\", gaps=False)\nstopwordRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\",stopWords=stopwords_english, caseSensitive=False)\n\n# PARAMETER - vocab size, min and max doc frequency\ncv = CountVectorizer(inputCol=\"filtered\", outputCol=\"vec\",vocabSize=20000, minDF=50) # reduced vocabSize from 100k to 20k to save memory\n\npipeline = Pipeline(stages=[tokenizer, stopwordRemover, cv])\nmodel = pipeline.fit(docs_en)\nvecs = model.transform(docs_en)\nvecs.show()","user":"anonymous","dateUpdated":"2017-10-21T08:27:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+--------------------+----+--------------------+--------------------+--------------------+--------------------+\n|              domain|                 url|lang|                text|               words|            filtered|                 vec|\n+--------------------+--------------------+----+--------------------+--------------------+--------------------+--------------------+\n|            1337x.to|http://1337x.to/t...|  en|Download Bhindi B...|[download, bhindi...|[download, bhindi...|(20000,[0,1,3,5,6...|\n|       909sickle.net|http://909sickle....|  en|Double Oh Duty\nab...|[double, duty, ab...|[double, duty, sa...|(20000,[5,16,53,7...|\n|          adioso.com|http://adioso.com...|  en|The best flights ...|[the, best, fligh...|[best, flights, f...|(20000,[0,5,6,10,...|\n|   akihabaranews.com|http://akihabaran...|  en|| AkihabaraNews S...|[akihabaranews, s...|[akihabaranews, s...|(20000,[0,5,7,9,1...|\n| alternativesite.net|http://alternativ...|  en|Alternative for 1...|[alternative, for...|[alternative, pre...|(20000,[0,1,3,5,1...|\n| animaldiversity.org|http://animaldive...|  en|ADW: Apotomops: C...|[adw, apotomops, ...|[adw, apotomops, ...|(20000,[5,17,19,2...|\n|      appshopper.com|http://appshopper...|  en|App Shopper: 和時計　...|[app, shopper, 和時...|[app, shopper, 和時...|(20000,[0,1,2,6,7...|\n|articles.baltimor...|http://articles.b...|  en|Popular veteran G...|[popular, veteran...|[popular, veteran...|(20000,[0,3,6,10,...|\n|    athlonsports.com|http://athlonspor...|  en|Athlon's Essentia...|[athlon, essentia...|[athlon, essentia...|(20000,[0,1,3,5,7...|\n|    baddaddytube.com|http://baddaddytu...|  en|Vocal fuck a fles...|[vocal, fuck, fle...|[vocal, fuck, fle...|(20000,[1,3,6,7,1...|\n|     batman-news.com|http://batman-new...|  en|New 52 - Red Hood...|[new, red, hood, ...|[new, red, hood, ...|(20000,[0,5,7,9,1...|\n|    betterlesson.com|http://betterless...|  en|Student Work.jpg ...|[student, work, j...|[student, work, j...|(20000,[0,3,5,10,...|\n|blanketfort.uninh...|http://blanketfor...|  en|disclaimer/warnin...|[disclaimer, warn...|[disclaimer, warn...|(20000,[27,68,249...|\n| blog.quinnipiac.edu|http://blog.quinn...|  en|» Professor Sean ...|[professor, sean,...|[professor, sean,...|(20000,[0,1,3,5,7...|\n|blogs.the-america...|http://blogs.the-...|  en|The American Inte...|[the, american, i...|[american, intere...|(20000,[0,1,5,10,...|\n|boatspecs.iboats.com|http://boatspecs....|  en|1990 Southern Cro...|[southern, cross,...|[southern, cross,...|(20000,[9,11,33,4...|\n|  britmovietours.com|http://britmoviet...|  en|Brit Movie Tours ...|[brit, movie, tou...|[brit, movie, tou...|(20000,[1,2,4,8,9...|\n|businessfinder.ml...|http://businessfi...|  en|Tabernacle of Jud...|[tabernacle, juda...|[tabernacle, juda...|(20000,[0,1,2,3,4...|\n|         calguns.net|http://calguns.ne...|  en|Who Posted? - Cal...|[who, posted, cal...|[posted, calguns,...|(20000,[38,41,53,...|\n|    catalogue.nli.ie|http://catalogue....|  en|Holdings: Her maj...|[holdings, her, m...|[holdings, majest...|(20000,[0,2,5,10,...|\n+--------------------+--------------------+----+--------------------+--------------------+--------------------+--------------------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1508512401362_1760964275","id":"20171020-101427_882065123","dateCreated":"2017-10-20T15:13:21+0000","dateStarted":"2017-10-20T20:57:18+0000","dateFinished":"2017-10-20T21:00:34+0000","status":"PENDING","progressUpdateIntervalMs":500,"$$hashKey":"object:270"},{"text":"%pyspark\n\n#Run the topic modelling\n\nfrom pyspark.ml.clustering import LDA\n#inputCol=\"vec\", outputCol=\"ldaVec\", k=3, optimizer=\"online\"\n\n# Fix java memory errors, perhaps using:\n# spark.driver.memory 256g - DIDN'T WORK\n# or by reducing vocabSize from 100k to 20k - WORKS!\n\nlda = LDA(k=100, maxIter=100, featuresCol=\"vec\")\nldaModel = lda.fit(vecs)\nprint(ldaModel.isDistributed())","user":"anonymous","dateUpdated":"2017-10-21T08:27:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-5732463703618195166.py\", line 367, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-5732463703618195166.py\", line 360, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 4, in <module>\nAttributeError: 'LDA' object has no attribute 'isDistributed'\n\n"}]},"apps":[],"jobName":"paragraph_1508512401362_1760964275","id":"20171020-101446_892258643","dateCreated":"2017-10-20T15:13:21+0000","dateStarted":"2017-10-20T21:01:48+0000","dateFinished":"2017-10-21T01:55:51+0000","status":"PENDING","progressUpdateIntervalMs":500,"$$hashKey":"object:271"},{"text":"%pyspark\n\n# Save the models\nldaModel.save('s3://billsdata.net/CommonCrawl/topic_model_256files/ldamodel')\npipeline.save('s3://billsdata.net/CommonCrawl/topic_model_256files/textpipeline')","user":"anonymous","dateUpdated":"2017-10-21T08:27:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1508512401363_1760579526","id":"20171020-124001_1609701105","dateCreated":"2017-10-20T15:13:21+0000","dateStarted":"2017-10-20T23:00:55+0000","dateFinished":"2017-10-21T01:56:10+0000","status":"PENDING","progressUpdateIntervalMs":500,"$$hashKey":"object:272"},{"text":"%pyspark\n\n# Get topic vectors for index pages (estimate of topic vec per domain)\n\nvecs_index = vecs.filter(\"url LIKE '%index.html'\")\nresults = ldaModel.transform(vecs_index)\n\n# Drop text cols\nresults2=results.drop('text').drop('words').drop('filtered')\n\n# Save domain topic vecs\nresults2.write.parquet('s3://billsdata.net/CommonCrawl/topic_model_256files/cc_index_page_topics.parquet')","user":"anonymous","dateUpdated":"2017-10-21T08:27:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1508512401363_1760579526","id":"20171020-124102_343731757","dateCreated":"2017-10-20T15:13:21+0000","dateStarted":"2017-10-21T01:55:51+0000","dateFinished":"2017-10-21T01:58:00+0000","status":"PENDING","progressUpdateIntervalMs":500,"$$hashKey":"object:273"},{"text":"%pyspark\n\n# Create a dataset containing just the host, url and top 3 topic labels & scores\n\nimport pandas as pd\nimport numpy as np\ntopicIndices = ldaModel.describeTopics(maxTermsPerTopic = 5).collect()\nvocab = model.stages[2].vocabulary\n\ntopic_labels = []\nfor i, (topic, terms, termWeights) in enumerate(topicIndices):\n    topwords = pd.Series(dict(zip([vocab[t] for t in terms], termWeights))).sort_values(ascending=False)\n    topic_labels.append('_'.join(topwords.index.values))\n\ntopic_labels = np.array(topic_labels)\n\ndef topTopics(x):\n    labels = topic_labels[np.argsort(x.topicDistribution)[::-1][:3]]\n    scores = np.sort(x.topicDistribution)[::-1][:3]\n    return (x.domain, x.url, str(labels[0]), float(scores[0]), str(labels[1]), float(scores[1]), str(labels[2]), float(scores[2]))\n\nresults3 = results2.rdd.map(topTopics)\nresults3 = results3.toDF([\"host\", \"url\", \"topic1\", \"score1\", \"topic2\", \"score2\", \"topic3\", \"score3\"])\n\nresults3.write.parquet('s3://billsdata.net/CommonCrawl/topic_model_256files/cc_index_page_topic_labels.parquet')\nresults3.show()","user":"anonymous","dateUpdated":"2017-10-21T08:27:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n|                host|                 url|              topic1|             score1|              topic2|              score2|              topic3|              score3|\n+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n|        nowretro.com|http://nowretro.c...|porn_sex_tube_big...| 0.9989964613360407|email_search_name...|1.934827854166181...|like_one_would_ge...|1.520965688788838E-5|\n| onlyamateurtube.com|http://onlyamateu...|porn_sex_tube_big...| 0.5909796072765714|views_videos_vide...| 0.32828038918474856|food_recipes_reci...| 0.04096231431567997|\n|       money.cnn.com|http://money.cnn....|market_energy_com...| 0.3001351025451066|said_people_news_...| 0.16049798144775618|offer_credit_bank...|  0.1006166940895161|\n|       idlebrain.com|http://idlebrain....|art_movie_movies_...| 0.6849752482814744|photo_image_herit...| 0.13877600868871826|com_http_www_org_net|  0.1367208427098497|\n|      lvx.tripod.com|http://lvx.tripod...|church_god_bible_...| 0.6182698205816841|shipping_order_pr...|  0.1357727539039878|tutoring_one_also...|   0.127051518655225|\n|lesbian-sapphic-e...|http://lesbian-sa...|porn_sex_tube_big...| 0.9975070296105998|church_god_bible_...|9.614505413466535E-4| dec_nov_oct_mar_feb|7.581462548444677E-4|\n|prod.www.49ers.cl...|http://prod.www.4...|news_sports_new_g...| 0.6469746479310147|college_school_un...| 0.12518619721285612|sports_golf_baske...| 0.05233916718009717|\n| hackage.haskell.org|http://hackage.ha...|add_cart_view_pri...| 0.7424359223680268|data_system_using...| 0.16320541147057646|music_quot_piano_...| 0.07408551291820058|\n|     juicyteenie.com|http://juicyteeni...|porn_sex_tube_big...| 0.6991649379039865|views_videos_vide...| 0.18797024934758855|said_people_news_...| 0.04759986644175548|\n|publications.nigm...|https://publicati...|college_school_un...|0.34844619738120575|court_law_section...| 0.16744750948954387|county_state_new_...| 0.15416092956219257|\n|mail-index.netbsd...|http://mail-index...|class_div_data_sp...|0.22922133866572866|gmt_cruise_disney...| 0.21257650705535935|android_app_googl...|  0.2114740912925089|\n|       money.cnn.com|http://money.cnn....|market_energy_com...|0.41518156307306714|said_people_news_...| 0.18203966913723946|health_weight_new...| 0.11569881593511358|\n|   public-fucked.com|http://public-fuc...|porn_sex_tube_big...| 0.8849623765839598|tutoring_one_also...| 0.06288219615708589|english_chinese_s...|0.033533772803233636|\n|       snapbikes.com|http://snapbikes....|property_estate_s...|0.27591969496790025|travel_airport_fl...|  0.2606432111675775|accessories_ski_w...| 0.20052971130615688|\n|     www.asiapay.com|http://www.asiapa...|business_manageme...| 0.4877846483864224|travel_airport_fl...|  0.1543650025786414|world_news_war_in...| 0.11371028853483613|\n|support.rightscal...|http://support.ri...|business_manageme...|0.29414640317039276|email_search_name...| 0.23379507575310213|data_system_using...|  0.2199452827771428|\n|   nudegirlstube.com|http://nudegirlst...|porn_sex_tube_big...| 0.7300575430873868|views_videos_vide...|  0.1938744017925257|like_one_would_ge...| 0.06608063425648698|\n| pages.stern.nyu.edu|http://pages.ster...|function_var_retu...|0.27732478511979586|paper_perez_fabri...|  0.2246170280754816|offer_credit_bank...| 0.18125409230131395|\n|      www.alagna.net|http://www.alagna...|like_one_would_ge...|  0.494052886950671|sports_golf_baske...| 0.11981676283030172|food_recipes_reci...| 0.07557521615292546|\n|            lxer.com|http://lxer.com/m...|business_manageme...| 0.3429450677455559|forum_forums_post...| 0.20196271255019926|windows_software_...| 0.19094225789906438|\n+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1508512401364_1758655781","id":"20171020-131815_2006247238","dateCreated":"2017-10-20T15:13:21+0000","dateStarted":"2017-10-21T08:19:34+0000","dateFinished":"2017-10-21T08:21:30+0000","status":"PENDING","progressUpdateIntervalMs":500,"$$hashKey":"object:274"},{"text":"%pyspark\n\n","user":"anonymous","dateUpdated":"2017-10-20T16:10:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1508512401364_1758655781","id":"20171020-101912_1610139389","dateCreated":"2017-10-20T15:13:21+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:275"}],"name":"Tom 1 Topic Modelling","id":"2CWHDYUJP","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}